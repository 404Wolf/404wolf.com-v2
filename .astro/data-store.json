[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.13.7","content-config-digest","97e2dc124e7ea0b7","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://404wolf.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12,27,28,41,42,52,53,63,64,76,77,89,90,104,105,117,118,137,138,152,153,163,164,176,177,187,188,198,199,209,210,220,221,231,232,242,243,253,254,264,265,277,278,288,289],"404wolfcom",{"id":11,"data":13,"body":23,"filePath":24,"digest":25,"deferredRender":26},{"title":14,"type":15,"date":16,"covers":17,"tags":19,"description":22},"404Wolf.com","project","2024-01-01",[18],"https://static.404wolf.com/postEditor_0001.png",[20,21],"featured","academic","How I made my website, and an overview of all its unique features, including an integrated what-you-see-is-what-you-get markdown viewer, and fully featured Obsidian plugin. I explain my stack choice, how the posts are managed, and present my custom in-site editor. I also talk briefly about some specific struggles when building the website, like creating a good backup protocol and getting my markdown to parse properly and in a very specific way.\n","# Making [404Wolf.com](https://404wolf.com)\n\n## Inspiration\n\nI initially was planning on working on various other ongoing projects, such as an English flashcard generating service, but decided that I wanted to have a good place to document my progress on everything else. I started by making a simple homepage, and then when determining how to integrate a post/blog system fell down the rabbithole of learning my first stack and javascript for the first time. I could've used Wordpress, but I thought it would be a good chance to learn how to do it from scratch.\n\nI began working on this website during my second week of my batch at [Recurse Center](https://recurse.com), an amazing open-ended programming retreat based in Brooklyn, NY.\n\n## Choosing frameworks\n\nOne of the main goals of this website was to get started with webdev. It was my first proper \"full stack project.\" Previously I'd experimented with some templated HTML, but I hadn't done `javascript` before. I really enjoyed Harvard's CS50 React Native course's video, where they speed-teach the language (which is public and can be found [here](https://www.youtube.com/watch?v=X52b-8y2Hf4)). I also read over the [learnxinyminutes.com](https://learnxinyminutes.com) website to get a brief overview of the syntax. I've found that javascript (and, later, typescript), is weird, and not quite like other languages I've used. In some ways it's functional, especially with such flexible lambdas and promises. Yet, in others, it's object-orianted. Everything is a descendent of a primitive `object`, much like Python, and you can have \"classes,\" but using it functionally is often a lot more straightforward than in Python in my opinion.\n\nFor the frontend I went with React; I liked the idea of a composable component based system, it is quite popular, and I didn't really know what I was getting into. At the time I didn't know about React component libraries like MUI, so I ended up building everything from the ground up, which I think was good for learning, but bad for longer term maintenance.\n\nSince I knew I was going to want a backend for things like managing the posts on my website, I did a bit of research on how to set up a webserver for the project. I considered using `express` or `django` to serve the site and corresponding API, but a Recurse batch-mate introduced me to [NextJS](https://nextjs.org/), which was very easy to scaffold and fun to work with. It was also very easy (and free!) to get it hosted with [Vercel](https://vercel.com/). NextJS is an interesting framework that blends React for the frontend with Express for the backend, so that you can write your backend would-be API code in the same file directory, and even files, as your frontend code.\n\nOriginally, I made my website pages pull from a folder of markdown files which I edited and directly commited to Github. Eventually, though, it became unwieldy, and I met someone who introduced me to [Prisma](https://www.prisma.io/) and `Postgresql`. Postgres is a relational database system, an extension of SQL, and Prisma is a popular Javascript ORM (object-relational-mapping framework, used for querying the database with JS-object-style calls instead of literal SQL queries). I stored the posts and some resources in AWS S3 blob storage (flat ID to file storage), which at first was a pain to set up but got easier as I tinkered with the settings and began to understand how it (and auth) worked, referencing the images of my posts with keys that I stored in the database. It was a rabbit hole into my first full stack web app.\n\nI originally was planning on just using basic CSS, but after stumbling upon tailwind in a react guide I was reading, I decided that it was worth giving it a shot. It was simple to get set up, and made styling the website much easier and faster. Tailwind is a \"utility-first\" styling framework that provides a ton of useful classes that pre-pack styles so that you can do the styling directly in HTML instead of ever needing any CSS, sort of like bootstrap. For example, to add a bit of padding to the left of a `div`, you can simply add the class \"pl-3\". It has classes for pretty much every possible CSS style, and has predetermined discrete choices for sizes and colors (which can be customized, but in general help development more than hurt).\n\nOne fun thing I came across when designing the homepage UX is [Typewriter.js](https://safi.me.uk/typewriterjs/), a library for simulating typing. I thought it'd be a cool affect to apply to headers on my site, and then later experimented with other animations and animation frameworks a bit. It lets you do typewriter animations in a very nice modonic style.\n\n```js\ntypewriter\n  .typeString(\"Hello World!\")\n  .pauseFor(2500)\n  .deleteAll()\n  .typeString(\"Strings can be removed\")\n  .pauseFor(2500)\n  .deleteChars(7)\n  .start();\n```\n\n## Post Management\n\nOne of the key features of my website is its integrated post management system. Though originally my purpose was to just have a collection of my projects on the site, as a portfolio of sorts, I decided to also add the ability to post blogs too. All posts on the site are of a specific `type`, either `project` or `blog`. By going to the pattern matched URL `https://404wolf.com/posts/\u003Ctype>s`, you can view all posts of a specific type. Each post has a specific schema, which is used to generate a grid of tiles that present post previews.\n\n```ts\ninterface PostData {\n  coverUrl: string | null;\n  coverAlt: string | null;\n  id: string;\n  title: string;\n  description: string;\n  date: string;\n  tags: string[];\n}\n```\n\n![href](https://static.404wolf.com/postsPage_0001.png)\n\nThe posts themselves store this metadata in the database, and have corresponding markdown files in S3. When the page is loaded to view a post, the S3 markdown is prefetched, and is rendered client side. I use [react-markdown](https://github.com/remarkjs/react-markdown) to render the markdown, with some custom overrides to handle images and codeblocks. I talk about this more [in this blog I wrote](/posts/blog/imageBlocks), but I've also added image blocks to markdown, to allow for groups of many images to show up inline in the rendered markdown, by actually toying with the markdown to html `AST` process.\n\n### Post editor\n\n![Post editor](https://static.404wolf.com/postEditor_0001.png)\n![Editable S3 text area](https://static.404wolf.com/editAboutMe_0001.png)\n\nTo edit my posts, I decided to add an integrated editor into my website. This is because I want the website to automatically handle storage of associated post resources (images, files, markdown versions, etc.), rather than having to manually deal with uploading things to S3 and directly using the hard S3 links. My goal was to be able to reference the resources by keys (unique IDs I assign to them) directly in the markdown, and by integrating the editor into the website I've made it possible to have a what-you-see-is-what-you-get markdown editing system where the markdown automatically replaces aliases live. The actual post-editing page is quite complex since it includes many different fields to enter metadata for the project post, a split screen viewing panel, and a resource panel. The most notable part, seen in the `Editable S3 text area` image above, is I've made a component to directly edit an AWS S3 file with simple text area entry that is capable of displaying images and other artifacts as rendered markdown.\n\n![The resource editor](https://static.404wolf.com/https://static.404wolf.com/Post-20240710001621089.webp)\n\nThis system of using IDs was done with keys that are required to be unique by the user, which is probably not the ideal way of doing it -- I was manually naming files uniquely. I decided to solve this problem by making all posts upload with a unique ID automatically based on their filename, by appending `000n` to the end, like `filename_0004.png`. It's a bit clunky and requires iteration to find an unused file name, but it works for now.\n\n## Exporting/importing\n\n![Export tree](https://static.404wolf.com/exportTree_0001.png)\n\nIn general, I don't like locking myself into ecosystems, so from the beginning I knew I wanted a system to export the contents of the site. This website obviously relies on the hosting of various different cloud providers, which, though reliable, are fail points. When I created the post editing system, I also wrote two basic scripts to upload and download the all the posts and their respective metadata. All files associated with a specific post get stored in a folder alongside the post's markdown, and the metadata is saved as a simple `json`. Writing these scripts was rather simple, since I'm iteratively doing a database call for each post to download all the resources using the public S3 URL, and my ORM can give me a metadata json automatically. This script was made obsolete by my new Obsidian plugin for the website, though.\n\n# Obsidian Plugin\n\nComing soon!\n\n## Teasers\n\n![The commands](https://static.404wolf.com/Post-20240716223544716.webp)\n\n![My website's contents](https://static.404wolf.com/Post-20240716223617606.webp)","src/posts/404Wolf.com.mdx","cbc8ad792394da60",true,"bitwardenbackuptool",{"id":27,"data":29,"body":38,"filePath":39,"digest":40,"deferredRender":26},{"title":30,"type":15,"date":31,"covers":32,"tags":34,"description":37},"Bitwarden Backup Utility","2021-01-01",[33],"https://static.404wolf.com/bitwarden_backup.webp",[35,36],"personal","hidden","Bitwarden, a popular open source and free password manager, does a great job of securely storing passwords and other personal data in their cloud, well-encrypted and accessible. However, their option to export your vault (to maintain a local/physical backup) is to export it as a .json file, leaving data in a very human-unfriendly format. So, I made a program that converts the json to a more human readable html file, which one can print onto physical paper. In addition, I've integrated automatic favicon/icon fetching, QR code generation, databreach checks and more.\n","# Bitwarden Backup Human-izer\n\n## A program to convert a bitwarden json backup into sleek html\n\n### How to use:\n\n1. Get the [official bitwarden desktop app](https://bitwarden.com/download/), in order to export your vault as a json file\n2. Open the bitwarden desktop app, and click `file > export vault`, making sure to choose `json` as the format.\n3. Once you reenter your master password, choose to download the json export in the same file directory as this project's `main.py`, and rename the export to `export.json`. You should be left with an **unencrypted** json file. When you are finished, you will want to delete this file and empty your trash.\n4. Open console, and run `main.py` by entering `python main.py`, or `python3 main.py`, depending on your operating system. If you get a `ModuleNotFound` error, type `pip install \u003Cname of module that was not found>`. Depending on how many items are in your vault, this process can take a considerable amount of time (sometimes minutes).\n5. Open `output.html` in a web browser such as [chrome](https://www.google.com/chrome/), and print out the file, or save it as a pdf by clicking the `save as pdf` option under `printers`.\n6. Delete the `qrCodes` folder, `output.html` file, and `export.json` file when you are done, and **empty your trash**! If you use a utility such as google drive backup and sync, do not put these files in a folder that syncs. These files contain unencrypted sensitive data.\n\n### Use cases:\n\n- Printing out the backup\n- Storing as a backup on a hard drive, in case bitwarden ever goes away in the future\n- Having access to your vault without needing a device\n\n### Future plans:\n\n- TOTP 2FA QR code generation\n- Folder support (colour coding, or small tab on right side to indicate folder name)\n- Credit card image generation (for credit card type items, generate a picture of a credit card with the user's info on it)\n- Automatic html to pdf conversion\n- Mark/save where the user has printed up to, so they can only print new content\n- Decrypt encrypted bitwarden json backups\n- Fix inaccurate/broken progress bar\n\n### Trying it out:\n\nIf you just want to try out the script, you can find an example `export.json` and `output.html` file [here](https://gitlab.com/bread/BitwardenBackup/-/tree/main/demoImages).","src/posts/BitwardenBackupTool.mdx","61a5397fc82a2b4e","androidinthebrowser",{"id":41,"data":43,"body":49,"filePath":50,"digest":51,"deferredRender":26},{"title":44,"type":15,"date":16,"covers":45,"tags":47,"description":48},"Android in the Browser",[46],"https://static.404wolf.com/Post-20240807144914137.webp",[35],"An ongoing effort to get a fully functional android phone embedded into an iFrame in a browser, with as little latency as possible. Note: post in progress!\n","# Notice\n\nThis is a long-term, very much in-progress project, so this post currently serves primarily as a progress tracker and collection of notes on the project, along with some information what I've accomplished so far.\n\n# Presentation\n\nA recreation of a 5 minute presentation I gave at [Recurse Center](https://recurse.com) for the project.\n\n![Quick overview](5minuteDemo.webm|float=none|width=100)\n\n# Inspiration\n\nSo, earlier this year I was working on my first React Native application, which was a small app to plan events. It was my first mobile project in general, and at the time I got started with it on a Windows machine to avoid the pains that I assumed may accompany mobile development package management.\n\nIt didn't take long to realize that it's very very hard to develop for IOS on anything other than a mac, because tooling to \"talk\" to iPhones for development relies on xCode. That means that I couldn't use a physical iPhone, or even run an emulator (a \"fake\" phone running on my computer).\n\n![Android studio](https://static.404wolf.com/https://static.404wolf.com/Post-20240807195159827.webp)\n\nFor Android development, Google is much nicer about it, and lets you run emulators and bridge a physical phone over on all platforms. They recommend using [Android Studio](https://developer.android.com/studio), which is _fine_, but a pain in the neck. The process to create an emulator in android studio is pretty straight forward, but requires a lot of clicking and is quite tedious and magical. You can choose a \"skin\" and android image, sometimes you configure the virtual device a bit further with their gui, and then run it from the app.\n\nI used it for the project, and it worked well enough for my needs. Metro, a bundler that creates and ships APKs based on your `react native` project works well with Android studio's emulator, and it was fine at the time, and was only moderately annoying to work with.\n\n## Android Development on Linux\n\nFast forward a few months, and I was returning to the project, but this time was running NixOS. It was my first half of a [Recurse Center](https://recurse.com) batch, and I was still figuring a lot of things out. One of the things that `nix` claims to be very good at is reproducible builds, meaning that I would expect packages in the `nixpkgs` package registry to \"just work.\"\n\nSo, I tried adding `android-studio` to my developer environment, and then ran it. It launched!\n\nI browsed through the configuration options to go and set up an emulator again, and, upon launching the emulator, it would say emulator booting, but fail to actually start.\n\nDebugging this, as a pretty new `nix` user at the time, was painful. I ran `android studio` from the command line, and enabled debug logs. It looked like there were a whole bunch of dependencies not for android studio, but for the emulators it was spawning. Part of the issue is that android studio usually pulls emulator images when you set up the emulators, not when you install android studio, so while the build of android studio that I got was working just fine, the emulators that it was pulling were broken, likely because of upstream changes.\n\nAndroid Studio is very heavy though; it's an entire Jetbrains IDE. I find it really clunky to use, and when things don't work it's a pain in the neck to debug since it's a massive GUI desktop app that does so many things under the hood.\n\nPlus, the licensing and codebase for it seems a bit sketchy and obstruce.\n\n> The code is under Apache-2.0, but:\n> If one selects Help -> Licenses in Android Studio, the dialog shows the following:\n> \"Android Studio includes proprietary code subject to separate license,\n> including JetBrains CLion(R) (www.jetbrains.com/clion) and IntelliJ(R)\n> IDEA Community Edition (www.jetbrains.com/idea).\"\n> Also: For actual development the Android SDK is required and the Google\n> binaries are also distributed as proprietary software (unlike the\n> source-code itself).\n\nI like open source tooling, and I don't like magic. So, I decided that it would be productive to delve deeper and figure out how to do what it's doing without the entire desktop app.\n\n## Android CLI Tooling\n\nThe general breakdown is that there's an android SDK toolkit that provides you with a ton of command line utilities for android development and debugging. This SDK is included in distributions of android studio, and they are what Android studio uses internally under the hood. Furthermore, `nixpkgs` already has packaged them under`android-tools` (source [here](https://github.com/NixOS/nixpkgs/blob/nixos-24.05/pkgs/tools/misc/android-tools/default.nix#L28)). Because the android build system is so annoying to deal with, someone created [a project to build these cli tools with cmake](https://github.com/nmeum/android-tools), which is what the official `nixpkgs` package of them uses.\n\nThere's a lot of CLI tools for dealing with android, but it turns out that there's a few critical ones for getting an emulator up and running, and having a better conceptual understanding of the magic behind android studio.\n\n![Our tools](https://static.404wolf.com/https://static.404wolf.com/Post-20240807233545196.webp)\n\nFirst things first. You need to set `ANDROID_SDK_ROOT` to the directory with the various binary cli tools we were just talking about (so like, if they're in your PATH, you can figure out where to set `ANDROID_SDK_ROOT`to by doing `which emulator`, where emulator is an example of one of the many android tools). Since I'm using `nix` , can easily keep things simple and automated with a devshell. Okay, now we want to\n\nThen we do something along the lines of\n\n```bash\navdmanager create avd -n my_avd -k \"system-images;android-30;google_apis;x86\" -d \"pixel\"\n```\n\nTo create an \"avd,\" which is basically a configuration file that specifies the details of some virtual android device that could be run as an emulator. AVD stands for \"android virtual device.\"\n\nWe can check to make sure that our avd shows up by doing\n\n```bash\navdmanager list avd\n```\n\nAnd then, to run it, use\n\n```bash\nemulator -avd my_avd\n```\n\nAnd then, if you're on `nix`, you'll be welcomed with a friendly message informing you that there's some dynamically linked dependency that you don't have, that you'll have to wrap with `LD_LIBRARY_PATH`. And then again.\n\nAll of these android CLI tools are very powerful, and have a gagillion options that you can fiddle with.\n\nI spent almost a week trying to get all the packages and settings fine tuned for `nix`, and ended up getting very close -- I had a bash script that would create an `avd`, create a virtual `sdcard` for \"external\" device storage, and then actually run the emulator. But for some reason I was getting a segfault, and it wouldn't launch, or give me any more useful error messages.\n\nAt that point I decided to do further research on android emulators on Nix, and found that Nix's standard library itself has already solved the problem.\n\nThere's [\"documentation\" here](https://nixos.wiki/wiki/Android) that talks about android development on Nix. Here, they talk about some helper functions that you can use to create android SDKs with the exact binaries that you need, nicely purely packaged with nix.\n\nWith the help of that guide and reading some source, I was able to scrap together this flake, which gets you most of the lower level CLI tools you need for android development. It's not entirely trivial, and not every tool is necessary for every task, but it's quite good.\n\n### A working flake\n\n```nix\n{\n  description = \"React native environment\";\n\n  inputs = {\n    nixpkgs.url = \"github:NixOS/nixpkgs\";\n    flake-utils.url = \"github:numtide/flake-utils\";\n  };\n\n  outputs = { self, nixpkgs, flake-utils, ... }@inputs:\n    flake-utils.lib.eachDefaultSystem (system:\n      let\n        pkgs = import nixpkgs {\n          inherit system;\n          config = {\n            allowUnfree = true;\n            android_sdk.accept_license = true;\n          };\n        };\n\n        pinnedJDK = pkgs.jdk17;\n        buildToolsVersion = \"34.0.0\";\n        ndkVersion = \"25.1.8937393\";\n        androidComposition = pkgs.androidenv.composeAndroidPackages {\n          cmdLineToolsVersion = \"8.0\";\n          toolsVersion = \"26.1.1\";\n          platformToolsVersion = \"34.0.4\";\n          buildToolsVersions = [ buildToolsVersion \"33.0.1\" ];\n          includeEmulator = false;\n          emulatorVersion = \"30.3.4\";\n          platformVersions = [ \"34\" ];\n          includeSources = false;\n          includeSystemImages = false;\n          systemImageTypes = [ \"google_apis_playstore\" ];\n          abiVersions = [ \"armeabi-v7a\" \"arm64-v8a\" ];\n          cmakeVersions = [ \"3.10.2\" \"3.22.1\" ];\n          includeNDK = true;\n          ndkVersions = [ ndkVersion ];\n          useGoogleAPIs = false;\n          useGoogleTVAddOns = false;\n          includeExtras = [ \"extras;google;gcm\" ];\n        };\n      in {\n        devShells.default = pkgs.mkShell rec {\n          packages = [\n            pkgs.android-tools\n            pkgs.nodejs\n            pkgs.corepack\n            pkgs.zulu17\n          ];\n\n          JAVA_HOME = pinnedJDK;\n          ANDROID_SDK_ROOT = \"${androidComposition.androidsdk}/libexec/android-sdk\";\n          ANDROID_NDK_ROOT = \"${ANDROID_SDK_ROOT}/ndk-bundle\";\n          GRADLE_OPTS = \"-Dorg.gradle.project.android.aapt2FromMavenOverride=${ANDROID_SDK_ROOT}/build-tools/${buildToolsVersion}/aapt2\";\n          shellHook = ''\n            export PATH=$PATH:${androidComposition.androidSdk}/bin\n            adb start-server\n            adb devices\n          '';\n        };\n      });\n}\n```\n\n### An emulator, in 4 lines of Nix\n\nAfter reading through all the source though, a super neat function caught my eye: [emulate app](https://github.com/NixOS/nixpkgs/blob/master/pkgs/development/mobile/androidenv/emulate-app.nix). It wasn't documented anywhere, but it was super promising. Here's the entire source code, which is definitely worth reading over. It's very similar to what I was doing, but they were able to figure out how to get all the flags just right.\n\n```nix\n{ composeAndroidPackages, stdenv, lib, runtimeShell }:\n{ name\n, app ? null\n, platformVersion ? \"33\"\n, abiVersion ? \"armeabi-v7a\"\n, systemImageType ? \"default\"\n, enableGPU ? false # Enable GPU acceleration. It's deprecated, instead use `configOptions` below.\n, configOptions ? (\n    # List of options to add in config.ini\n    lib.optionalAttrs enableGPU\n      (lib.warn\n        \"enableGPU argument is deprecated and will be removed; use configOptions instead\"\n        { \"hw.gpu.enabled\" = \"yes\"; }\n      )\n  )\n, extraAVDFiles ? [ ]\n, package ? null\n, activity ? null\n, androidUserHome ? null\n, avdHomeDir ? null # Support old variable with non-standard naming!\n, androidAvdHome ? avdHomeDir\n, deviceName ? \"device\"\n, sdkExtraArgs ? { }\n, androidAvdFlags ? null\n, androidEmulatorFlags ? null\n}:\n\nlet\n  sdkArgs = {\n    includeEmulator = true;\n    includeSystemImages = true;\n  } // sdkExtraArgs // {\n    cmdLineToolsVersion = \"8.0\";\n    platformVersions = [ platformVersion ];\n    systemImageTypes = [ systemImageType ];\n    abiVersions = [ abiVersion ];\n  };\n\n  sdk = (composeAndroidPackages sdkArgs).androidsdk;\nin\nstdenv.mkDerivation {\n  inherit name;\n\n  buildCommand = ''\n    mkdir -p $out/bin\n\n    cat > $out/bin/run-test-emulator \u003C\u003C \"EOF\"\n    #!${runtimeShell} -e\n\n    # We need a TMPDIR\n    if [ \"$TMPDIR\" = \"\" ]\n    then\n        export TMPDIR=/tmp\n    fi\n\n    ${if androidUserHome == null then ''\n      # Store the virtual devices somewhere else, instead of polluting a user's HOME directory\n      export ANDROID_USER_HOME=$(mktemp -d $TMPDIR/nix-android-user-home-XXXX)\n    '' else ''\n      mkdir -p \"${androidUserHome}\"\n      export ANDROID_USER_HOME=\"${androidUserHome}\"\n    ''}\n\n    ${if androidAvdHome == null then ''\n      export ANDROID_AVD_HOME=$ANDROID_USER_HOME/avd\n    '' else ''\n      mkdir -p \"${androidAvdHome}\"\n      export ANDROID_AVD_HOME=\"${androidAvdHome}\"\n    ''}\n\n    # We need to specify the location of the Android SDK root folder\n    export ANDROID_SDK_ROOT=${sdk}/libexec/android-sdk\n\n    ${lib.optionalString (androidAvdFlags != null) ''\n      # If NIX_ANDROID_AVD_FLAGS is empty\n      if [[ -z \"$NIX_ANDROID_AVD_FLAGS\" ]]; then\n        NIX_ANDROID_AVD_FLAGS=\"${androidAvdFlags}\"\n      fi\n    ''}\n\n    ${lib.optionalString (androidEmulatorFlags != null) ''\n      # If NIX_ANDROID_EMULATOR_FLAGS is empty\n      if [[ -z \"$NIX_ANDROID_EMULATOR_FLAGS\" ]]; then\n        NIX_ANDROID_EMULATOR_FLAGS=\"${androidEmulatorFlags}\"\n      fi\n    ''}\n\n    # We have to look for a free TCP port\n\n    echo \"Looking for a free TCP port in range 5554-5584\" >&2\n\n    for i in $(seq 5554 2 5584)\n    do\n        if [ -z \"$(${sdk}/bin/adb devices | grep emulator-$i)\" ]\n        then\n            port=$i\n            break\n        fi\n    done\n\n    if [ -z \"$port\" ]\n    then\n        echo \"Unfortunately, the emulator port space is exhausted!\" >&2\n        exit 1\n    else\n        echo \"We have a free TCP port: $port\" >&2\n    fi\n\n    export ANDROID_SERIAL=\"emulator-$port\"\n\n    # Create a virtual android device for testing if it does not exist\n    if [ \"$(${sdk}/bin/avdmanager list avd | grep 'Name: ${deviceName}')\" = \"\" ]\n    then\n        # Create a virtual android device\n        yes \"\" | ${sdk}/bin/avdmanager create avd --force -n ${deviceName} -k \"system-images;android-${platformVersion};${systemImageType};${abiVersion}\" -p $ANDROID_AVD_HOME/${deviceName}.avd $NIX_ANDROID_AVD_FLAGS\n\n        ${builtins.concatStringsSep \"\\n\" (\n          lib.mapAttrsToList (configKey: configValue: ''\n            echo \"${configKey} = ${configValue}\" >> $ANDROID_AVD_HOME/${deviceName}.avd/config.ini\n          '') configOptions\n        )}\n\n        ${lib.concatMapStrings (extraAVDFile: ''\n          ln -sf ${extraAVDFile} $ANDROID_AVD_HOME/${deviceName}.avd\n        '') extraAVDFiles}\n    fi\n\n    # Launch the emulator\n    echo \"\\nLaunch the emulator\"\n    $ANDROID_SDK_ROOT/emulator/emulator -avd ${deviceName} -no-boot-anim -port $port $NIX_ANDROID_EMULATOR_FLAGS &\n\n    # Wait until the device has completely booted\n    echo \"Waiting until the emulator has booted the ${deviceName} and the package manager is ready...\" >&2\n\n    ${sdk}/libexec/android-sdk/platform-tools/adb -s emulator-$port wait-for-device\n\n    echo \"Device state has been reached\" >&2\n\n    while [ -z \"$(${sdk}/libexec/android-sdk/platform-tools/adb -s emulator-$port shell getprop dev.bootcomplete | grep 1)\" ]\n    do\n        sleep 5\n    done\n\n    echo \"dev.bootcomplete property is 1\" >&2\n\n    #while [ -z \"$(${sdk}/libexec/android-sdk/platform-tools/adb -s emulator-$port shell getprop sys.boot_completed | grep 1)\" ]\n    #do\n        #sleep 5\n    #done\n\n    #echo \"sys.boot_completed property is 1\" >&2\n\n    echo \"ready\" >&2\n\n    ${lib.optionalString (app != null) ''\n      # Install the App through the debugger, if it has not been installed yet\n\n      if [ -z \"${package}\" ] || [ \"$(${sdk}/libexec/android-sdk/platform-tools/adb -s emulator-$port shell pm list packages | grep package:${package})\" = \"\" ]\n      then\n          if [ -d \"${app}\" ]\n          then\n              appPath=\"$(echo ${app}/*.apk)\"\n          else\n              appPath=\"${app}\"\n          fi\n\n          ${sdk}/libexec/android-sdk/platform-tools/adb -s emulator-$port install \"$appPath\"\n      fi\n\n      # Start the application\n      ${lib.optionalString (package != null && activity != null) ''\n          ${sdk}/libexec/android-sdk/platform-tools/adb -s emulator-$port shell am start -a android.intent.action.MAIN -n ${package}/${activity}\n      ''}\n    ''}\n    EOF\n    chmod +x $out/bin/run-test-emulator\n  '';\n}\n```\n\nBasically, they generate a bash script that \"hard codes\" paths to the various packages (things like `${pkgs.hello}` here evaluate to `/nix/store/jfe...hash...jfei`), which are locations of specific, version locked dependencies.\n\nAnd it works! Using this function turns out to be extremely trivial. It's literally 4 lines of nix, since you don't need to build an android composition to use the function, even though you can.\n\nSo, here it is. Just a few lines of nix, and then `nix run`, and you have yourself a full on, working, ready to go android emulator, running on your computer.\n\n```nix\nemulator = pkgs.androidenv.emulateApp {\n    name = \"AndroidEmulator\";\n    platformVersion = \"30\";\n    abiVersion = \"x86_64\"; # armeabi-v7a, mips, x86_64\n    systemImageType = \"google_apis_playstore\";\n};\n```\n\nIt's so crazy cool, it just works!\n\nAfter all of the suffering to get a good working android emulator, and I had an idea: what if I could solve this problem for everyone, on every OS, everywhere, once and for all? What if I could offer android phones as a service, just using nix builds?\n\n### RobotNix\n\nOne of the massive pain points for Android development is actually building Android itself. Google provides scattered documentation that helps with this process, but it's very disparate, and just about everyone uses prebuilt images as a result.\n\nIn the process of tinkering, I [came across a project that packaged all google android images with `nix`](https://github.com/tadfisher/android-nixpkgs). It seemed pretty neat and promising here, since it would solve the issue of having images change over time in ways that break my setup because of differing dependencies.\n\n![Nixified android builds](https://static.404wolf.com/https://static.404wolf.com/Post-20240807144625586.webp)\n\nI spent a long time trying to get an emulator working using the images it provided, and in the process I learned a ton about android cli tooling.\n\nTad Fisher's project that I just mentioned also packages android sdk tools too, and his are much finer grain.\n\n```nix\n android-sdk.packages = sdk: with sdk; [\n    build-tools-34-0-0\n    cmdline-tools-latest\n    emulator\n    platforms-android-34\n    sources-android-34\n];\n```\n\n### ADB\n\nOne of the most important android `cli` tools is `adb`, or `android debug bridge`. `adb` is a CLI tool (and has a socket interface) that is used to communicate with android devices.\n\nIt automatically can pick up on all android devices plugged into your computer over USB, running on the local network with wireless debugging enabled, and even emulators (which will be important later).\n\nIt's very powerful. It can do just about everything. To use `adb` for android development, usually you begin by running\n\n```bash\nadb start-server\n```\n\nWhich starts a server running on a socket on your computer that lets you use the `adb` cli client, or other community clients, to manipulate android devices.\n\nWhat isn't as commonly known is that there's also a `tcp/ip` mode for `adb` with `adb tcpip`. Once `adb` is running, you can then list out android devices with\n\n```bash\nadb devices\n```\n\nAnd start issuing commands. You can do things like\n\n- `adb shell` to enter a shell on the android phone itself.\n- `adb push` to push a file onto the device, and `adb pull` to yoink files off it\n- `adb (un)(in)stall` to un/install apks (android apps) to the device\n- `adb input tap x y` to tap the screen at a specific spot\n\nand a ton of other manipulation commands to do things like entering text input, capturing screenshots, recording audio, and more.\n\nIt's super powerful, and will play an important role in this project, as I'll discuss a bit later.\n\nWhat I've learned while researching these tools is that they are really horribly documented. [Google has docs](https://source.android.com/docs/setup/create/coding-tasks) that talk about the general processes, and, if you can figure out where to find things, you can get the source code for the CLI programs too. But, it seems like their main intent is to try to get people to use Android Studio as much as possible.\n\n## [Appetize.io](https://appetize.io)\n\n[Appetize.io](https://appetize.io) is a company that offers roughly just that. I found out about them later on when reviewing the `react native` documentation -- all the little phone widgets that say \"Expo\" on them are powered by `appetize.io` devices. They let you spin up android or IOS devices, and then embed them in webpages with decently low latency. They also expose an API, so that you can do CI/CD testing with proper phones.\n\n![React native docs](https://static.404wolf.com/https://static.404wolf.com/Post-20240807144243428.webp)\n![It's expensive](https://static.404wolf.com/https://static.404wolf.com/Post-20240807144458831.webp)\n![Appetize.io](https://static.404wolf.com/https://static.404wolf.com/Post-20240807144317000.webp)\n![It \"just works\"](https://static.404wolf.com/https://static.404wolf.com/Post-20240807144431237.webp)\n\nBut appetize comes at a cost. It's very expensive, and very restrictive. It isn't open source, and definitely isn't nixified.\n\nIt's worth mentioning them here before going further though, since what they do is genuinely really cool. Their main thing is automated testing, although they may also be able to do android development with the regular SDK tools too.\n\n# Ideation\n\nSo, I started brainstorming. My idea was to stream `nix` packaged android emulators to web browsers.\n\nOne other super cool thing that `nix` rocks at is containerizing things. Nix's standard library provides [utilities to create docker base images](https://nix.dev/tutorials/nixos/building-and-running-docker-images.html) that have all of the dependencies and transient dependencies of a nix derivation (build).\n\nThis means that you can implicitly refer to libraries in the function nix provides that creates docker images, and if they get mentioned then they get \"baked\" into the container. Part of what's so nice about dockering android emulators is that the processes live and die with the containers, since the qemu processes that the emulators create are kind of a pain to track and to kill.\n\nI am still working on getting them working in a docker container, but what I currently have, which is pretty close to what I expect to work, looks like this\n\n```nix\n{\n  pkgs,\n  android-tools,\n  system,\n  ...\n}: let\n  run-android-emulator = import ./emulator.nix {inherit pkgs;};\n  android-sdk = import ./android-sdk.nix {inherit pkgs system android-tools;};\nin\n  pkgs.dockerTools.buildImage {\n    name = \"android-emulator\";\n    tag = \"latest\";\n\n    copyToRoot = pkgs.buildEnv {\n      name = \"root\";\n      pathsToLink = [\"/bin\"];\n      paths = [\n        pkgs.jdk\n        pkgs.coreutils\n        pkgs.bash\n        pkgs.busybox\n        pkgs.bun\n        android-sdk\n      ];\n    };\n\n    config = {\n      Env = [\n        \"JAVA_HOME=${pkgs.jdk}\"\n      ];\n      # has the script that uses the emulate-app function\n      Cmd = [\"./${run-android-emulator}/bin/android-emulator\"];\n    };\n\n    extraCommands = ''\n      mkdir -p tmp\n    '';\n  }\n```\n\nWhich does basically exactly what I just explained -- although we do need some dependencies that I didn't reference directly off of a nix object, like coreutils, and cli things like grep.\n\n## The browser?\n\nMy goal was to have the easiest, most streamlined devex possible for the project. So, ideally the final product for the end user could just be a react component, or even an `iframe` eventually. Right now, the interface is this.\n\n```typescript\nexport default function App() {\n  return \u003CAndroid ip={[\"ws://127.0.0.1:8188\"]} apiSecret=\"secret\" />\n}\n```\n\n### Streaming\n\nThe first step is to stream android at as low latency as possible out of the phone. As close to literal 0 as possible (so in reality, ideally \\\u003C300ms). Doing this, however, is actually pretty nontrivial.\n\nThe first step is figuring out how we can stream the screen out of the android device. Obviously this is possible, because when you run android emulators (without the `-no-window` flag) you get a window that shows the screen of the android device and is interactive. Android studio also natively provides this feature.\n\n`adb`, which we talked about earlier, does do this out of the box with a built in android utility called screenrecord. More information about that can be found [here](https://android.stackexchange.com/questions/7686/is-there-a-way-to-see-the-devices-screen-live-on-pc-through-adb).\n\nTo use it, it looks something like this...\n\n```bash\nsudo apt-get install adb ffmpeg\nadb exec-out screenrecord --output-format=h264 - |\n   ffplay -framerate 60 -probesize 32 -sync video  -\n```\n\nIt does work, but unfortunately the latency is pretty high. My tests got about 6 seconds of latency, although this stackoverflow post's video seems to have gotten about a second or less with some `ffmpeg` tuning. I may return to this later, but for now I am using what I believe to be a better alternative, [`scrcpy`](https://github.com/Genymobile/scrcpy).\n\n#### Scrcpy\n\n![Scrcpy](https://static.404wolf.com/https://static.404wolf.com/Post-20240807144813092.webp)\n![Scrpy in action](https://static.404wolf.com/https://static.404wolf.com/Post-20240807144914137.webp)\n\nScrcpy (\"screen copy\") is a 3rd party utility that lets you stream an android device to a window at extremely low latency (30ms or less!). It \"just works,\" and is available on `nixpkgs` (nix package manager). Using it is literally as simple as plugging in an android device, or running an emulator (headless or headed, it doesn't care), and then running\n\n```bash\nscrcpy\n```\n\nAnd a window will open up on your computer with `scrcpy`, which has a live stream of the screen of the android phone. The window it opens up is interactive and is very responsive, and audio works out of the box too.\n\nThe client (the window it opens up) has support for more advanced things too.\n\nSo, they seem to have solved the issue of `adb` having bad latency, but how?\n\nTo figure out how scrcpy works behind the scenes, they lay out a general schematic in [their docs](https://github.com/Genymobile/scrcpy/blob/master/doc/develop.mdhttps://github.com/Genymobile/scrcpy/blob/master/doc/develop.md) for contributors. I'm not going to reiterate everything they say there, but there are a few important takeaways if I want to use scrcpy's system of streaming at low latency.\n\nThe general idea of how `scrcpy` works is that you run it, and it ships a `apk` (android app) to the phone in its `/tmp` directory (which android phones have, they are also `unix`!). This `apk` exposes a server on the android phone on a `scrcpy` port on the phone, which then the `scrcpy` client can access and send data through.\n\n![Scrcpy server with audio](https://static.404wolf.com/https://static.404wolf.com/Post-20240808142749751.webp)\n\nThis `scrcpy` server that runs on the phone is implemented in `java` (which most android apps are), and acts as just a server running in the background.\n\nIt turns out that `scrcpy` streams out data over three \"channels,\" where the first connection gets a connection to stream video, followed by audio, and finally data (interactions like gestures, which scrcpy also handles itself with a super low-latency custom binary interface).\n\nTheir client itself is very complex, and is implemented in raw C and uses some very advanced frameworks to optimize for very high performance. That's less relevant here.\n\n#### Hijacking Scrcpy\n\n![Standalone scrcpy sever](https://static.404wolf.com/https://static.404wolf.com/Post-20240808142957377.webp)\n\nKnowing that scrcpy is just using a server running on the phone was enticing though.\n\nAt this point, I really just wanted to pipe the video into `ffmpeg` so that I could do things with it, since I still didn't know how I would stream it, but I knew that pretty much no matter what `ffmpeg` should be able to do the necessary forwarding.\n\nI did a bit of googling, and it looks like it is possible to do. I found a github issue, with a link to a VLC (the video viewing program) PR that fixes a latency issue having to do with how VLC throttles video stream outputs.\n\n![Piping Scrcpy to FFMPEG](https://static.404wolf.com/Post-20240807145206166.webp)\n\nI was able to follow their steps, and the main pain point was getting `adb` to forward a tcp port.\n\nTo use `scrcpy` to stream video output, you need to put and then start `scrcpy` on the phone, and then remap the port on the phone that scrcpy is using to a different port on your computer.\n\nThey provide an example script that shows how to do this, which is this\n\n```bash\nadb push scrcpy-server-v2.1 /data/local/tmp/scrcpy-server-manual.jar\nadb forward tcp:1234 localabstract:scrcpy\nadb shell CLASSPATH=/data/local/tmp/scrcpy-server-manual.jar \\\n    app_process / com.genymobile.scrcpy.Server 2.1 \\\n    tunnel_forward=true audio=false control=false cleanup=false \\\n    raw_stream=true max_size=1920\n```\n\nIt's not that bad. Another important thing here is that you need to set `raw_stream` to `false`, since usually `scrcpy` sends some metadata at the start of streams, which could stop `ffmpeg` from correctly interpreting the stream.\n\nI found [this great medium post](https://pencilflip.medium.com/how-to-use-adb-forward-6a8cbfa04907) that talks about how `adb forward` works, since it is horribly documented. They mention [SERVICES.txt](https://cs.android.com/android/platform/superproject/+/master:packages/modules/adb/SERVICES.TXT), which has even more helpful docs.\n\nI didn't end up needing to fiddle around much with the default command that they say to use to forward the port, but I like having an understanding of how it works.\n\nSo, at this point I have a working script that can copy `scrcpy` over to an android phone, run it on the phone, and then stream out the screen.\n\nNow, what's actually coming out of the port? Raw h264 video. Great! Viewing the screen using the `vlc` command they say to try **does** work, but it is very very laggy just like they say.\n\n## WebRTC?\n\nOkay, I now (kinda) have a working stream coming out of the android device. This is pretty sick. Now comes the hard part... how do I take this output stream and get it to a web browser, with as low latency as possible.\n\n### Streaming to a browser\n\n![Enter WebRTC](https://static.404wolf.com/Post-20240807145608512.webp)\n\nI did some research here, and there's a ton of different streaming protocols that browsers support. A google search reveals many, like\n\n- HLS\n- WebRTC\n- Real-time Messaging Protocol (Rtmp)\n- Secure Reliable Transport (Srt)\n- Real-time Streaming Protocol (Rtsp)\n- Microsoft Smooth Streaming\n- RTMP\n- RTSP\n\nHLS is really nice, it's just relaying video live over http, and you can access the media directly through a `\u003Cvideo>` element. Also, `ffmpeg` supports streaming out `\u003Cvideo>` out of the box, which is nice. Unfortunately though, it adds a lot of latency. To achieve the latency I want in this case, I really don't have any option other than WebRTC.\n\nWebRTC is a peer to peer browser streaming protocol. It's pretty simple to use since browsers have a good unified API for it, where you essentially have a signaling websocket server that tells clients when and whom to connect to, and then they can stream things to each other from the browser itself, like video camera output.\n\nThat's great, but in my case I am doing a very centralized broadcast. I have media streaming off of a server, and want to ship that media to browsers directly. This is something that WebRTC isn't really designed for.\n\n![Janus Gateway](https://static.404wolf.com/Post-20240807145641902.webp)\n![Janus (the god)](https://static.404wolf.com/Post-20240807145717463.webp)\n\nThere's a few implementations of the WebRTC protocol, like Google's official c++ one, or a community rewrite in rust (of course). To use them, there are projects like [node webrtc](https://github.com/node-webrtc/node-webrtc), which expose a javascript API to set up webrtc connections. The issue here is that I would have to implement a lot of the handshake process myself, even if I didn't need to actual manage the packets and connection stuff myself, which is a lot of work that I rather not get caught up in.\n\n![Ugh](https://static.404wolf.com/Post-20240807145750847.webp)\n\nIt turns out that I'm not the first person who has wanted extremely low latency server based WebRTC, and there's tools that do roughly exactly what I was trying to do. There's a super cool project called [Janus Gateway](https://github.com/meetecho/janus-gateway) that is designed to be a centralized WebRTC server.\n\n![Nix to the rescue!](https://static.404wolf.com/Post-20240807145822398.webp)\n\nIt can do a ton of different things, and is a very large C project. The build process is a huge pain in the neck, but thankfully it was already packaged with `nix`, so I didn't need to deal with it.\n\nThe important thing to know about Janus Gateway is that it has a whole bunch of plugins to do common WebRtc media server tasks.\n\nThere are [a whole bunch](https://janus.conf.meetecho.com/docs/pluginslist.html) documented on their website here. Some fun ones:\n\n- **VideoCall plugin**: \"Peer to peer\" calling each other, but the data flows through Janus gateway\n- **Sip Plugin** is a plugin that abstracts authing into a SIP server and then lets you do SIP calls through the browser over WebRTC\n- **VideoRoom** is a plugin meant for many to many streaming, so like, conference calls\n- **TextRoom**, which is a plugin that deals only with WebRTC's data channel to stream raw data at very low latency over WebRTC.\n\n![Jangouts](https://static.404wolf.com/Post-20240807145842880.webp)\n\nThere's a really neat project called [Jangouts](https://github.com/jangouts/jangouts) that lets you do google hangouts style conference calling through an open source server running Janus Gateway, which is a neat showcase of the capabilities of the plugins.\n\nFinally, there's an API to create plugins for Janus Gateway in `C`, `lua`, and even `javascript`, if none of the preexisting plugins work. I think this is really neat and may return to trying out their API, or once I learn `C` write a native plugin, but for now I found what I needed: the `streaming` plugin.\n\nThe `streaming` Janus Gateway plugin lets you read prerecorded media or access prerecorded media and broadcast it over WebRTC, but, more importantly, it also lets you pass in media over [RTC](https://en.wikipedia.org/wiki/Real-time_Transport_Protocol). Here's how they word it\n\n> the plugin is configured to listen on a few ports for RTP: this means that the plugin is implemented to receive RTP on those ports and relay them to all peers attached to that stream. Any tool that can generate audio/video RTP streams and specify a destination is good for the purpose: the examples section contains samples that make use of GStreamer (http://gstreamer.freedesktop.org/) but other tools like FFmpeg (http://www.ffmpeg.org/), LibAV (http://libav.org/) or others are fine as well. This makes it really easy to capture and encode whatever you want using your favourite tool, and then have it transparently broadcasted via WebRTC using Janus. Notice that we recently added the possibility to also add a datachannel track to an RTP streaming mountpoint: this allows you to send, via UDP, a text-based message to relay via datachannels (e.g., the title of the current song, if this is a radio streaming channel). When using this feature, though, beware that you'll have to stay within the boundaries of the MTU, as each message will have to stay within the size of an UDP packet.\n\nLiterally just what I want! How convenient. But now, we have to configure it.\n\nTo say it briefly, Janus is a pain in the neck to configure. It's a monster of a project and there are a billion different options that all need to be configured correctly.\n\n## Janus Gateway\n\nWe talked about this a bit earlier, but Janus is a all in one WebRTC, so that means that it both is a \"peer\" that is sharing media, but also is the signaling server itself (the thing that tells clients to start getting content and from who).\n\nIt does the signaling through an API that it exposes, which can either be in the form of Websockets or HTTP (or both!). It also exposes a \"admin api\" that you can use to query metadata about `janus`, like\n\n### Configuring\n\nFirst things first, Janus has its own DSL for configuring it. It's not that bad, it's mostly key pair stuff.\n\nJanus provides a nice set of example configurations that have a ton of comments [on their github](https://github.com/meetecho/janus-gateway/blob/master/conf/janus.jcfg.sample.in). It's very helpful, and I would have been totally lost (well, more totally lost than the amount of totally lost that I was) had they not had example configurations.\n\nThere's a few different things we have to configure:\n\n- The signaling server that `Janus` hosts and general configuration\n- The streaming plugin itself\n- The admin server, which is a separate server for managing janus itself (getting information like what ports things are running on, statuses, etc)\n\nThere were a few manual things I had to set up for the configuration. First, I explicitly enabled the streaming plugin. I'm not entirely sure if this is necessary, but I believe it would at least give me an error if it couldn't find it, which is good.\n\n```janus\nplugins: {\n  enable = \"janus.plugin.streaming\"\n}\n```\n\nSecond, I set up an admin secret, but `janus` does have support for token auth and eventually I'll figure out how to use that. For auth, it's not well documented, but to pass the token when accessing you literally just add a `apisecret: \"secret\"` header to the request.\n\n```janus\nadmin_secret = \"secret\"\t# String that all Janus requests must contain\n```\n\nThere's also a configuration section called `media`, which seems to be where you put global media configuration settings.\n\nI'll be honest in saying I don't totally understand every setting here, but I did a lot of trial and error to figure things out. It seems pretty important to do `nack_optimizations` for this project, which significantly helped with stuttering.\n\n```janus\nmedia: {\n\t#ipv6 = true\n\t#ipv6_linklocal = true\n\tmin_nack_queue = 1200\n\trtp_port_range = \"20000-40000\"\n\tdtls_mtu = 1500\n\tno_media_timer = 2\n\tslowlink_threshold = 4\n\ttwcc_period = 100\n\tdtls_timeout = 500\n\n\t# Janus can do some optimizations on the NACK queue, specifically when\n\t# keyframes are involved. Namely, you can configure Janus so that any\n\t# time a keyframe is sent to a user, the NACK buffer for that connection\n\t# is emptied. This allows Janus to ignore NACK requests for packets\n\t# sent shortly before the keyframe was sent, since it can be assumed\n\t# that the keyframe will restore a complete working image for the user\n\t# anyway (which is the main reason why video retransmissions are typically\n\t# required). While this optimization is known to work fine in most cases,\n\t# it can backfire in some edge cases, and so is disabled by default.\n\tnack_optimizations = true\n\n\t# If you need DSCP packet marking and prioritization, you can configure\n\t# the 'dscp' property to a specific values, and Janus will try to\n\t# set it on all outgoing packets using libnice. Normally, the specs\n\t# suggest to use different values depending on whether audio, video\n\t# or data are used, but since all PeerConnections in Janus are bundled,\n\t# we can only use one. You can refer to this document for more info:\n\t# https://tools.ietf.org/html/draft-ietf-tsvwg-rtcweb-qos-18#page-6\n\t# That said, DON'T TOUCH THIS IF YOU DON'T KNOW WHAT IT MEANS!\n\tdscp = 46\n}\n```\n\n![Streaming plugin](https://static.404wolf.com/Post-20240807145901202.webp)\n\nGetting the streaming plugin working at first seemed really annoying since the plugins are all `C` files that have to be built and then placed in a specific folder on your system, which is not that portable. However, analyzing the `janus` cli (the thing you use to launch `janus gateway`), I figured out that you can set flags to specify where to look things up. Also, the `nix` build of `janus` comes with all the plugins!\n\n```bash\n$JANUS \\\n    -P \"$JANUS_INSTALL\" \\\n    -F \"$JANUS_CONFIG_DIR\" \\\n    -C \"$JANUS_CONFIG\"\n```\n\nNow these official names are really confusing. TLDR: `$JANUS_INSTALL` is the directory where the `janus` binary and plugin binaries live, `$JANUS_CONFIG_DIR` is the location where plugin configuration files go, and `$JANUS_CONFIG` is where the general configuration file goes.\n\nNow, where is Janus installed? Well, I've installed it with nix, so the location it's installed will look something like `/nix/store/jfieao...hash....fjeioa/bin/janus`, which could change and is bad practice to directly reference. Eventually, I'll generate a shell script using `pkgs.writeShellScriptBin`, where I can then reference Janus's root path in the generator for the shell script as `pkgs.janus`. To get started though, I did just do it in a janky way with `which`. I'll clean it up eventually.\n\nThe directory where `janus` lives looks like\n\n```\n/nix/store/46c284cqdgia0dxzmi8rs5vzwszxalwg-janus-gateway-1.2.3\n├── bin\n│   ├── janus\n│   ├── janus-cfgconv\n│   ├── janus-pp-rec\n│   └── mjr2pcap\n└── lib\n    └── janus\n        ├── events\n        │   ├── libjanus_gelfevh.la\n        │   ├── libjanus_gelfevh.so -> libjanus_gelfevh.so.2.0.3\n        │   ├── libjanus_gelfevh.so.2 -> libjanus_gelfevh.so.2.0.3\n        │   ├── libjanus_gelfevh.so.2.0.3\n        │   ├── libjanus_sampleevh.la\n        │   ├── libjanus_sampleevh.so -> libjanus_sampleevh.so.2.0.3\n        │   ├── libjanus_sampleevh.so.2 -> libjanus_sampleevh.so.2.0.3\n        │   ├── libjanus_sampleevh.so.2.0.3\n        │   ├── libjanus_wsevh.la\n        │   ├── libjanus_wsevh.so -> libjanus_wsevh.so.2.0.3\n        │   ├── libjanus_wsevh.so.2 -> libjanus_wsevh.so.2.0.3\n        │   └── libjanus_wsevh.so.2.0.3\n        ├── loggers\n        │   ├── libjanus_jsonlog.la\n        │   ├── libjanus_jsonlog.so -> libjanus_jsonlog.so.2.0.3\n        │   ├── libjanus_jsonlog.so.2 -> libjanus_jsonlog.so.2.0.3\n        │   └── libjanus_jsonlog.so.2.0.3\n        ├── plugins\n        │   ├── libjanus_audiobridge.la\n        │   ├── libjanus_audiobridge.so -> libjanus_audiobridge.so.2.0.3\n        │   ├── libjanus_audiobridge.so.2 -> libjanus_audiobridge.so.2.0.3\n        │   ├── libjanus_audiobridge.so.2.0.3\n        │   ├── libjanus_echotest.la\n        │   ├── libjanus_echotest.so -> libjanus_echotest.so.2.0.3\n        │   ├── libjanus_echotest.so.2 -> libjanus_echotest.so.2.0.3\n        │   ├── libjanus_echotest.so.2.0.3\n        │   ├── libjanus_nosip.la\n        │   ├── libjanus_nosip.so -> libjanus_nosip.so.2.0.3\n        │   ├── libjanus_nosip.so.2 -> libjanus_nosip.so.2.0.3\n        │   ├── libjanus_nosip.so.2.0.3\n        │   ├── libjanus_recordplay.la\n        │   ├── libjanus_recordplay.so -> libjanus_recordplay.so.2.0.3\n        │   ├── libjanus_recordplay.so.2 -> libjanus_recordplay.so.2.0.3\n        │   ├── libjanus_recordplay.so.2.0.3\n        │   ├── libjanus_sip.la\n        │   ├── libjanus_sip.so -> libjanus_sip.so.2.0.3\n        │   ├── libjanus_sip.so.2 -> libjanus_sip.so.2.0.3\n        │   ├── libjanus_sip.so.2.0.3\n        │   ├── libjanus_streaming.la\n        │   ├── libjanus_streaming.so -> libjanus_streaming.so.2.0.3\n        │   ├── libjanus_streaming.so.2 -> libjanus_streaming.so.2.0.3\n        │   ├── libjanus_streaming.so.2.0.3\n        │   ├── libjanus_textroom.la\n        │   ├── libjanus_textroom.so -> libjanus_textroom.so.2.0.3\n        │   ├── libjanus_textroom.so.2 -> libjanus_textroom.so.2.0.3\n        │   ├── libjanus_textroom.so.2.0.3\n        │   ├── libjanus_videocall.la\n        │   ├── libjanus_videocall.so -> libjanus_videocall.so.2.0.3\n        │   ├── libjanus_videocall.so.2 -> libjanus_videocall.so.2.0.3\n        │   ├── libjanus_videocall.so.2.0.3\n        │   ├── libjanus_videoroom.la\n        │   ├── libjanus_videoroom.so -> libjanus_videoroom.so.2.0.3\n        │   ├── libjanus_videoroom.so.2 -> libjanus_videoroom.so.2.0.3\n        │   └── libjanus_videoroom.so.2.0.3\n        └── transports\n            ├── libjanus_http.la\n            ├── libjanus_http.so -> libjanus_http.so.2.0.3\n            ├── libjanus_http.so.2 -> libjanus_http.so.2.0.3\n            ├── libjanus_http.so.2.0.3\n            ├── libjanus_pfunix.la\n            ├── libjanus_pfunix.so -> libjanus_pfunix.so.2.0.3\n            ├── libjanus_pfunix.so.2 -> libjanus_pfunix.so.2.0.3\n            ├── libjanus_pfunix.so.2.0.3\n            ├── libjanus_websockets.la\n            ├── libjanus_websockets.so -> libjanus_websockets.so.2.0.3\n            ├── libjanus_websockets.so.2 -> libjanus_websockets.so.2.0.3\n            └── libjanus_websockets.so.2.0.3\n```\n\nSo to reference the plugins in the correct places I can write a bash script that uses `janus` like this\n\n```bash\necho \"Starting janus in $PWD\"\nCONFIGS=./src/janus/configs\nJANUS_INSTALL=$(dirname \"$(dirname \"$(which janus)\")\")\necho \"$JANUS_INSTALL\"\njanus -P \"$JANUS_INSTALL/lib/janus/plugins\" -F \"$CONFIGS\" -C \"./src/janus/janus.jcfg\"\n```\n\n`dirname` just gets the directory something is located in, so I'm effectively hopping two directories up.\n\nOnce I was able to load the `streaming` plugin, I then had to configure it. They have this [handy example](https://github.com/meetecho/janus-gateway/blob/master/conf/janus.plugin.streaming.jcfg.sample.in) of various streaming plugin setups for different use cases.\n\nThe first example that called out to me is this one:\n\n```\n# This is an example of an RTP source stream, which is what you'll need\n# in the vast majority of cases: here, the Streaming plugin will bind to\n# some ports, and expect media to be sent by an external source (e.g.,\n# FFmpeg or Gstreamer). This sample listens on 5002 for audio (Opus) and\n# 5004 for video (VP8), which is what the sample gstreamer script in the\n# plugins/streams folder sends to. Whatever is sent to those ports will\n# be the source of a WebRTC broadcast users can subscribe to.\n#\nrtp-sample: {\n\ttype = \"rtp\"\n\tid = 1\n\tdescription = \"Opus/VP8 live stream coming from external source\"\n\tmetadata = \"You can use this metadata section to put any info you want!\"\n\taudio = true\n\tvideo = true\n\taudioport = 5002\n\taudiopt = 111\n\taudiocodec = \"opus\"\n\tvideoport = 5004\n\tvideopt = 100\n\tvideocodec = \"vp8\"\n\tsecret = \"adminpwd\"\n}\n```\n\nSince it claims to do exactly what I want: stream media over RTP.\n\nOkay, so now I just place all the `janus` configurations into the right spots, run `janus` using my hacky `bash` script, and pray it works.\n\nIt didn't at first, or for the first day of trying to get it to, but eventually I got it to a functional state where janus would at least run.\n\nNow what? I'm not streaming media, but now I _can_ stream through RTP on localhost.\n\nThe next step was to figure out how to **connect** to `janus`, which is totally a pain in the neck and nontrivial.\n\n## Browser again\n\nModern browsers are designed to support WebRTC connections. They provide an API that you can use to create `PeerConnections`, do handshaking, set up media streams, and all that fun stuff.\n\nIt looks something like this (signalingServer is a websocket server)\n\nNote that this example is ai-written/modified, since it's a very minimal short example of what you'd do to get webrtc working.\n\nICE is a network technique to establish peer to peer connections while going through some central server (google hosts a commonly used one).\n\n```typescript\n// 1. Create peer connection\nconst pc = new RTCPeerConnection();\n\n// 2. Create and set local description\nconst offer = await pc.createOffer();\nawait pc.setLocalDescription(offer);\n\n// 3. Send offer to remote peer (via signaling server)\nsignalingServer.send(JSON.stringify(offer));\n\n// 4. Receive answer from remote peer\nsignalingServer.onmessage = async (event) => {\n  const answer = JSON.parse(event.data);\n  await pc.setRemoteDescription(answer);\n};\n\n// 5. Exchange ICE candidates\npc.onicecandidate = (event) => {\n  if (event.candidate) {\n    signalingServer.send(JSON.stringify(event.candidate));\n  }\n};\n\n// 6. Handle incoming ICE candidates\nsignalingServer.onmessage = async (event) => {\n  const iceCandidate = JSON.parse(event.data);\n  await pc.addIceCandidate(iceCandidate);\n};\n\n// 7. Handle getting streams\npc.ontrack = (event) => {\n  const [remoteStream] = event.streams;\n  console.log(\"Received remote stream\", remoteStream);\n  // Use the remoteStream, e.g., attach it to a video element\n  const videoElement = document.querySelector(\"#remoteVideo\");\n  videoElement.srcObject = remoteStream;\n};\n\n// 8. Connection established\npc.onconnectionstatechange = (event) => {\n  if (pc.connectionState === \"connected\") {\n    console.log(\"WebRTC connection established!\");\n  }\n};\n```\n\nIn this case though, I didn't actually create the websocket server, and `janus`'s is much more complicated than this. It isn't a matter of just accepting the first message received, but rather `janus` requires you actually have a \"conversation\" and tell it what you want -- you ask for a list of streams, choose one by id, etc, all while sending heartbeats. It's annoying to work with, but they provide a [`javascript` sdk](https://www.npmjs.com/package/janus-gateway) with type declarations.\n\n### A Little React\n\nTo procrastinate figuring out how to use their sdk, I started off by setting up a super simple `vite` `react` app so that I could nicely abstract things.\n\nI learned a bit about `vite` here, since I hadn't used it before. It seems like vite's entrypoint is an `index.html` file that looks something like\n\n```html\n\u003Cbody>\n  \u003Cdiv id=\"root\">\u003C/div>\n  \u003Cscript type=\"module\" src=\"/src/main.tsx\">\u003C/script>\n\u003C/body>\n```\n\nWhere vite hosts a server, and then automatically intercepts requests for `/src/main.tsx` and serves a `javascript` bundle (which it can prebuild or dynamically generate).\n\nI found this [random helpful example](https://github.com/LorisGiann/simple-janus-streaming-client/blob/master/streamingtest.js) usage that was pretty helpful for figuring out how to interface with `janus`.\n\nReact [hooks](https://react.dev/reference/react/hooks) are ways to move logic away from your components so that you can reuse logic. The difference between hooks and regular functions is that you can use `hooks` within `hooks`, so, like, hooks can call `useState` to maintain their own states.\n\nThe way you define a hook is by placing it in a file with the `use` prefix, and then provide a function as a default export. So like, in my case, `useJanusStream.ts` and `export default function useJanusStream`.\n\nIn that function body we can use hooks like `useState`. Okay, so let's start writing the logic for connecting to `janus` and getting a stream into a `\u003Cvideo>` element\n\n[There are docs](https://janus.conf.meetecho.com/docs/JS.html) on their javascript sdk, but it's kinda awful to work with. It sends all the right `api` requests and works well enough, but it was implemented before `const` and `async/await`, so it's full of callbacks and is awful to deal with.\n\nTo start, we `init` `Janus`, which is already kinda yucky -- we're setting a global state of how `Janus` is to behave.\n\n```typescript\nJanus.init({\n  debug: true,\n  dependencies: Janus.useDefaultDependencies({ adapter }),\n  callback: () => {\n```\n\nWe get the `adapter` with `import adapter from \"webrtc-adapter\"`, which is from [here](https://www.npmjs.com/package/webrtc-adapter). It's a common package that exposes the `WebRTC` api in a browser agnostic way.\n\nOkay, now we instantiate a new Janus (yes, init just set a global config state, it didn't actually create a connection or anything like that)\n\n```typescript\nconst janus = new Janus({\n    server: servers, // a list of websocket/http server IPs (of janus servers)\n    apisecret: \"secret\",\n    success: () => {\n```\n\nAnd, once the Janus gets created we handle the success with\n\n```typescript\njanus.attach({\n    plugin: \"janus.plugin.streaming\",\n```\n\nThis attaches the streaming plugin, which makes an api request that asserts that there is a streaming plugin running on the `janus` server, and then (as usual) has a callback for once the assertion is done...\n\n```typescript\nsuccess: (receivedStreamingPluginHandle) => {\n  console.debug(\"Got streaming plugin information\");\n  streamingPluginHandle = receivedStreamingPluginHandle;\n  console.debug(\"Requesting stream from plugin\");\n  streamingPluginHandle.send({\n    message: { request: \"list\" },\n    success: (list: any) => {\n      console.debug(\"Listed!\", list);\n    },\n  });\n  streamingPluginHandle.send({\n    message: { request: \"info\", id: 1 },\n    success: (info: any) => {\n      console.debug(\"Got info\", info);\n    },\n  });\n  streamingPluginHandle.send({\n    message: { request: \"watch\", id: 1 },\n    success: (resp: any) => {\n      console.debug(\"Resp\", resp);\n      console.debug(\n        \"Watching stream success. Now waiting to start stream.\",\n      );\n    },\n  });\n},\n```\n\nOnce it is ready, we ask for a list of streams (to log, for debugging purposes for now), we get information on the stream that should be the one we are going to connect to, and then we ask to watch the stream.\n\nThat last step is the tricky part -- in order to obtain a `MediaStreamTrack`, which is just raw video/audio, which we can create a `MediaStream` from, which can be slotted into a `\u003Cvideo>` element, we need to ask `janus` to send us the stream, and define a callback for once it's done so.\n\nBefore it can send the stream, it'll ask to do an auth handshake, which\n\n```typescript\nonmessage: (msg, jsep) => {\n  console.debug(\"Received msg from Janus server\", msg, jsep);\n  if (streamingPluginHandle === null) return;\n  if (jsep === undefined) return;\n  console.debug(\"Received JSEP!\", jsep);\n  console.debug(\"Answering the JSEP request.\");\n  streamingPluginHandle.createAnswer({\n    jsep: jsep,\n    media: { audioSend: false, videoSend: false },\n    success: (jsep: any) => {\n      console.debug(\"Successful SDP answer created\");\n      let body = { request: \"start\" };\n      streamingPluginHandle.send({ message: body, jsep: jsep });\n    },\n    error: (error: any) => {\n      console.error(\"WebRTC Error:\", error);\n    },\n  });\n},\n```\n\nJSEP's a complicated handshake that goes on to establish a `webrtc` connection. It's mostly abstracted away from us.\n\nOnce the handshake is done, we just define a `onRemoteTrack` function for when the `MediaTrack` is ready.\n\n```typescript\nonremotetrack: (track: MediaStreamTrack) =>\n    onReceivedMediaTrack(track),\n```\n\nThen we have a `MediaStreamTrack`, which is a \"container\" of sorts for the inbound video stream. We can attach it to our `\u003Cvideo>` element by creating a `MediaStream` with it. A `MediaStream` is a collection of tracks -- so, like, audio and video, for example.\n\nIt looks something like this...\n\n```typescript\nconst setupStream = () => {\n  if (videoPlayer.current && mediaStreamTrack.readyState === \"live\") {\n    const newMediaStream = new MediaStream();\n    newMediaStream.addTrack(mediaStreamTrack);\n    videoPlayer.current.srcObject = newMediaStream;\n  }\n};\n```\n\n`MediaStreamTracks` have a enum for their readyState, so if it's \"live\" (video is streaming), then create a `MediaStream` with the track, and then set our video element (which we can grab with a selector, or, in this case, a `useRef`)'s srcObject (what it's playing) to the track we just received.\n\nOkay, so I implemented all of this, and, to put it briefly, it did connect, but no video would play.\n\n### Video Encoding Transcoding\n\nThe next major obstacle\n\n![Your tab crashed!](https://static.404wolf.com/Post-20240807145930075.webp)\n\n![NALUs](https://static.404wolf.com/Post-20240807145949240.webp)\n\n# Other Cool Things\n\n![RobotNix](https://static.404wolf.com/Post-20240807144559741.webp)","src/posts/AndroidInTheBrowser.mdx","e7706d70ccc739a5","cwrufreefoodfinder",{"id":52,"data":54,"body":60,"filePath":61,"digest":62,"deferredRender":26},{"title":55,"type":15,"date":16,"covers":56,"tags":58,"description":59},"CWRU Free Food Finder",[57],"https://static.404wolf.com/Screenshot_from_2024-03-28_23-28-45_0001.png",[20,21],"For Case Western's 2024 hackathon two friends and I built a webapp for locating free food on our campus. We used a fine tuned OpenAI model to read all events from our university's event management system and determined whether they had food, of what type, and to generate other metadata. We then displayed this data on a appealing MUI-React UI, and set up a deployment at free-cwru-food.404wolf.com! We added various additional features like a calendar integration, and have continued to improve the site.\n","# [The Website](https://free-cwru-food.404wolf.com)\n\n![Main website](Screenshot_from_2024-03-25_13-20-22_0001.png|float=none|width=80)\n\nFor Case Western's 2024 hackathon two friends (Mars and Mark) and I got together and built a webapp for locating free food on campus. We used a fine tuned OpenAI model to read all events on our universities event management service page and determine whether they had food, of what type, and to generate other metadata. We then displayed this data on a appealing MUI-React UI, which can be found at **[free-cwru-food.404wolf.com](https://free-cwru-food.404wolf.com)**. The github is located [here](https://github.com/404Wolf/Food-Finder).\n\nUpdate (2/2025): CampusGroups seems to have made a change that broke our web scraping logic. This will be fixed but currently the website will not show many or any events.\n\n## Inspiration\n\nThough we were not supposed to begin working on our hackathon project before the official start time, we did decide to meet to brainstorm for the project a bit ahead of time. The two friends I teamed up with had previously worked on a separate hackathon at WashU to create an app for automatically registering for classes as spots opened up. Taking inspiration, we also wanted to work on a project that interfaced with some campus service to make it better and easier to use, but weren't sure which. We knew it'd need to be something that had an obvious and applicable use case, and something vague enough that we could make it more prompt-specific when the hackathon were to actually start.\n\n![CampusGroups events](https://static.404wolf.com/Screenshot_from_2024-03-28_23-28-45_0001.png)\n\nAs we brainstormed, we came up with a list of a few campus services that we could extend. Canvas is our school's portal for classes -- course announcements, grading, etc. We thought of adding a \"Submit to Canvas\" button Google Docs extension, or a \"scheduled submit\" option for Cavnas. I proposed the idea of making a syllabus scanner to find easy important details on each classes' syllabus. Eventually, we decided on creating some sort of analysis tool for our school's event management system CampusGroups. CampusGroups is a great platform for garnering all events happening on campus, but it can be a bit intimidating and confusing to filter through all the events.\n\nWe thought that, since we'd be heavily constrained on time, we would start with something more simple and constrained, which is when I came up with the specific idea of filtering for events that had food. Funny as it may be, free food is a big motivator for college students everywhere, including Case. Wouldn't it be great to have a website that analyzes the descriptions of all events on campus and screens for the ones that have free food? So that's just what we did.\n\n# Making it\n\n## Prompting\n\nFor the actual event's prompt, it was an AI based theme. The track we participated in was the \"maker\" track. We thought that our choice to use AI as an analysis tool would fit well with the prompt.\n\n> Prompt: Welcome to the AI-Powered Innovation Challenge, where visionaries and trailblazers converge to harness the transformative potential of Artificial Intelligence (AI). In this Hackathon's Innovation Track, your goal is to leverage AI technologies to pioneer groundbreaking solutions that address real-world challenges and propel us into a future defined by innovation. Imagine a world where AI is not just a tool but a catalyst for unprecedented innovation across all sectors. Your mission is to conceptualize and develop a project that embodies this vision, pushing the boundaries of what's possible with AI-driven innovation. Whether it's revolutionizing industries, improving societal well-being, or enhancing human capabilities, let AI be the engine driving your creative and innovative endeavor.\n\nWhen we outlined the project, we decided on a few core features, and since then, we've added some more. To start, we made the main page of the website a grid of events that each had free food. Since CampusGroups does have its own proper event registration system, and some events require registration, we knew that we'd want a way for people to easily access the actual CampusGroups page, so we made the tiles clickable links. Because of this, we thought it'd be okay to truncate the descriptions and information about the event, since the event tiles would serve primarily as information about the food content of the event.\n\nOur goal was to provide food-centric event information, so we spent some time brainstorming what food-related information we could feasibly gather from event descriptions, and that would be useful. We decided that the cuisine of the food would be most important, and then for fun also added an AI generated rating of the food. Since we noticed that there are a lot of food-drive type events, we also added a flag for whether the event was a volunteering event (so, not really free food for the taking).\n\n## How it works\n\nThe project's basic structure is as follows: we have a user facing frontend, which is a `react` based website, which hooks into a database that has all the food-related events. Every 5 days an automatic `google run` lambda is run to fetch new events. Below are some more specific details about the innerworkings.\n\n## Frameworks\n\n![Cloud run logs fetching events](https://static.404wolf.com/Screenshot_from_2024-03-29_01-44-19_0001.png)\n\nWe also decided early on on the tools that we wanted to use -- mostly typescript ones :).\n\nWe decided that it'd be easiest to use react for our frontend, and to integrate a backend with `nextjs`. nextjs is a super cool framework that is sort of like `create-react-app` in that it bootstraps the `react` project creation process, but unique in that it adds many of its own abstractions like powerful server side components and \"server actions\" for running code server side, and sets up directory based routing. Next does SSR and handles hydration for you. It lets you write API routes in the same folder and even files as your `react` UI code, which makes it super easy to rapidly develop a webapp. And, [Vercel](https://vercel.com/) , the company that maintains it, offers free hobbist hosting in a way that's very convenient, including setting up CI.\n\nI wrote most of the frontend of the app, and to get a nice looking UI up and running quickly, decided to use react material UI (`MUI`), and `tailwindcss`. MUI provides a bunch of premade components that work and look nice out of the box, and tailwind lets you customize styles with simple classes, much like bootstrap, but with more flexibility.\n\nFor our database to store the events, we chose to set up a free tier `MongoDb` database, since, besides being free, we'd still be prototyping the app as we were building it. Being able to not have to worry much about migrations or constantly updating a schema would be very helpful. We used the default `MongoDb` client instead of bothering to learn and implement `mongoose` (schema enforcement for `MongoDb` for `Typescript`), and just wrote our out `Typescript` interfaces to prevent typing issues.\n\n## Getting the Events\n\nOne of the first challenges we had to tackle was actually going about getting a listing of all the CampusGroups events from a script without a webpage. After some exploring I found that the `ical` integration that CampusGroups offers to add events to your calendar had most of the descriptions in it too! By just fetching [the ical](https://community.case.edu/ical/ical_cwru.ics) from CampusGroups we were most of the way there.\n\nHowever, the public URL fails to include some important information about the event; namely, the location for most events is hidden. To solve this issue, I wrote a basic script that uses a headless chromium browser to fetch an auth token, which we use to make authed requests to CampusGroups to get information like event location.\n\n```ts\nasync function getAuthHeaders(caseId: string, casePassword: string) {\n  const browser = await puppeteer.launch({\n    headless: true,\n    args: [\"--no-sandbox\"],\n    ignoreDefaultArgs: [\"--disable-extensions\"],\n  });\n  const page = await browser.newPage();\n\n  await page.goto(\"https://login.case.edu/cas/login\");\n  await page.type(\"#username\", caseId);\n  await page.type(\"#password\", casePassword);\n  await page.click('input[name=\"submit\"]');\n\n  await page.goto(\"https://www.campusgroups.com/shibboleth/login?idp=cwru\");\n  await page.waitForSelector('[id=\"button-menu-mobile\"]', { timeout: 100000 });\n  await page.goto(URL);\n\n  const cookies = await page.cookies();\n  const headers = {\n    Cookie: cookies.map((ck) => `${ck.name}=${ck.value}`).join(\"; \"),\n  };\n  await browser.close();\n\n  return headers;\n}\n```\n\n## Screening Events\n\nTo screen all the events and populate the database with the events that had food and the metadata about the food, we decided to use an OpenAI fine tuned model. The idea behind a fine tuned model is that you take a base model from OpenAI, like GPT3 (regular tier chat GPT at the time of writing), and then feed it a bunch of example inputs and outputs, like so.\n\n```json\n{\n        description:\n            \"Join the African Student Association at our annual Karaoke event, Battle of the Mics, where you can watch and/or sing your favorite African songs, from Afrobeats to Amapiano! Enjoy lighthearted competition, great music, delicious food, and an incredible time to start off the spring semester.\",\n        rating: \"7\",\n        cuisine: \"Cultural\",\n        volunteer: \"false\",\n        onCampus: \"true\",\n    },\n    {\n        description:\n            \"Join us for Grind training on the FAB floor at think[box]. Proper PPE is Required [short sleeves, long pants, close-toed shoes, hair tied back, no jewelry An ability badge is required to complete this training. If you do not yet have an ability badge, you will need to complete a 15-minute safety tour prior to your training time\",\n        rating: \"0\",\n        cuisine: \"None\",\n        volunteer: \"false\",\n        onCampus: \"true\",\n    },\n    {\n        description:\n            \"Brew CWRU is hosting a field trip to Cleveland's very own Phoenix Coffee Co's HQ in downtown Cleveland! During this field trip, Phoenix Coffee's director will take us through various processes of QA/QC in specialty coffee including cupping, roasting, and dialing in a coffee recipe. Spots are limited due to transportation, so make sure you can commit to the registration and do not miss out on this amazing opportunity!\",\n        rating: \"4\",\n        cuisine: \"Beverages\",\n        volunteer: \"false\",\n        onCampus: \"false\",\n    },\n```\n\nThen you run a \"training\" session, which cost us only about $2, and you can use the fine tuned model by referencing its id as a model for OpenAI requests, in conjunction with a prompt, like this:\n\n```ts\nconst completion = await openai.chat.completions.create({\n  messages: [\n    {\n      role: \"system\",\n      content: `Your job is to read the description of a student-run event located at a local university, and determine whether the event provides food or not to people attending the event. You are also tasked with rating the food on a scale from 1 to 10, with 1 representing cheap canned food and 10 representing a fully prepared feast. If no part of the event mentions food, rate the food a 0. If there is food mentioned at all, give it at least a rating of 1, and at most a rating of 10. If there is food provided, to classify what cuisine the food is, which MUST be one of the following values: Pizza, Beverages, Cultural, Healthy, Sweets, Unknown, and None. Additionally, indicate whether this event is for volunteers or is offering food to the community. If it is, say true, otherwise if it is not or if taking food, say false. Additionally, indicate whether the location is on the university campus, or requires traveling off campus, also true or false (say true if it is unknown). Output each of these fields in a JSON object with the fields \"rating\", \"cuisine\", \"volunteer\", and \"onCampus\" \n                    \n                    Make sure that if there is food mentioned in the description that the rating is not a 0. Give a rating of 0 only if the event will not have any food.`,\n    },\n    { role: \"user\", content: description },\n  ],\n  model: FINE_TUNED_MODEL,\n});\n```\n\nUsing the OpenAI API is basically like simulating a user interaction with ChatGPT, but a bit more customization. What's super cool is that the AI gives us a `json` formatted response consistently and always in the right shape. I doubted the safety of this, but OpenAi's own documentation notes that this is a good method for this sort of thing.\n\nWe packaged this scanning system into a library that I then dockerized, and deployed to a Google cloud run lambda. I set it up to run every 2 days, so that events consistently get added to the database.\n\n## Finishing Touches\n\n![Mobile website](Screenshot_from_2024-03-25_13-21-22_0001.png|width=30)\n![Google calendar integration](https://static.404wolf.com/Screenshot_from_2024-03-25_13-22-03_0001.png)\n\nTo finalize the website, I added a few neat additional features. I added a [ical integration](https://www.npmjs.com/package/ical-generator) that lets you add all food events to your iCal supported calendar (like google calendar), and an add to Google Calendar link (if you click on the dates on any of the tiles it should take you to a pre-filled Google Calendar link). Getting Google Calendar template links to work was super cool, it's just a `url` template:\n\n```\n`https://www.google.com/calendar/render?action=TEMPLATE&text=${escapedName}&details=${escapedDescription}&location=${escapedLocation}&dates=${formattedDate}/${formattedEndDate}`;\n```\n\nI also added a filtering system, which initially was client side, but I moved to the backend to reduce client strain and bandwidth. I added basic Vercel analytics to the website, and have been improving the mobile UI too.\n\nAfter the hackathon we've done some optimization, improved event fetching concurrency, and in general cleaned up the UI a bit. I also added skeletons to the website for the loading screen, since the website dynamically loads.\n\n# Results\n\nIn the end, we presented to a panel of 5 judges, and came in first for the event. We had a fully completed webapp with a deployment and mobile UI, and overall I was very happy with how things turned out. It was a great experience, we learned a lot about OpenAI's fine tuning API, MUI, and the other frameworks we used. It was my first time using Mongo, and the flexibility it offered really was great. I look forward to hopefully participating in other hackathons down the line!\n\nFor some additional things that I'd like to look into adding, I'm considering adding Case SSO for getting more intimate event details like location, along with adding an email attendees button. Case SSO is technically not open source, but the system that Case uses is a common Java framework and getting the auth token from a redirect isn't hard. Retuning the model to have better training data, and also adding more information to the event tiles about the food itself would be nice to do as well.","src/posts/CWRUFreeFoodFinder.mdx","dc68a96bd5a9aca1","coinsortbot",{"id":63,"data":65,"body":73,"filePath":74,"digest":75,"deferredRender":26},{"title":66,"type":15,"date":16,"covers":67,"tags":71,"description":72},"Coin Date Sorting Robot",[68,69,70],"https://static.404wolf.com/sideViewWithRamp_0001.png","https://static.404wolf.com/frontView_0001.png","https://static.404wolf.com/wiresOnTable_0001.png",[21,20],"Coin-sort-bot is a physical robot that I co-designed and wrote software for to automatically align and sort coins based on their physical features like year, date, and mint location. It is designed mostly with fusion360 for CAD and Python driver software, and is an IOT device that connects to a separate Django webserver. It is still in development, and currently has a basic 3d printed prototype and driver software to control the hardware.\n","# Inspiration\n\n![Coin scanner app images](https://static.404wolf.com/Screenshot_2024-02-05_151340_0001.png)\n\nA while back I was sifting through some older coins that my grandma had saved from many years ago, looking up their values one by one, and knew there had to be a better way. Some coins have collector value based how many were made that year, the denomination and composition, and various other factors. For example, some copper pennies from WW2 are worth a significant amount because most pennies then were made from zink.\n\nLooking at \"coin identifying\" apps on the app store, I found that there were already various different apps to identify coins, which acted as essentially a specialized reverse image search. They were all proprietary though, and I couldn't find a good API for the process.\n\nAdditionally, though these apps presented a software solution to make manually sifting through the coins more streamlined, I still found it tedious to have to lay down each coin on the table one by one, and snap photos of each side.\n\nI decided then, that, in addition to making a tool like that of the apps to convert an image of the coin to a dollar valuation, it would also be handy to have a robot lay out the coins, and physically move the coins into appropriate rolls based on their year and/or value.\n\n## Think\\[box] Grant\n\nAt my university (Case Western) there is a campus makerspace called \"Thinkbox.\" Each year they award various project ideas up to $2.5k to bring the ideas to fruition, through the [Thinkbox project fund](https://case.edu/thinkbox/funding/student-project-fund). Their grant page lists projects eligible as ones that are:\n\n- Individual and team-based extracurricular and personal projects.\n- Projects related to a competition.\n- Entrepreneurial projects that require prototypes.\n\nWhich my automatic coin sorter was a perfect match for. I applied for the grant, writing up the concept and creating a list of materials that I thought we'd need for the robot, like 3d printer filament, cameras, various sensors, and a raspberry pi. I invited a friend to help join me for the project, thinking that two people would increase the chance of approval. After a few weeks, we were approved for a $650 grant! I began ordering supplies, and started learning CAD and planning.\n\n### Senior project fair\n\n![Coin identifyer senior project](https://static.404wolf.com/coinSorterSeniorProject_0001.JPG)\n![Coin identifyer senior project](https://static.404wolf.com/secondPosterImage_0001.jpg)\n\nTowards the end of my first semester, I attended our senior project fair, and, after hearing from my logic design professor about the projects her students were working on, decided to check them out. It turned out that there were some groups in our electrical engineering department working on designing the software for identifying coin years and denominations, which was very similar to what I was working on. I noted their contacts at the time, and plan on reaching out when we get around to actually implementing the image identification for the device.\n\n# The project\n\n## Parts & Design\n\n[Coin aligner mechanism](https://static.404wolf.com/sideViewWithPie_0001.webp)\n[Coin chute component](https://static.404wolf.com/coinChuteUnit_0001.webp)\n\nEarly on we decided to make the project mostly 3D printed, to make fabrication simple so that we could focus on the design of the bot. The primary components of the coin sorting machine are the main tub where the input coins go, the alignment system, and the chute which dispenses the coins into coin rolls (a unique facet of our design, where we decided we'd let hang off the table).\n\nA lot of the initial steps for the process were drafting ideas on paper, trying to figure out an efficient way to sift through the coins while also taking photos of each side of every coin so that we could do processing. This turned out to be very tricky, since we wanted something that would be as foolproof as possible and wouldn't have a chance of jamming, since eventually we wanted to sift through very large amounts of coins.\n\nMost of the components 3D printed were designed in Fusion360, because of how easy it is to collaborate, but also because I liked the interface. Being able to parameterize parts has been super helpful; for example, the funnel that the coins fall into that has a coin roll in it can be generated for any type of coin by simply changing the coin diameter value, and everything updates to make it work.\n\nWe got Servos and most of our other parts through Adafruit. Adafruit makes coding for their controller boards super easy by providing libraries that 'just work.' Check out their motor controller board example code, for example...\n\n```py\nfrom adafruit_motorkit import MotorKit\n# Initialise the first hat on the default address\nkit1 = MotorKit()\n# Initialise the second hat on a different address\nkit2 = MotorKit(address=0x61)\n```\n\nWhat _was_ annoying, however, was getting RPIO (the interface that lets you use the raspberry pi hardware via Python) to work on my local machine for testing. What I figured out, however, is that I could remotely program to the Pi over SSH using either a VSCode remote development extension, or, Jetbrain's remote interpreter. With their remote interpreter add on, the code would automatically get shipped to the Pi's temp folder, and then would be executed on board, even though I'd be coding directly on my own computer. Now that I'm more into vim I probably could just do onboard development over ssh, though, which would be most ideal.\n\n![Coinbot discord IP finder](https://static.404wolf.com/coinbotDiscord_0001.png)\n![Tailscale dashboard](https://static.404wolf.com/tailscaleDashboard_0001.png)\n\nTo network to the Pi, originally I set up a simple cron job to automatically discord message me (using a discord webhook) the local IP of the device. However, configuring the IP address every time to be different was very annoying. Thankfully, I had recently learned about [tailscale](https://tailscale.com/), which has been absolutely amazing and seamlessly let me hook up the Pi (along with all of my other devices) to a secure personal virtual network. To install tailscale on the Pi, it was as simple as a single `curl` command.\n\n![Digital microscope coin image](https://static.404wolf.com/microscopeImage_0001.jpg)\n\nFor the main board, we decided to go with a $50 Raspberry Pi 4 (which we were able to obtain from Adafruit quite easily), and for the electronics, we got 2 digital microscopes. The main issue with the cameras we got is that they need to be about 9 inches away from the coin to focus properly, but 3D printing a tube to hold them out at the proper distance should solve the problem. We purchased two LED lights to illuminate the sides of the coins, though we realized after receiving the cameras that they themselves also have lights built in. And, finally, we got 16 servos for controlling where to place the coins, along with a servo and motor controller.\n\n![Motor controller](https://static.404wolf.com/motorHat_0001.jpg)\n![Servo controller](https://static.404wolf.com/servoControlled_0001.png)\n\nThe controllers were annoying to set up since they are designed to be \"HATs\" for the raspberry pi - that is, they are meant to literally sit on top of the board. To use multiple of them they had to be addressed (soldering binary IDs onto pads on the tops of them), and then right angle extenders needed to be soldered onto the bottom servo hat to allow the wires to stick out for the servos.\n\n## Initial design\n\n![Coin sorter inspiration](https://static.404wolf.com/ElectricSorterLowAngleCoins061617_0001.jpg)\n\nFor the during school year portion of the project, I decided to work specifically on the hardware portion of the project, and am planning to work on the software over the summer. For now, we started off by working on how we would align the coins so that we could photograph them, process them, and then move the coins to proper output coin rolls.\n\n![Coins on rubber wheel](https://static.404wolf.com/coinsOnRubber_0001.jpg)\n![Rubberized wheel](https://static.404wolf.com/rubberizedWheel_0001.jpg)\n\nWe took inspiration from the a classic metal coin sorter with a rotated wheel, which the coins friction slide along as the wheel rotates and eventually dispenses them aligned onto a track by stripping them off the wheel. After a lot of experimentation, we designed something similar for use with a stepper motor, which we 3D printed. What's cool about stepper motors is how precise control we'd have over them; it may not have been necessary for this project, but it wouldn't hurt to have the extra torque and speed. During one day while working on the project, I came across some rubber sheeting that was being discarded, and decided to also lasercut that and apply it to the wheel to add friction for the coins.\n\n![The original \"drum to chute\" design](https://static.404wolf.com/Screenshot_from_2024-04-25_23-56-45_0001.png)\n\nThe next step for the spinning drum design was to \"slice\" the coins off the spinning wheel so that they could fall into a chute. We added a nib affixed to the side of the wheel to redirect the coins, and then added a pathway to allow the coins to eventually fall into a chute where we could then use servos to move them into view of a camera, and then, afterwards, separate them.\n\n![Beam break sensor](https://static.404wolf.com/2168-04_0001.jpg)\n\nWe quickly realized, though, that it was entirely possible that multiple coins could end up on top of one another in the chute, and that multiple coins could jam the system. The issue was that, while only one coin could \"cling\" to the rubber at a time, the coins could fall one after another if the wheel were continuously spinning, allowing coins to drop faster than we could process them. We thought one good solution to this problem would be to use a beam break sensor, and so we ordered [this one](https://www.adafruit.com/product/2168) from Adafruit. But before we even tested it, we realized that adding a new chamber to limit the flow of coins would be a whole new challenge in it of itself.\n\n![The chute](https://static.404wolf.com/Screenshot_from_2024-04-25_23-55-17_0001.png)\n\nWe decided to take a break from the drum design, and move on to designing the actual chute that the channel would eventually connect to. The idea was that there would be many chutes stacked on top of each other, and we'd know which coin was falling ahead of time. We could have a single chute have its respective servo move into position so as to _redirect_ the current falling coin into a funnel, which would have an output coin roll in it. The system was very vertical, and would hang off the edge of the table, using gravity to move the coins along.\n\nThis system worked great! The servo was able to redirect the coin into the funnel, and the coin nicely fell into the bulbous shape of the funnel and aligned itself atop the other coins in the coin roll in the funnel. This system worked so well, in fact, that it inspired us to completely redesign our robot, and move away from the spinning drum method.\n\n## Redone design\n\n![New design dispensing coins one at a time](https://static.404wolf.com/IMG_8408_0001_0001.webm)\n\nInstead of having a spinning drum with room for multiple coins to be dispensed at a time, we spent a while planning out new ideas, and came up with a different system that could allow a rotating motor arm to skimp off one coin at a time from a slightly elevated tube with a gap the size of a coin at the bottom. We reused the funnel design, but this time the funnel would redirect the coin into the chute. We considered that multiple coins could have different thicknesses, with some being even twice as thick as others (e.g. nickles and dimes), so we made the tube screw on to the main platform holding the controller, motor, platform, and funnel.\n\n![New design CAD](https://static.404wolf.com/Screenshot_from_2024-04-26_00-06-42_0001.png)\n\nThe new design clamps on to the corner of a table, and the actual sorting chute is completely vertical. A friend mentioned that we could have it be at a slight diagonal to allow it to be slightly longer (since we're restricted to the height of the table), which is something we may consider later.\n\nFor our final project submission we provided the following rendering, since the actually physical assembly is still not quite complete and more parts need to be printed.\n\n![Final Rendering](https://static.404wolf.com/Post-20240727215816081.webp)\n\n## Driver software\n\nAlthough the actual processing of coin images is a later step that I haven't really gotten too far into yet, I have been making sure that the hardware components that we use are able to be controlled with our Pythonic on-board software. The software for this project is two-part: [software that will live on the board itself](https://github.com/Coin-Sort-Bot/OnBoard/), and a backend web server to control the board. The on board software at its current stage provides a very easy to use API interface for driving the various components, so that I can write code like this to control it.\n\n```py\nasync def main():\n    coinbot = CoinBot()\n    await coinbot.setup()\n\n    photo1 = await coinbot.cameras.camera1.capture()\n\n    await coinbot.servos.toggle(2)\n    await coinbot.motor.start(speed=40)\n```\n\nWhat I've done is added another layer of abstraction, so that we can control exactly what we need. For the cameras, I'm using `opencv`, which is a library for processing images, that also has the ability to interface with the OS to capture images. I experimented with `ffmeg` to capture the images by shelling out of my Python code, and was able to get it to work, but to keep the lights on the cameras on so that the cameras stay focused it made more sense to go with `opencv`. I may return to this eventually.\n\n## Next steps\n\nI'm currently brainstorming how to go about controlling the board remotely, and am toying with the idea of using [MTQQ](https://mqtt.org/), [RabbitMQ](https://rabbitmq-website.pages.dev/), or a simple websocket or webhook system with on-board flask endpoints to control the various components. Eventually, the machine will intake coins, send the photo data to the webserver, and then will wait until it is instructed to manipulate its servers to allow the coins to fall down the proper chute.\n\nIn the future, the plan is to actually implement OCR to scan the dates off of the coins and basic machine learning to identify denomination. I'm not entirely sure how I'll go about doing this, but it will likely involve image classification to determine the denomination and perhaps other details (such as whether or not the coin is a D-mark coin), and then either hosted OCR using an open source library like tesseract on the webserver controlling the raspberry pi, or an API like those that Amazon or Google offers to perform the text analysis.\n\n# Reflection\n\nUltimately, the prototyping and iterative design required for this project has been a lot more extensive than I expected. We've gone through a ton of rolls of filament to get a working prototype, and there's still more work that we could do. 3D printing has been great though, and allowed us to rapidly test out designs. I've also grown to really like Fusion360 (though, not it's cloud based model, and licensing model).\n\n# Additional Notes\n\nThis is still a work in progress! This post will continue to be updated.","src/posts/CoinSortBot.mdx","13482c945954c48a","dnananotubesoftware",{"id":76,"data":78,"body":86,"filePath":87,"digest":88,"deferredRender":26},{"title":79,"type":15,"date":80,"covers":81,"tags":84,"description":85},"DNA Nanotube Design Software","2022-01-01",[82,83],"https://static.404wolf.com/example_nanotube.webp","https://static.404wolf.com/first_top_view.webp",[21,20],"NATuG (Nucleic Acid Tube Grapher) was an academic research project I undertook in my senior year that's a Python3-based desktop application designed to streamline the DNA nanotube design process. It's one of my most extensive projects, involving a complex and dynamic UI that lets users visualize DNA nanotube shapes, weave together strands of DNA with cross-strand exchanges, set and export sequences, and more. Here I discuss what the program does, a bit about how it works, and how I got involved.\n","# Getting Started\n\nA video \"TLDR\" of what NATuG can do --\n![Program preview](https://static.404wolf.com/programOverview_0001_0001_0001.webm)\n\nA technical briefing made in preparation for a \"technical deep dive\" presentation on the project can be found **[here](https://github.com/404Wolf/stainless-technical-breifing-natug/releases/download/v1.0/natug_technical_brief.pdf)**.\n\n## Involvement\n\nIt was early 2022, in my professor's Physics class, when in my first homework assignment, an about-me paper, I discussed my love of programming. I wrote about how I liked the problem solving that accompanied code, and how I was eager to learn more about Physics because of its practical applications. Fast forward a few months, and he reached out to see whether I'd be interested in contributing to an ongoing research project.\n\nWhat I love about code is that it enables actual application of theory (praxis). By implementing known algorithms computationally, processes become simpler and more practical. In some cases, they become simply _possible_ and, critically, accessible. This project was to involve me developing an application around a complex framework for designing DNA nanotubes, which I could see would enable never before possible designs, but also could serve as a tool for people with limited knowledge of the field in general to learn more too. The project builds off my professor's [research paper discussing DNA nanotube design](https://www.sciencedirect.com/science/article/pii/S0006349506726303) by implementing the theory in practical and user friendly software.\n\nBut before discussing the specific application I developed, it is important to gain a brief understanding of the field surrounding the software.\n\n## Background\n\nI like to think of DNA nanotubes as a niche in the complex and ever-growing realm of DNA nanotech. DNA nanotech is, essentially, taking advantage of how DNA operates (base pairing, shape, chemistry, etc.) to get it to form custom shapes. These shapes are super tiny, so in a way it's like nanoscale 3D printing. Nanotubes are, of course, just one of many different possible shapes that you can form DNA into, but one with particularly many use cases. Employing DNA nanotechnology, one can create a wide array of highly customizable, self-assembling, rigid nanostructures with precision of up around 1nm, and applications ranging from nanophotonics (altering light wavelengths by passing light through tiles of the DNA), to DNA based computing, to DNA-based sensors, and much more. The field is still developing, and new applications are sprouting constantly.\n\n### DNA Nanotubes\n\n![Example DNA nanotube](https://static.404wolf.com/example_nanotube.webp)\n\nThere are many different forms of nanotubes that can be created, but they are all somehow alterations of a hollow, tubular structure. They involve conjoining many cylindrical DNA double helices with cross-strand exchanges to 'bond' them together. DNA nanotubes possess significant potential for use in targeted drug delivery, tissue wound repair, and much more. The specific form of nanotube that I've focused on consist of multiple double helices running parallel to each other, a specific type of nanotube. Even with the constraints of the structure I was designing software to create, design is very complex, and there are many different possible tubes. The design process involves identifying a tube shape consistent with the intrinsic geometry of a DNA double helix, aligning helices, placing connections between helices as to generate minimal strain, and determining base sequences.\n\n![Staple Strands](https://static.404wolf.com/dnaOrigami_0001.png)\n\nMaking matters more complex is the fact that to actually go about transferring the theoretical shapes to test tubes, these nanotubes generally utilize DNA origami, in which a long viral strand is folded into shape by short \"staple strands.\" This is because synthetic DNA can only be up to 100 base pairs in length or so, while viral DNA can cheaply be produced with thousands of bases. By using strand \"staples\" you can fold up the virus into a shape of your choosing.\n\nWhile the process needed for nanotube design has been known for a while, up until NATuG there's been no good computational tool specifically dedicated to their design. Previously bionanotechnologists could utilize a complex spreadsheet tool, allowing users to plot the side view and top view, but it could only support a fixed number of double helices (given the nature of spreadsheets), and did not provide the necessary interactivity that the software I developed, NATuG (nucleic-acid-tube-grapher), offers. Interestingly, NATuG also allows for the creation of non-tubular structures, with a super intuitive interface that is great for people first learning about DNA nanotech; though, however, there exists various tools for nontubular DNA nanostructure design.\n\n# The program\n\n![Side view plot](https://static.404wolf.com/side_view_plot.webp)\n\nNATuG is, most simply put, a Python-based desktop application that is designed to streamline the DNA nanotube design process. It provides a nice UI that allows users to easily set the angles between double helices as to change the overall shape of the tube, while computing a top and side view plot in real time. NATuG automatically lines up the double helices as to allow for cross-strand exchanges to hold together the structure. With a single click on overlapping nucleoside midpoints (spots between two nucleosides), NATuG automatically swerves the strands across double helices, creating a cross-strand exchange. Additionally, users can easily interact with specific nucleosides of the structure, create nicks and linkages, and more. By strategically placing junctions throughout the structure, the isolated double helices become a unified, rigid nanotube. The program provides an intuitive interface, allowing one to customize and visualize the nanotube shape, weave together helices in a matter of clicks, and apply/export sequences. So, while designing DNA nanotubes is a multistage endeavor, NATuG aims to make the process as dynamic as possible—letting users easily traverse the nanotube design process with ease.\n\nIt's a very complex tool that I've continued to build on extensively, and includes rendering features, a custom file format to bundle and save program states, and much more. I've\n\n![NATuG 2.0](https://static.404wolf.com/NATuG2.webp)\n\nThis is the third iteration of NATuG software, and is a complete overhaul both UI wise and design wise. The older versions were abandoned years ago, and at the time they had extensive limitations, such as only allowing for a single type of cross-strand exchange, insufficient for the design of structurally integral DNA nanotubes. This version of NATuG takes much inspiration from the interface of the previous versions, but is also original in many ways, and has many more features than its predecessors.\n\n## Getting started\n\n![NATuG interface](https://static.404wolf.com/interface.webp)\n\nWhen starting work on NATuG, I needed to start off choosing my UI and plotting framework, which would inevitably be a vital part of the program. Interactivity would be key, along with, ideally, a large amount of plug-and-play widgets to choose from. Ultimately, I settled on [QT's](https://www.qt.io/) UI framework, and Python as the primary language, given my experience with the paradigms of the language, and comprehensibility of the toolkit. Though the project was my first time with UI design, it was a great learning experience. For the plotting framework, though many to most Python projects implement [matplotlib](https://matplotlib.org/) as their, I elected to use [pyqtgraph](https://www.pyqtgraph.org/) because of how well it integrates with PyQt, and support for much needed interactivity. It's able to track clicks on individual points, and update in real time.\n\n## Adding features\n\n![NATuG's first plot](https://static.404wolf.com/first_top_view.webp)\n\nMy first step with the program, before building a complex, multi-widget UI, was to actually implement side and top view visualization plots. And for this, I began in Excel, tinkering with parameters while working on grasping the already known plotting algorithm I'd be using. Of course, Excel's plotting capabilities are much more limited than that of programic plotting in Python with pyqtgraph, and I'd have a lot I'd need to learn.\n\n## The plots\n\n![Side view plot](https://static.404wolf.com/topView_0002.svg)\n\nNATuG consists of two plots: the **top view plot** and the **side view plot**. Both plots display the same nanostructures, but from two different perspectives.\n\n### Top View Plot\n\n![Heart shaped tube](https://static.404wolf.com/heart_tube.webp)\n![Symmetrical design](https://static.404wolf.com/symmetric_design.webp)\n\nThe top view plot displays a view of the nanotube from the top down, showcasing the overall shape of the tube. It allows the user to better visualize what they are actually constructing. As one tinkers with the inter-domain angles, the actual shape of the tube changes. Each circle represents a DNA double helix, and the fact that they all touch and eventually close up indicates that it is a closed tube. I've also made it so that if you click on a specific double helix in the top view plot, NATuG automatically pans to the side view plot location that has information on the nucleosides in that region.\n\n### Side View Plot\n\n![Creating cross-strand exchanges](https://static.404wolf.com/creating_junctions.webp)\n\nThe side view provides a view as if the nanotube had been unrolled flat, and is strategically distorted as to show all the nucleosides of the nanostructure without overlaps. This plot is much more complex and feature-rich than the top view plot, since it allows for user interaction with the actual nucleosides. It allows users to create nicks in strands, conjunct strands, link together the ends of strands to allow for DNA origami designs, and more. Lots of work has gone into converting the underlying datastructure for strands into a visualized pyqtgraph plot widget that has signals properly hooked up as to allow the user to manipulate the state.\n\n### Future Plots\n\nIn the future, there's many other types of plot improvements, and even entirely new plots that could be contrived. For instance, we have spent some time discussing the possibility of creating a 3D plot, to visualize the tube from any given perspective at once.\n\n### The interface\n\n![Multi-panel UI beginnings](https://static.404wolf.com/beginnings_of_ui.webp)\n\nThe primary goal of NATuG has been to make the nanotube design experience as pain-free and intuitive as possible. So, not only have I had to learn how to actually go about creating UIs, but I've also had to figure out the best way to position and size elements to make clear how to utilize the program. For the UX design, I choose to go with a three panel UI, with an undockable multi-use, tabbed configuration panel and a resizable top/side view plot area. This allows the user to view the different plots simultaneously or one at a time, while always having access to the configuration.\n\n### Junctions!\n\n![Possible junction types](https://static.404wolf.com/junction_types.webp)\n\nOne of the most important features of NATuG is the ability to create cross-strand exchanges. These exchanges implement \"Holliday\" junctions to allow strands to swerve across their helical domains, weaving together the nanostructure. This was definitely the most difficult to implement part of the project, since previous works showed that junctions were possible, but relied on intuition to determine how to go about making them. This makes sense, since if you look at a side view helix plot, it is fairly obvious to a human how to conjunct the strands. This was definitely one of my favorite parts of the project, since it was both challenging and rewarding to catalog the various cases. Unrelated: this was a classic case of [Moravec's Paradox](https://en.wikipedia.org/wiki/Moravec%27s_paradox), which is definitely an interesting read.\n\nAfter extensive tinkering and cogitating, I've come to the conclusion that there are a distinct amount of different possible cases for conjunction the strands of two arbitrary nucleoside-end midpoints, which are outlined in the tree to the right. As it turned out, there were specific pathways to the subcases, dependent on the closedness of the strands of the NEMids and whether the NEMids are in the same strand. Coming up with this algorithm is definitely one of my most impressive contributions to the project, and was almost equally annoying to implement. Implementing the algorithm required moving nucleosides between strands, of which some had no definite start/end and were closed loops. Determining how to reindex arrays to most efficiently build the new strands, and prevent off-by-one errors, was no easy feat, and if you're interested in reading through the code yourself you can find it [here](https://gist.github.com/404Wolf/bbbe24af9939124a0752b8909097e578).\n\n# Takeaways\n\nFirstly, there are many project-related takeaways worth discussing. Ultimately, NATuG showcases the powerful potential of software to allow for more complex, larger-scale tubular DNA nanostructures. The program allows the user to spend less time doing tedious computations, and more time focusing on the actual design of the structure. Additionally, with the ability to load and export structures into and out of NATuG, we expect collaborative design to become much more streamlined. Additionally, we also realized that the program holds the potential for non-closed tile design, which is common in the realm of DNA origami. While there are other tools that are more sophisticated and perhaps better suited for this specific purpose, NATuG provides a uniquely user friendly and convenient experience.\n\nAs I complete the initial version of the program, Professor Sherman and I are beginning to draft a paper for NATuG, which we intend to submit for publication to a peer reviewed journal within the next few months. We hope to discuss some of the potential shapes of nanotubes that can be created, the way that the program tackles conjoining strands, and the like.\n\n[Nadrian Seeman](nadrianSeeman_0001)\n\nTowards the end of the project we've also informally shared the project at NYU's Nadrian Seeman Memorial Symposium. Nadrian Seeman is the founder of DNA Nanotechnology as a field in general, and paved the path for not just this project, but all structural DNA related projects and software tools. He showed that it's possible to take a medium like DNA, the molecule of life, and turn it into something completely different: a nanoscale building block. The symposium at NYU was truly an amazing experience, where I got to hear about many different fascinating areas of the field and speak with people about countless ongoing related projects.\n\nOn a more personal note, this project was one of my best coding experiences yet. I've come to find that large scale projects are generally the best way for me to improve my coding abilities, and this was no exception. Spending countless hours figuring out how to detect the click of an up button on a double spin box may seem like a complete waste of time, but many different obsessions and debugging sessions throughout the project have greatly improved my bug-catching abilities. Working with libraries like PyQt may seem to provide niche skills that may only be useful for specific types of projects in the future, but they actually helped me grasp the complex concepts of OOP and better understand Python's weird quirks. I liked this project more than many of the others I've worked on because it's not a means to an end, but is an end that provides more means.\n\n## Learn more\n\n![Poster preview](https://static.404wolf.com/natugPosterLowRes_0001.png)\n\nThough this post attempts to discuss the needed background to understand what NATuG does, I still strongly suggest reading my professor's [paper on the design of DNA nanotubes](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1471877/). It's definitely quite complex, but it has useful diagrams and is a very interesting and mind bending read. Also, it may be helpful to check out [this poster I created showcasing the project](https://drive.google.com/file/d/1R7wqzkVm2bnDmgzsexkkqsYj_X0iEB5T/view?usp=sharing).\n\nIf you're interested in learning more about how to actually set up and use the program, check out its [user manual](https://github.com/NATuG3/Manual/blob/main/manual.pdf) and [Github repository](https://github.com/NATuG3/NATuG3). Also, feel free to reach out if you have any questions.","src/posts/DNANanotubeSoftware.mdx","f5df64f54bee9a04","eclecticenglishvocabdeck",{"id":89,"data":91,"body":101,"filePath":102,"digest":103,"deferredRender":26},{"title":92,"type":15,"date":93,"covers":94,"tags":98,"description":100},"Eclectic English Vocab","2023-01-01",[95,96,97],"https://static.404wolf.com/mobile_flashcards.webp","https://static.404wolf.com/desktop_flashcard_front.webp","https://static.404wolf.com/word_cubes.webp",[35,99],"ongoing","Conglomeration, obstreperous, mercurial, preantepenultimate, rapacious, verisimilitude. For some, it's coins—for me, words. Over the past year, I've fastidiously curated those with intriguing meanings, idyllic spellings, eccentric pronunciations, and compelling origins, bolstering my lexicon and piquing my logophilia. It's been an engrossing use of free-time tranches, and a process as delightful as the product.\n","# What it Is\n\nThis project discusses my eclectic, carefully curated deck of English vocab words that are both useful and mostly advanced/not very common. Many of the words in the deck are taken from Webster's words of the Day page, but lots are also from my readings/experiences too. They're all words that I did not originally know and that I believe are genuinely useful, even if they are indeed a bit esoteric. I've made a custom, styled template for the deck inspired by Webster dictionary, and have also put together images and audio for each card.\n\n![Desktop flashcard example (front)](https://static.404wolf.com/desktop_flashcard_front.webp)\n![Desktop flashcard example (back)](https://static.404wolf.com/desktop_flashcard_back.webp)\n\n# The deck\n\n![The backlog](https://static.404wolf.com/backlog.webp)\n\nAs I encounter new, unknown words, I've stored them away in a [Google Keep](https://keep.google.com/) backlog. I've gotten into the habit of allocating a corner of my loose leaf that I use for notes for vocab words that I don't yet know, and stay up to date with the [Merriam-Webster word of the day](https://www.merriam-webster.com/word-of-the-day). Since I don't want to commit completely useless words into my lexicon for no reason, I do some vetting, checking their usage over time, recent usage, and the applicability of the word, before batch adding words to my [spaced-repetition](https://en.wikipedia.org/wiki/Spaced_repetition) flashcard deck.\n\n## Spaced repetition\n\n![Spaced repetition learning curve](https://static.404wolf.com/spaced_repitition_graph.webp)\n\nSpaced repetition is a special evidence-based flashcard studying method wherein cards are automatically shown to you at specific intervals based on your response to remembering the card, as to show you the card at the moment before you are predicted to forget it. That is, the more you forget a card, the more often you will encounter the card, and the better you get at remembering it, the longer the interval gaps become. The end result: the more you review, the longer it takes to forget. Not only is retention boosted, but study time is better optimized.\n\n![Leitner box system](Leitner_system_animation_0002.gif|float=right)\n\nGenerally these days spaced repetition is implemented with software, but that does not necessarily need to be the case. ['Leitner boxes'](https://en.wikipedia.org/wiki/Leitner_system) are an implementation of spaced repetition with physical flashcards and boxes to store them in based on proficiency. After reviewing cards, the cards move to boxes based on your ability to recall them, and the easier to remember cards end up being reviewed less often.\n\n# Getting the deck\n\n![Anki Flashcards graph example](https://static.404wolf.com/anki_graph_example.webp)\n![Mobile flashcard example](https://static.404wolf.com/mobile_flashcards.webp)\n\nAlthough approaches like this do work, I highly recommend using software to manage the spaced repetition for you, since they can provide greater configurability, allow you to track your progress over time, and manage everything for you, so that you can spend your time actually reviewing cards rather than handling technicalities. There are a large variety of both free and paid applications for the task, but my go-to is [Anki Flashcards](https://apps.ankiweb.net/). It's completely open source, easy to use, highly configurable, extendable, and has lots of community support, decks, and add-ons. It's completely free to use their website, desktop app, and android app, but their iPhone app is $25 (and worth every penny).\n\nA copy of the deck can be downloaded [here](https://drive.google.com/file/d/1wysbw8pV2i1xhy1Xwt3zRoyVMkC2zH5s/view?usp=share_link). I will try to frequently update the link with new cards as I add them, and Anki Flashcards should automatically merge in the new ones when you install updated decks.\n\n# Automating Compilation\n\nWith my deck building up in size, and my appetite for words evergrowing, I knew I'd need a better way to create flashcards. For each flashcard, there are 9 different fields: word, definitions, examples, synonyms, notes, images, pronunciation, audio, and part of speech. All fields are needed for every card except notes, which is reserved for when an important note is needed to provide context for a word. While this may have been fine for the first 100 cards, I hope to grow at a much higher rate, and also thought that automatic card generation would be a fun next step. I'd still curate the words, but a bot would help create the cards.\n\nThe first step of figuring out how to automate would be to determine where and how to fetch card information. While indeed many dictionary APIs, including free options, already exist, such as [webster's](https://dictionaryapi.com/), I wanted something that would provide me unique examples for the word, and compile all the data in one place. Additionally, I needed to implement some sort of image generation/location system to find an image to help remember the word, along with adding text to speech so that my flashcard software could read me the word.\n\nOver the past month, I've come to find that OpenAI's ChatGTP has been particularly useful for curating these specific things, and their DALLE image generator has been able to create good-enough images for memorizing words. Since they have extremely cheap and easy to use APIs for the services, and I've been wanting to learn how to implement NLP into software anyway, I chose to implement OpenAI's AI to generate word images and metadata. For text to speech, I chose Google text to speech, given it's robustness and popularity.\n\nWith ChatGTP's API, you have the option of providing a \"system message\" to the bot before querying it. For this, I wanted a bot that would both write poetically and in interesting/helpful ways, but also provide output in as a valid JSON. For this, I wrote up the following message to teach the bot how to behave and function.\n\n```\nYou are a very skillful poet with a large lexicon. Your goal is to help people improve their vocab in a fun and helpful way. People will provide you a single word input, and you will reply with various pieces of information, separated by two newlines. Ensure it is a valid json. Follow the following template exactly. If the word appears misspelt, take your best guess as to what the word is. If you are totally unsure, respond \"na\".\n\n{\n    \"word\": {Word provided, or, if provided word misspelt, your best guess.},\n    \"part_of_speech\": {Part of speech of the word.},\n    \"pronunciation\": {The phonetic pronunciation of the word, using dashes as separators and only ascii characters. Aim for clarity.},\n    \"definitions\": [\u003CDefinitions here, separated by commas, in order of popularity. Include the top definition, along with up to 3 other popular definitions as needed, but aim for as few as possible. Ensure each definition is clear and longer than 4 words. The word itself shouldn't show up in any of the definitions. Make them clear, but not overly textbooky.>],\n    \"synonyms\": [\u003C4-5 synonyms here, separated by commas, each embedded in quotes, in order of helpfulness. Synonyms should be only single words each, and they shouldn't be totally obscure.],\n    \"examples\": [\u003C4-5 examples here, separated by commas, each embedded in quotes, in order of popularity. Each example should not start with a proper noun, and the ending period should be left out (if it is multiple sentences only the last one should lack a period). For the specific requested word, embed it in single asterisks. The examples should be upbeat, make sense and sound eloquent and good, and help demonstrate the word definition. Ensure that they are fully lowercase, except proper nouns.>]\n}\n\nAdditional important instructions:\n1) If passed a conjugated verb, standardize it to be imperative.\n2) If passed a declined noun, standardize it to be singular.\n3) Be lively, friendly, clear, and as helpful as possible. Be slightly poetic and convivial.\n```\n\nImages also require a prompt, but for the image I decided that the best person to write a prompt would AI itself. So, for the images, I prompted GPT to write a prompt for DALLE using the following template.\n\n```\nProvide {count} brief, different bits of imagery that capture a common occurrence of \\\"{word}\\\" These descriptions should: - NOT use the word \\\"{word}.\\\"\\n- NOT involve humans.\\n- BE 300 characters or less.\n```\n\n![\"Glower\" DALLE image](https://static.404wolf.com/glower_image.webp)\n![\"Obnubilate\" DALLE image](https://static.404wolf.com/obnubilate_image.webp)\n![\"Conflate\" DALLE image](https://static.404wolf.com/conflate_image.webp)\n\n```json\n{\n  \"word\": \"Conflate\",\n  \"part_of_speech\": \"verb\",\n  \"pronunciation\": \"kuhn-fleyt\",\n  \"definitions\": [\"to bring together; meld or fuse\", \"to confuse or mix up\"],\n  \"synonyms\": [\"blend\", \"merge\", \"combine\", \"unify\", \"amalgamate\"],\n  \"examples\": [\n    \"Let's *conflate* our ideas to create something truly original\",\n    \"Don't *conflate* this issue with others that are irrelevant\",\n    \"The author often *conflates* fact and fiction in his stories\",\n    \"The sensation of nostalgia and longing were *conflated* in her heart\"\n  ]\n}\n```\n\n# Logophilio\n\nAfter using Anki for a while for this project though, I decided that it'd be fun to try to generate actual physical flashcards of my own. Now that I had the ability to generate all the different pieces of flashcards, I spent a significant amount of time figuring out how to render them into actual flashcard images. After much experimentation, I decided to code custom SVG templates, which I write more about [here](https://404wolf.com/posts/blog/svgShenanigans). The general idea is that SVG files are really just definitions of paths, lines, shapes, and colors. Instead of using a program like Illustrator to generate them for me, I hand-wrote a flashcard-style SVG in a text editor, and then added fields that could be swapped out for dynamic content (including image sources!). As I worked on this I was also able to fine tune the image generation to allow for more accurate to the word images. Here's some examples...\n\n![Example flashcard #1](https://static.404wolf.com/exampleFlashcard1_0001.png)\n![Example flashcard #2](https://static.404wolf.com/exampleFlashcard2_0001.png)\n\nAlthough the software tool I initially was working on was a basic script to help me create new Anki flashcards, I'm now working on a much larger-scale project to generate templated PDF flashcards that can be (eventually) professionally printed out. At the moment I do have a working script for the program, which can be found [here](https://github.com/404wolf/logophilio), but I'm in the process of porting it over to Django. The current port allows you to generate flashcards via a simple endpoint by submitting a list of words and styles, placing the output PDFs and images used for the flashcards into S3 (AWS storage) automatically.\n\n![Example API request](https://static.404wolf.com/exampleAPIRequest_0001.png)\n\nWhile my API implementation enables concurrent flashcard generation server-side, but, as it turns out, flashcard generation is extremely IO-bound. It takes 20 seconds worth of waiting to gather all the needed resources for a given card, including AI-generated images and dictionary entries, no matter what. However, since most of that time is spent waiting, multiple cards can be generated on other threads at the same time. My goal is to be able to send a request to generate as many flashcards as you'd want and get back a task ID, which you could then use to get the generated flashcards later.\n\nFor this, I've been looking into using some sort of task queue system with workers, although I may just use threading and implement my own task ID model for my database. Part of what makes the flashcard generation annoying to distribute is that it can't run on lambdas serverless-ly because of the cold start of chromedriver. Since I'm using serelium to render the PDFs, it'd take a long time for a serverless function to set up to perform the render, as opposed to a dedicated server always having a chromedriver running.\n\n## Making a service\n\n![Wireframing idea #1](https://static.404wolf.com/wireframing1_0001.png)\n![Wireframing idea #2](https://static.404wolf.com/wireframing2_0001.png)\n![Wireframing idea #3](https://static.404wolf.com/wireframing3_0001.png)\n\nThe next step for this chapter of the project, after further refining the API, is to create an actual UI. My plan is to eventually integrate with Twilio so that you can text a phone number a word whenever you come across it in daily life, and then at the end of each month a deck of flashcards could automatically be generated, printed, and sent to you. Updates will be posted here as the project progresses.","src/posts/EclecticEnglishVocabDeck.mdx","120569b806bb1a87","forcedbrowserzoomextension",{"id":104,"data":106,"body":114,"filePath":115,"digest":116,"deferredRender":26},{"title":107,"type":15,"date":16,"covers":108,"tags":112,"description":113},"Forced Browser-Based Zoom Extension",[109,110,111],"https://static.404wolf.com/Post-20240716211735260.webp","https://static.404wolf.com/Post-20240716212111111.webp","https://static.404wolf.com/Post-20240716214604533.webp",[35],"This idea spawned from my hatred and eternal frustration with Zoom. It's just always a pain to deal with; screen share often just doesn't work right, the UI glitches out, audio is a mess and very inconsistent, and it eats up system resources and is probably doing mysterious things behind the scenes intruding on privacy. There's a solution though: use Zoom in your browser, only, always, ever! Zoom provides an option to join in the browser, given that you reject their popups to open in desktop, and then click through a chain of links to open in the browser. My solution: a browser extension to redirect Zoom links directly to browser Zoom.\n","# The Idea\n\nIt's just always a pain to deal with Zoom. Screen share often just doesn't work right, the UI glitches out, audio is a mess and very inconsistent, and it eats up system resources and is probably doing mysterious things behind the scenes intruding on privacy. But privacy aside, I'm sure everyone reading this has been late to **at least** 1 meeting because Zoom randomly decided to update (I thought that when I ditched windows that problem was behind me!).\n\nThere's a solution though: use Zoom in your browser, only, always, ever! Zoom provides an option to join in the browser, given that you reject their popups to open in desktop, and then click through a chain of links to open in the browser. The nice thing about the browser is that it's sandboxed, it's very limited in what access it has to your system, and is much more private than a closed source binary.\n\nMy solution: a browser extension to redirect Zoom links directly to browser Zoom. The idea was simple, I would create a simple plugin for Chrome (and eventually Firefox) to allow you to skip past popups to join Zoom rooms with the desktop app. The goal was so that you could paste in a Zoom URL as usual, and you would just be forwarded directly to the Zoom room in your browser.\n\n# Research\n\nThe first step was to figure out what the exact user flow that I would need to automate would be. It would be ideal if I could avoid simulating user actions as much as possible, and just take advantage of flags/find ways to redirect right to the browser Zoom interface.\n\nWhat I quickly figured out is that when you visit a Zoom URL, `onWindowLoad` it creates the infamous \"Open Zoom Workplace\" popup, **AND** appends `#success` to the URL.\n\nI figured out if you visit a Zoom URL that already has this `#success` flag at the end of it, that Zoom will not give you the popup. This turned out to be a great step, since apparently it's just straight up not possible to interact with browser dialogs with an extension. Not discovering this may have killed off the project.\n\n![Joining a Zoom](https://static.404wolf.com/Post-20240716211735260.webp)\n\nThe next step in the user flow I thought would be simple, just scrape the page and find the URL that the \"Join from your Browser\" button links to, and then redirect there, but it turns out that that button is actually executing javascript.\n\n![The button](https://static.404wolf.com/Post-20240716212111111.webp)\n\nLuckily extensions do have the ability to modify the webpage, so I could just click the button for the user. This is annoying, but it works fine.\n\nNow let's dive into how I actually wrote it.\n\n# Implementation\n\nI'd never made a browser extension before, but it turns out that [Google](https://developer.chrome.com/docs/extensions)'s (and Mozilla's, as I'd figure out later when porting to Firefox) documentation for extensions is pretty good.\n\nBasically, the general flow is that you create a directory with a image icon for the extension, a `manifest.json` file that follows a specific schema (there's a few versions of the schema that chrome supports, but the most recent one is called \"Manifest v3\"), and then some javascript files (technically optional, but that's where the extension's logic goes). I started with a very bare bones basic manifest and just added permissions and configuration as I went.\n\n## Development\n\nGetting a developer environment set up for the project was pretty straight forward. First, I made a `nix` devShell that had a base chromium and firefox binary, so that I could test in a clean \"sandbox\"-y environment:\n\n```nix\n{\n  description = \"Force browser only Zoom\";\n\n  inputs = {\n    flake-utils.url = \"github:numtide/flake-utils\";\n    nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";\n  };\n\n  outputs =\n    {\n      self,\n      nixpkgs,\n      flake-utils,\n    }:\n    flake-utils.lib.eachDefaultSystem (\n      system:\n      let\n        pkgs = import nixpkgs { inherit system; };\n      in\n      {\n        devShells = {\n          default = pkgs.mkShell {\n            packages = [\n              pkgs.ungoogled-chromium\n              pkgs.librewolf\n            ];\n          };\n        };\n      }\n    );\n}\n```\n\nAnd then in Chrome (and in Firefox it was a similar process) I went to `chrome://extensions`, and enabled developer mode.\n\n![Developer mode](https://static.404wolf.com/Post-20240716222255624.webp)\n\nAfterwards, I clicked to load the \"unpacked\" (you can \"pack\" your extension as a special zip like file with encryption, in case you want to deploy a closed source extension) plugin.\n\n![Loading it in](ttps://static.404wolf.com/Post-20240716222359125.webp)\n\nAnd it was added! It was a pretty easy process. I could get logs by clicking \"Details\", and could just reload it by clicking a little reload icon.\n\n## Redirecting\n\nThe first step of the project's implementation would be to figure out how to redirect users as they visit websites, as a function of the website they visit. Something like\n\n```ts\n(websiteVisited: string) => websiteVisited + \"#success\";\n```\n\nSuper simple, I know.\n\nI found [this super super helpful](https://stackoverflow.com/a/12070823) Stack Overflow post summarizing the options I had.\n\nThe options they presented:\n\n> 1. The [`webRequest`](https://developer.chrome.com/extensions/webRequest.html) API, specifically the [`onBeforeRequest` event](https://developer.chrome.com/extensions/webRequest.html#event-onBeforeRequest). (Even better, the upcoming [`declarativeWebRequest` API](http://developer.chrome.com/extensions/declarativeWebRequest.html)).\n\n(note that the url is broken -- it's now [here](https://developer.chrome.com/docs/extensions/reference/api/declarativeNetRequestk)\n\nThis initially seemed like the best option. It seemed like the \"proper\" way to do it. Firstly, it's pretty secure since I don't have to have my extension view the web content itself (although, as I'll explain later, this turned out to be necessary anyway)\n\n> The `chrome.declarativeNetRequest` API is used to block or modify network requests by specifying declarative rules. This lets extensions modify network requests without intercepting them and viewing their content, thus providing more privacy.\n\nMore importantly though, it seemed like this approach wasn't great for actual browser navigation, and was better for redirecting network requests, which wasn't really my goal.\n\n> 2. [Content scripts](http://developer.chrome.com/extensions/content_scripts.html). Inject `location.replace('http://example.com')` in a page.\n\nThis option basically means swapping out links that users would click on so that they never end up at the link without `#success` to begin with. This also means that it wouldn't work if users pasted the URL into the search bar, so this wouldn't work.\n\n> 3. The [`tabs`](http://developer.chrome.com/extensions/tabs.html) API. Use the [`onUpdated` event](http://developer.chrome.com/extensions/tabs.html#event-onUpdated) to detect when a page has changed its location, and [`chrome.tabs.update`](http://developer.chrome.com/extensions/tabs.html#method-update) to change its URL. Avoid an infinite loop though!\n\nThis option looked great! Just monitor when a tab starts to visit a URL and then before it can begin doing fetches swap the URL. This is what I went with, and it turned out later that Mozilla had an identical API and version for Firefox.\n\nThe code for deciding to redirect the user ended up being super minimal, and looked something like this...\n\n```js\nchrome.webNavigation.onCommitted.addListener(\n  (details) => {\n    zoomPattern =\n      /^https:\\/\\/(\\w+\\.)?\\w+\\.\\w+\\/j\\/\\d{10}\\?pwd\\=[a-zA-Z0-9]{32}$/;\n    if (details.url.match(zoomPattern))\n      chrome.tabs.update(details.tabId, { url: `${details.url}#success` });\n  },\n  { url: [{ urlMatches: \".*\" }] },\n);\n```\n\nIt's probably a bit more complicated than it had to be, but basically I wanted to be super careful that people would only be redirected when they visited Zoom URLs, and Zoom URLs can be hosted on your own enterprise domain (e.g. `zoom.yourcompany.com`), so I wanted to make sure that I pattern matched against the Zoom URL schema as tightly as possible with regex.\n\n## Clicking Past\n\nNow that I was able to skip the \"Open in Zoom Desktop\" popup, I'd need to click the button for the user to actually go to the browser Zoom page.\n\nThis is just a clickable element, and interacting with it was as simple as using a selector to select it, and calling the `click` method. I'd done quite a bit of `puppeteer` before and it was very similar syntax.\n\nThe full code for this looks like this\n\n```js\nconst elements = [\n  ...document.querySelectorAll('a[role=\"button\"][tabindex=\"0\"]'),\n];\nconst element = elements.find(\n  (el) => el.innerText === \"Join from Your Browser\",\n);\nif (element) {\n  element.click();\n}\n```\n\nIt's really not that bad. I just add a listener to execute this on all page loads (although I really should only do this on loads of Zoom-like-URLs, but optimizations come later!).\n\nI also added some code to remove the other buttons on the page and Ads to get the app, for while the page redirected you and things were still loading\n\n```js\n// findAndRemoveIfExists is a helper function I define elsewhere. It does what\n// the name says it does.\nfindAndRemoveIfExists(\"div.ifP196ZE.x2RD4pnS\");\nfindAndRemoveIfExists('hr[role=\"presentation\"]');\nfindAndRemoveIfExists('h3[class=\"rm-presentation\"]');\n```\n\nAnd had a bit of fun messing with the DOM...\n\n```js\nconst zoomAppSpans = document.querySelectorAll(\"span\");\nconst targetSpan = [...zoomAppSpans].find((span) =>\n  span.textContent.includes(\"with the Zoom\"),\n);\nif (targetSpan)\n  targetSpan.childNodes[0].textContent = \"Hate the Zoom Desktop App? \";\n```\n\nAnd then all I had to do was write a `manifest.json` with the right permissions. It turns out that ChatGPT is much better at writing the old `manifest V2` style manifests, but it was still helpful\n\nIt was pretty simple, and the hard part was just finding what I needed permissions for in the docs.\n\n```json\n{\n  \"manifest_version\": 3,\n  \"name\": \"Browser Zoom\",\n  \"description\": \"Only let zoom run in the browser. No more popups!\",\n  \"version\": \"1.0\",\n  \"background\": {\n    \"service_worker\": \"background.js\"\n  },\n  \"content_scripts\": [\n    {\n      \"matches\": [\"https://*/*\"],\n      \"js\": [\"content.js\"],\n      \"run_at\": \"document_idle\"\n    }\n  ],\n  \"permissions\": [\"activeTab\", \"webNavigation\"],\n  \"action\": {\n    \"default_popup\": \"popup.html\",\n    \"icons\": {\n      \"16\": \"https://static.404wolf.com/icon-16.png\",\n      \"48\": \"https://static.404wolf.com/icon-48.png\",\n      \"128\": \"https://static.404wolf.com/icon-128.png\"\n    }\n  }\n}\n```\n\n# Distributions\n\nThe plugin is available on my Github [here](https://github.com/404wolf/Browser-Zoom), and is totally open source.\n\n## Chrome\n\n![Google Extension Rejection](https://static.404wolf.com/https://static.404wolf.com/Post-20240716215027831.webp)\n\nIt was a bit tricky to publish the plugin on extension stores, mostly because it requires access to \"modify\" ANY website. Basically, in my extension's manifest (where metadata about it and its permissions live, which is mostly directives to the browser), it has\n\n```json\n...\n\"content_scripts\": [\n  {\n    \"matches\": [ \"https://*/*\" ],\n    \"js\": [ \"content.js\" ],\n    \"run_at\": \"document_idle\"\n  }\n],\n...\n```\n\nThis means that the extension has permission to modify the DOM of any website. Initially I was worried Google would reject the plugin because of this extensive requirement, but my main justification is that Zoom can run on any domain (like zoom.yourcompany.us), and thus I can't match domains without complicated regex (but the match pattern here is not regex, it's special google syntax).\n\n![Chrome developer dashboard](https://static.404wolf.com/https://static.404wolf.com/Post-20240716215251691.webp)\n\nIt turned out that the annoying parts of the Google extension publishing experience were elsewhere, though. To start, to even make a developer account for the Chrome webstore dashboard, you need to make a $5 deposit to \"fight spam and abuse.\" Then, after publishing it a few times, while they haven't gotten upset about the permission I thought they would be upset about, they've rather been nit picky on things that don't matter -- like, in my most recent rejection, they told me I don't have a privacy policy link, even though I don't collect user data and supplied a link to a plaintext file that says \"I do not collect any data.\" I'll keep trying to get it published on the Chrome extension store, though!\n\nFor now, to run it on Chrome just get it from the Github and install it yourself, it's not that hard and you don't need any developer experience.\n\n## Firefox\n\nMozilla on the other hand was really pleasant to deal with. Their store's developer UX was easier to navigate, there was no \"anti-spam\" deposit, and they gave me \"preliminary approval\" in two days.\n\n[It's here, on the Mozilla firefox extension store, if you use firefox!](https://addons.mozilla.org/en-US/firefox/addon/browser-zoom/reviews/)\n\n![Extension Listing](https://static.404wolf.com/https://static.404wolf.com/Post-20240716214604533.webp)\n![Extension ratings](https://static.404wolf.com/https://static.404wolf.com/Post-20240716214554914.webp)","src/posts/ForcedBrowserZoomExtension.mdx","5190a4b5290e55e1","hydroponics",{"id":117,"data":119,"body":134,"filePath":135,"digest":136,"deferredRender":26},{"title":120,"type":15,"date":121,"covers":122,"tags":132,"description":133},"Closet Hydroponics","2020-01-01",[123,124,125,126,127,128,129,130,131],"https://static.404wolf.com/a_harvest.webp","https://static.404wolf.com/baby_pepper.webp","https://static.404wolf.com/early_growth.webp","https://static.404wolf.com/grow_baskets.webp","https://static.404wolf.com/hydroGreen.webp","https://static.404wolf.com/outside_closet_view_of_peppers.webp","https://static.404wolf.com/peppers_side_view_lights_on.webp","https://static.404wolf.com/roots.webp","https://static.404wolf.com/strawberries.web",[35,99],"With the goal of learning how to code some basic Arduino, I fell down the deep rabbit hole of automated gardening. After setting up a simple strawberry watering apparatus in my closet, I began upscaling, up until some mold related challenges prompted a shift to basil hydroponics. Weekly pesto became the norm, and it was smooth sailing until the perennial crop passed its prime. And after such great success with basil, I've now stumbled upon the less successful crop of Shishito Peppers. Here I discuss the research process and many of the pitfalls of my journey, along with many of the things I learned along the way and tips for other aspiring closet gardeners.\n","# The roots\n\n## Starting off\n\n![The Roots](https://static.404wolf.com/roots.webp)\n\nIt all began with an interest in learning how to use Arduinos. After a few years of working on [robot foundry](https://brooklynrobotfoundry.com)'s design team (and many years prior as a student!) building an assortment of simple-circuit powered robots, my desire to implement microcontrollers and programming to a larger-scale personal project had been growing. I'd procured a few years of coding experience at the time, but had never before gone about integrating that experience with hardware. So, I decided to buy myself a small knock-off eBay arduino, and chose to learn how to program it though a project-based approach (as usual). While some people go about learning the language with simple LEDs, buttons, and perhaps a servo or two, as usual I was more interested in a productive and larger scale introductory project. After much brainstorming, I stumbled upon the idea of somehow automating the care of a plant. The idea would be to somehow control the lights and water automatically and dynamically, so that the plant could grow for long periods of time without any human involvement. It seemed like a fun project, and so I dove in, beginning with the most fun decision in the process: choosing what to grow. At the time, it was just a small educational project, but since then it's scaled farther than I ever anticipated.\n\n# Moldy Strawberries\n\n![Strawberry Grow Tower](https://static.404wolf.com/strawberry_tower.webp)\n\nAs I began my research, I realized that I was actually more enticed by the concept of the project (mass-garden-automation) than the actual implementation of the Arduino. Learning a custom and slightly esoteric programming language wasn't something that particularly interested me, but having infinite access to edible plants was very enticing. Though I'd start out the project with a simple Arduino-based system, later on, as will be explained, I moved away from the microcontroller and chose a larger-scale redundant system for the plant automation system. For the research process, I started out by exploring fast growing, easily maintainable plants. I really wanted to grow avocados, but they take a very long time to grow and generally are full sized trees. There is, however, a specific variety of avocado called [wartz avocados](https://minnetonkaorchards.com/wurtz-avocado-tree/) that are smaller, but one issue that quickly came to my attention is that once they reach maturity, which could take a very long time, the avocados themselves take a while to regenerate between harvests. Greens like spinach seemed to be popular choices for the type of system I was planning on making, but I wanted a crop that I could easily preserve over the long term, and unfortunately greens lose their texture when frozen. Berries seemed to be an appealing choice, given their quick germination and grow time, and so I eventually settled on strawberries.\n\n![How a relay works](howRelaysWork_0001.gif)\n\nUltimately I settled on strawberries specifically, since I found that there are fairly common [stackable grow towers](https://www.amazon.com/Amazing-Creation-Strawberries-Vegetables-Succulents/dp/B07BSX6R31) readily available. The nice thing about the towers is that I could scale them to perfectly fit my closet, and could easily add more towers as needed. I ordered some generic strawberry seeds, and got to work cleaning out my closet. I lined the floor with a plastic garbage bag to prevent moisture from damaging the wood floor, and bought a [Govee brand water leak detector](https://us.govee.com/products/wireless-water-leak-detector) in case of any emergency spills. I sectioned off the right half of the closet for the tower and then set up a large bucket with fertilizer-water and affixed the arduino to the inside wall of the closet with velcro. Parsing together some code snippets I found online I figured out enough Arduino to set up a system for automatically dispersing water when the soil dried up using a soil moisture sensor, and covered the closet walls in tin foil with the hope of maximizing the amount of light hitting the plants. I purchased a small relay, a device that lets a low power device like an Arduino toggle an external power connection to higher power devices, and ran the positive wire of an extension cord across it, so I could control the lights automatically with the same system. Cutting the extension cord felt a bit scary, but it seemed to work so I didn't overthink it.\n\n![The strawberry apparatus](https://static.404wolf.com/strawberry_tubing.webp)\n\nWith everything complete and operational, the seeds did indeed germinate as anticipated, but the watering system didn't go according to plan. As time progressed, it didn't water often enough, and when I tinkered with the watering threshold it tended to over-water and cause spillage. To compensate, I ended up needing to manually water from time to time, which defeated the whole point of the project. So, I ended up pivoting to timer-based-watering, which worked, though it was slightly less precise.\n\n![Cheap grow lights](cheapGrowLights_0001.jpg)\n![Better grow lights](betterGrowLight_0001.jpg)\n\nFor the grow lights, I started out with a cheap Amazon grow light, but that didn't last long. After only a few days in the PSU melted itself, but since I had planned for the worst, it simply tripped my GFCI outlet (I ran an extension cord from a specially-protected laundry machine outlet, which has auto-shutoff for this sort of thing) and shut itself off. The replacement lights I bought were definitely better, but still weren't bright enough for the flourishing strawberries, so I ended up again purchasing higher quality more powerful bar lights. This third choice worked well, but it heated up my closet to an ambient 85 and drew 90 watts of power. The expense was notable (probably around $10-15 a month of extra power usage), but less than the quantity of strawberries I was expecting the plants to yield.\n\n## Success-ish\n\n![Strawberry runners](https://static.404wolf.com/strawberryRunnerDiagram_0001.png)\n![Diagram of runner connection](https://static.404wolf.com/strawberryRunnerDiagram_0001.png)\n\n![The first fertilizer](miracleGroFertalizer_0001.jpg)\n\n![Strawberry Fruit](https://static.404wolf.com/strawberries.webp)\n\nWithin a few weeks the plants were off to a great start: they began branching out and runners (technically they're called [stolons](https://strawberry.calpoly.edu/runner-cutter)), which are baby plants attached to the mother plant, started shooting out of the lower parts of the stems. Cutting them off turned out to be important, since they took significant energy away from the plant's fruit production, and it quickly became a daily chore. This is definitely something I'd take into account for future plants, since it was quite tedious. On a few occasions I placed pots next to the plant to clone it, for strawberry-plant-gifts. Flowers eventually appeared on the plants, and then the first few fruits sprung out. I began using a basic [\"miracle gro\"](https://www.amazon.com/Miracle-Gro-2000992-Water-Soluble-Purpose/) fertilizer at this stage, worried that the soil would be depleted of nutrients with the new fruit. The strawberries were indeed juicy, bright red, and aesthetically perfect.\n\n### Mold\n\n![Moldy leaves](moldyLeaves_0001.jpg)\n\nThe success unfortunately didn't last much more than a few weeks, which is when the mold started. A slight white powder type mold began appearing on the undersides of leaves, and it quickly spread to the entire plant. It seemed that it was \"powdery mildew\" that I was dealing with. I added a small dehumidifier from Amazon, and drilled a hole in the water tank to redirect the collected water back into the plant watering reservoir, which actually helped reduce the need to water the plant as often as an added bonus. I bought Neem oil as a natural fungicide to protect the edibility of the fruit, but it was futile at stopping the mold and only did so much as deter flies. In such a moist, enclosed setting, with plants growing in dirt, fungus was inevitable, but it got quite bad. Unfortunately I had to cave to a powerful toxic synthetic fungicide, which almost overnight completely ridded the plants of fungus, but had effectively made them ornamental for months to come. In the meantime I began planning for the next season, contriving a solution to prevent the fungus before it were to start. To me, the culprit was clear: it was the soil. I'd have to go dirt-less.\n\n# Hydroponic Transition\n\n## The Transition\n\n![Germinating basil plants](https://static.404wolf.com/germinatingSeeds_0001.webp)\n![Lights on](https://static.404wolf.com/germinatingSeedsLightOn_0001.webp)\n\nThrough the previous strawberry endeavor, I learned a lot. Keeping the environment clean is key, and consistency maximizes yield. Before setting up the next crop, I moved the strawberries out onto a deck, and completely bleached out the closet to kill all residual mold. While the Arduino was fun to tinker with, it'd be in the best interest of the plants to go with a more robust and consistent system this next time around. For the upcoming crop, I chose to implement hydroponics, a technique wherein the plants grow with their roots directly in nutrient water or mist, eliminating the need for soil. Hydroponics is really neat since the plants grow on average 30% faster and use up to 10x less water. I also opted for [preventative biofungicide](https://southernag.com/product/garden-friendly-fungicide/), which utilizes naturally occurring soil bacteria that 'eat' fungus: a fungicide that's not only non-toxic to humans, but scientifically proven effective. For the seeds, I bought generic basil seeds, which I'd soon realize was highly unideal. And, for the germination medium, I went with rockwool (instead of a make-shift paper towel like I did for the strawberries). Rockwool is a fluffy stuffing-like material, used most frequently in insulation, but also commonly botanically.\n\n## Assembled Grow Tower\n\n![Basil grow rack](https://static.404wolf.com/basil_tower.webp)\n\nFor my first attempt, I decided to go with an Amazon [basil grow rack](https://www.amazon.com/gp/product/B0787F9LG7/), since it claimed to provide an all-in-one system that could assemble quickly and easily. A bit weary of leakage, I carefully put it together, and placed my basil seeds into the included grow pods. For the first few weeks, while figuring out ideal nutrient ratios and water acidity, the basil did successfully began growing. However, I quickly ran into a roadblock: the small tubes were being jammed by the ever-growing plants' roots. The larger they got, the more unwieldy the system became, and the less water they received. Moreover, cleaning the system was virtually impossible without removing all the plants and disassembling the tubes, since the roots were jamming themselves in the tubes. Unfortunately, I needed to change gears, but, on the brighter side, I did establish hydroponic basil as a plant with potential.\n\n## Custom Vertical Tower\n\n![Hydroponic vertical grow tower](https://static.404wolf.com/hydroponic_grow_tower.webp)\n\nThe first idea for the overhaul was to build a vertical [hydroponic grow tower](https://extension.okstate.edu/fact-sheets/building-a-vertical-hydroponic-tower.html). In the setup, a pump would turn on every 10 minutes for 10 minutes, carrying water to the top of the system, and letting it drip on and drench the roots. Vertical systems like the one pictured don't require an additional air system, since the roots are constantly exposed to direct air. Another key advantage is space efficiency: whereas in typical systems the plants height is limited because of bushing tendencies, with a vertical system the space of my closet could be maximized by having multiple towers of the height of my closet. Instead of buying a kit this time, I made my own vertical system by drilling holes along a large PVC tube, and then placing smaller segments of tube within the holes. Unfortunately the product didn't work out, since my pump was so powerful as to propel water out and along the edges of the tube, wetting the outside of the central tower and fostering algae. Additionally, the tower itself was particularly difficult to keep upright, even amidst many ropes and wires, and since this setup involves water dripping down the central tube, it was extremely loud. It was disappointing, but I wasn't defeated. It was time for another method.\n\n# Deep Water Culture\n\n![Deep water culture system](https://static.404wolf.com/deepWaterCulture.webp)\n\nMy first success: deep water culture (DWC) hydroponics. In DWC hydroponics, plant roots are suspended in a nutrient-rich water solution, with airstones constantly pumping air into the water, allowing the roots to maximally absorb the nutrients and minerals. The system itself is extremely simple on paper, but requires managing large reservoirs of liquid—ensuring that they hover around the right acidity level, that there's the right fertilizer amount, and that they stay fungus-free. The approach seemed much more feasible than any of my prior systems, since I'd just need a few bins and grow baskets. Agog to proceed, I got to work planning.\n\n## Setup\n\n![Grow baskets](https://static.404wolf.com/grow_baskets.webp)\n\nTo start, I purchased [three large storage containers from Lowes](https://www.lowes.com/pd/Style-Selections-30-Gallon-120-Quart-Gray-Tote-with-Standard-Snap-Lid/1000183149). While food safety is obviously of importance, food grade bins are astronomically expensive, so I settled on bins with food-safe plastic composition, even though they weren't technically rated food grade. My plan was to use a [super large 3\" drill bit](https://www.amazon.com/gp/product/B07ZRVM7WM/) and some [3\" grow baskets](https://www.amazon.com/dp/B08CGVL9FW) filled with pebbles to hold the plants in place. The air pumps I used were initially small bubblers, but, after later learning that 1 wat of air pumping power per liter of liquid is the general practice in hydroponics, went with [two commercial air pumps](https://www.amazon.com/gp/product/B078H92695/). Since they were extremely loud, I also threw in some [vibration dampening pads](https://www.amazon.com/gp/product/B0042U92TE/) that cut down on the sound a bit, and placed a dollar-store fan above the air pumps to prevent overheating.\n\n### Progress\n\n![Baby plants](https://static.404wolf.com/baby_pepper.webp)\n![Early growth](https://static.404wolf.com/early_growth.webp)\n![Pruning basil](https://static.404wolf.com/pruning_basil.webp)\n\nThe system was all set up, so now all that was left was to wait. The plants germinated flawlessly, and were quickly ready to be placed into the pebble-stuffed grow cups. The tanks were full and fertilized, and the air pumps and lights' timers had been configured properly in advance. The new DWC setup worked like magic, requiring extremely low maintenance and yielding extremely high loads of basil. Unlike my strawberries, there was no soil involved, so the setup was significantly cleaner and more maintainable. Something that I quickly learned is that basil **requires** meticulous pruning to maximize yield, which explains why the basil from my previous tower-approach grew as vertical stalks. By cutting between the leaf stalks, I was able to get the plant to branch out into a bush, rather than the tall stalks I had in my older systems. With such rapid growth, the harvests quickly began rolling in. It was finally time to start producing pesto.\n\n## Pesto Production\n\n![Pesto-packed freezer](https://static.404wolf.com/frozen_pesto.webp)\n![A harvest](https://static.404wolf.com/a_harvest.webp)\n![Bowl of pesto](https://static.404wolf.com/pesto_bowl.webp)\n\nWhile indeed the basil tasted great as a salad mix-in and pasta topper, pesto was the inevitable real deal. It was one of the primary reasons I chose basil: as the plants grew beyond my appetite, it'd be super easy to freeze the final product. For the first few rounds of pesto, I kept it super simple, just blending together basil, salt, and a bit of olive oil and garlic. As the batches went on, I started getting more creative, experimenting with adding walnuts and almonds, along with weirder ingredients like kale and hot peppers. Each week I reaped around 2 cups of pesto, which I froze in ice cube molds and then zip locked, so that I could microwave one cube at a time as needed. Over the weeks, the freezer filled with pesto, and, even two years later we still have a seemingly endless supply.\n\n## Basily Takeaways\n\nThe deep water culture system seemed to be the best route, yielding the greatest amount of basil while being extremely easy to maintain. I decided to keep up the system for a few years, slowly building off of prior years by improving the setup. I switched to [special basil seeds](https://extension.umn.edu/disease-management/basil-downy-mildew), which have been bred to be resistant to the most common basil illness downy mildew. During my first few years I worried that the basil had mites, but shortly learned that they were in fact the buds of roots. I also spraypainted the bins with a layer of opaque black, followed by two layers of white, to prevent light from penetrating the water and causing algae. I also upgraded my air stone system to new, larger disc airstones, which provide a much steadier and higher quality flow of air. I also installed a fan in the ceiling of the closet, along with two smaller fans on the walls, aimed at the plants and machinery. Since the fans use lots of electricity, they are set on timers to turn off an hour after the lights, and on when the lights turn on. And finally, I've switched my rope out paracord, which is much more durable, easier to work with, and overall sleeker.\n\n# The New Shishitos\n\n## The choice\n\n![Current setup](https://static.404wolf.com/new_cording.webp)\n\nWith my optimized system already assembled and ready for the next year's plant, I've entered research mode once more. Basil was great because of how rapidly it grew, but, equally important, that its product (pesto) could be frozen. Surfing through the vast array of potential hydroponic candidates, including tomatos, bell peppers, lettice, spinach, and more, I eventually settled on Shishito peppers. They were the perfect match: tasty, roast-able, and freezable. And, most importantly, unlike many other types of peppers, they're particularly fast growing.\n\n## Progress\n\n![Peppers (exterior view)](https://static.404wolf.com/outside_closet_view_of_peppers.webp)\n![Peppers (side view)](https://static.404wolf.com/peppers_side_view.webp)\n\nSince germination, the peppers have been growing rapidly, day after day. After some research, I learned that in the past I'd been using way less fertilizer than I could have been, so I've increased my concentration. Additionally, I quickly learned that the new, cheaper tubing that I purchased this year was completely unsuitable for my purposes, as the acidic water quickly ate away at the plastic, and the tubing began to leak. My check valves (valves that you put on a tube that force water to only travel in one direction) worked, preventing the water from entering the expensive electric air pumps, but still allowed the water to leak onto my floor. Luckily I'd installed some water sensors on the floor, and was able to quickly dry the floor. Since this incident, I moved the air pumps to a higher location (even though the check valves worked, I was scared of the possibility of them not working, and having the water pumps higher up would make it impossible for the water to backflow into the pumps). I switched to a much higher quality PVC clear tubing, and have had no issues since.\n\n![Lights on!](https://static.404wolf.com/peppers_side_view_lights_on.webp)\n\nAt this point there are no actual peppers on the plants. The fertilizer I've been using is optimized for foliage growth, so I'm fairly certain that that has been why the peppers haven't begun to grow. Soon I'll be switching to a different fertilizer, which is optimized for fruit growth, which should kickstart flowering. After a bit of research, I've also come to find that peppers require pollination in order to produce fruit, so, while there is indeed a notable wind current in the closet due to the fans, it may not be enough, and I may need to learn how to manually pollinate the plants. Since this is an ongoing project, I'll be sure to keep updating this post as the peppers grow (and hopefully eventually make it into my freezer \\[and stomach!]).","src/posts/Hydroponics.mdx","7fdde885b4bc2784","linuxclassportfolio",{"id":137,"data":139,"body":149,"filePath":150,"digest":151,"deferredRender":26},{"title":140,"type":9,"date":16,"covers":141,"tags":147,"description":148},"CWRU Linux Scripting Class Portfolio",[142,143,144,145,146],"https://static.404wolf.com/Screenshot_from_2024-04-14_23-29-12_0001.png","https://static.404wolf.com/Screenshot_from_2024-04-14_23-29-31_0001.png","https://static.404wolf.com/Pasted_image_20240414232043_0001.png","https://static.404wolf.com/Linux-desktopentry_0001.png","https://static.404wolf.com/Screenshot_from_2024-04-16_18-15-57_0001.png",[21],"This is my portfolio for Professor Ronald Loui's CSDS285 @ CWRU, a class that teaches various Linux tools and concepts, like bash, awk, regex, and bottom-up design. It's an eclectic mix of scripts and Linux-y things I've done with the stuff I've learned throughout the semester in the course. There are a few projects towards the beginning, and then I have a bunch of random bash scripts and more Linux-y things towards the bottom portion.\n","# Linux Scripting/Tools Class Portfolio\n\n# What's this?\n\nThis is my portfolio for Professor Ronald Loui's CSDS285 @ CWRU. It's an eclectic mix of scripts and linux-y things I've done with the stuff I've learned throughout the semester in the course.\n\n# Some Projects/Scripts\n\n## [Text Sender](http://sender.404wolf.com/)\n\n![Desktop version](Screenshot_from_2024-04-14_23-29-12_0001.png|float=none|width=70)\n\n### What is it?\n\nText sender is a basic website that uses client side Javascript to poll a PHP server to obtain the current text contents of a Redis cache. The server is deployed to AWS and is publicly accessible through AWS. The live polling is a feature I added later on, and I also added bootstrap to make the website look nice.\n\nThe current contents of the text box are accessed from redis by PHP using [PHPRedis](https://github.com/phpredis/phpredis). I decided to use [composer](https://getcomposer.org/) to manage this package, since it made installing it super easy. The project is also dockerized, so it can be easily deployed, and uses `Nginx` to serve the content.\n\n### Uses\n\n- Sending text data between devices (shipping from phone to phone or desktop to phone etc)\n- Sharing data in front of a live audience\n- Conversations and interactive use\n\n![Network Logs](https://static.404wolf.com/Screenshot_from_2024-04-14_23-29-31_0001.png)\n![Mobile Version](https://static.404wolf.com/Screenshot_from_2024-04-14_23-26-55_0001.png)\n\nOriginally, I used the file system to cache the contents, but migrated for performance and to learn how to do Redis in PHP. I also added bootstrap to make it look nicer.\n\nBasically, you can visit [sender.404wolf.com](http://sender.404wolf.com) and you'll be met with a text input box. You can plop text into it, and it will show up to date contents. If you go to a different device or tab it will keep in sync the current content.\n\nAll of the source code can be found [here](https://github.com/404Wolf/Code-Ship), since it's a bigger project than can reasonably fit here. But here's some of the important PHP code.\n\nIt's made of two parts: backend API and frontend client. The first codeblock is the main page with the actual layout and input boxes. The second codeblock is a backend that the clients use to update the state of the redis cache.\n\n### Changelog\n\n- Version 1 - Create basic working version that stores state in file.\n- Version 2 - Add redis with PHP redis. Get working on localhost\n- Version 3 - Add compose.yml and dockerize. Then deploy to aws and use Nginx to serve\n\n```php\n// Index.php\n\n\u003C!doctype html>\n\u003Chtml lang=\"en\">\n\n\u003C?php\nrequire_once __DIR__ . '/vendor/autoload.php';\nrequire 'vendor/autoload.php';\nPredis\\Autoloader::register();\n\n$client = new Predis\\Client([\n    'scheme' => 'tcp',\n    'host'   => 'redis',  // Use the service name as the hostname\n    'port'   => 6379,  // Default port for Redis\n]);\n\nfunction injectVariable($name, $value)\n{\n\t// Add important env variables to the global scope by putting them in a script\n\t// tag like this.\n    echo '\u003Cscript> const ' . $name . ' = \"' . $value . '\"; \u003C/script>';\n}\n?>\n\n\u003Chead>\n    \u003C!-- Required meta tags -->\n    \u003Cmeta charset=\"utf-8\">\n    \u003Cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n\n    \u003C!-- Bootstrap CSS -->\n    \u003Clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css\" integrity=\"sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T\" crossorigin=\"anonymous\">\n\n    \u003C!-- Favicon -->\n    \u003Clink rel=\"icon\" href=\"favicon.ico\" type=\"image/x-icon\">\n\n    \u003C!-- Page metadata -->\n    \u003Ctitle>Send it!\u003C/title>\n\n    \u003Cstyle>\n        .bg-light-gray {\n            background-color: #f8f9fa;\n        }\n    \u003C/style>\n\n    \u003C?php\n    // Add some constants to the global scope\n    injectVariable('MAX_LENGTH', $_ENV['MAX_LENGTH']);\n    injectVariable('ADDRESS', $_ENV['ADDRESS']);\n    injectVariable('PORT', $_ENV['PORT']);\n    injectVariable('REFRESH_RATE', $_ENV['REFRESH_RATE'])\n    ?>\n\n    \u003C!-- Setup webhook on load -->\n    \u003Cscript>\n        let priorContents = false;\n\n        function setInputAreaText(text) {\n            document.getElementById(\"text-to-send\").value = text;\n        }\n\n        function getInputAreaText() {\n            return document.getElementById(\"text-to-send\").value;\n        }\n\n        function shipNewContents() {\n            const newContents = document.getElementById(\"text-to-send\").value;\n            console.log(\"Shipping the contents of the text area. New contents: \" + newContents);\n            fetch(`${ADDRESS}:${PORT}/state.php`, {\n                    method: \"POST\",\n                    headers: {\n                        \"Content-Type\": \"application/json\"\n                    },\n                    body: JSON.stringify({\n                        text: newContents.slice(0, MAX_LENGTH),\n                    })\n                })\n                .then(response => response.json())\n                .then(data => {\n                    console.log(data);\n                })\n                .catch(error => {\n                    console.log(error);\n                })\n        }\n\n        function justUpdated() {\n\t        // new Date() returns a new date object with the current time\n            document.getElementById(\"last-update\").innerText = \"Updated at \" + formatTime(new Date());\n        }\n\n        function beginPolling() {\n            setInterval(() => {\n\n                console.log(\"Attempting poll @\" + (new Date()))\n                const textArea = document.getElementById(\"text-to-send\");\n                if (textArea.value !== priorContents) {\n                    console.log(\"New contents detected. Shipping new contents.\");\n                    shipNewContents();\n                    priorContents = textArea.value;\n                    justUpdated();\n                    return\n                }\n\n                fetch(`${ADDRESS}:${PORT}/state.php`)\n                    .then(response => response.json())\n                    .then(data => {\n                        if (data.text !== priorContents) {\n                            console.log(\"Received new text contents. Updating text area.\");\n                            setInputAreaText(data.text);\n                        }\n                        justUpdated();\n                    })\n            }, REFRESH_RATE);\n        }\n\n        function formatTime() {\n            const date = new Date();\n\n            let hours = date.getHours();\n            const minutes = date.getMinutes();\n            const seconds = date.getSeconds();\n            const ampm = hours >= 12 ? 'PM' : 'AM';\n\n            hours = hours % 12;\n            hours = hours ? hours : 12; // the hour '0' should be '12'\n            const strHours = hours \u003C 10 ? '0' + hours : hours;\n            const strMinutes = minutes \u003C 10 ? '0' + minutes : minutes;\n            const strSeconds = seconds \u003C 10 ? '0' + seconds : seconds;\n\n            return strHours + ':' + strMinutes + ':' + strSeconds + ' ' + ampm;\n        }\n\n        addEventListener(\"DOMContentLoaded\", () => {\n            beginPolling();\n        })\n    \u003C/script>\n\u003C/head>\n\n\u003C/script>\n\u003C/head>\n\n\u003Cbody>\n    \u003C!-- Main container for body -->\n    \u003Cdiv class=\"container\">\n        \u003Cdiv class=\"row mt-5 justify-content-center\">\n            \u003Cdiv class=\"my-4 p-3 pb-0 border col-10 bg-light-gray\">\n                \u003Ch1 class=\"w-75 text-center mx-auto mb-2\">Sender\u003C/h1>\n                \u003Cp>\n                    Share your code! Whatever you enter below becomes what everyone visiting this site sees,\n                    and the current contents on the page will be lost.\n                \u003C/p>\n\n                \u003C!-- Area for user input -->\n                \u003Ccode id=\"code-text-area\">\n                    \u003Ctextarea class=\"form-control font-monospace text-sm\" style=\"min-height: 32rem; font-size: 12px\" id=\"text-to-send\" rows=\"3\">\n\u003C?php\necho $client->get('text');\n?>\n\u003C/textarea>\n                \u003C/code>\n\n                \u003C!-- Last update timestamp -->\n                \u003Cp class=\"text-right -mb-2\" id=\"last-update\">\n                    Updated at \u003C?php echo date(\"h:i:s A\"); ?>\n                \u003C/p>\n            \u003C/div>\n        \u003C/div>\n    \u003C/div>\n\n    \u003Cfooter style=\"background-color: #f2f2f2; padding: 10px; position: fixed; bottom: 0; width: 100%;\" class=\"container-fluid text-right border\">\n        Made by \u003Cspan>\u003Ca href=\"http://404wolf.com\" target=\"_blank\">Wolf\u003C/a>\u003C/span>\n    \u003C/footer>\n\u003C/body>\n\n\u003C/html>\n```\n\n```php\n// state.php\n\u003C?php\nrequire_once __DIR__ . '/vendor/autoload.php';\nrequire 'vendor/autoload.php';\nPredis\\Autoloader::register();\n\n$client = new Predis\\Client([\n    'scheme' => 'tcp',\n    'host'   => 'redis',  // Use the service name as the hostname\n    'port'   => 6379,  // Default port for Redis\n]);\n\nif ($_SERVER['REQUEST_METHOD'] === 'POST') {\n    // Get the JSON data from the request body\n    $data = @json_decode(file_get_contents('php://input'), true);\n\n    // Make sure that the new text is not too long\n    if (strlen($data['text']) > 100000) {\n        http_response_code(400);\n        echo json_encode([\"error\" => \"Input text too long\"]);\n        exit();\n    }\n\n    // Dump the contents to the contents file\n    $client->set('text', $data['text']);\n\n    http_response_code(200);\n    echo json_encode([\"success\" => true]);\n}\n\nif ($_SERVER['REQUEST_METHOD'] === 'GET') {\n    $contents = $client->get('text');\n    $contents = json_encode([\"text\" => $contents]);\n    if ($contents === null) {\n        http_response_code(404);\n        echo json_encode([\"error\" => \"No data found\"]);\n        exit();\n    }\n    echo $contents;\n}\n```\n\nAlso, here is the `Nginx` config that serves the website. I haven't used `Nginx` before, but it wasn't too bad to set up and it works well. ChatGPT helped me configure this and also added all the comments.\n\n```nginx\nserver\n{\n\t# Listen on all interfaces on port 80\n\tlisten 0.0.0.0:80;\n\n\t# Set the root directory for requests\n\troot /var/www/html;\n\n\t# Default location block\n\tlocation /\n\t{\n\t\t# Specify index files to be served\n\t\tindex index.php index.html;\n\t}\n\n\t# Location block for processing PHP files\n\tlocation ~ \\.php$\n\t{\n\t\tinclude fastcgi_params; # Include FastCGI parameters\n\t\tfastcgi_pass php:9000; # Forward PHP requests to the FastCGI server on port 9000\n\t\tfastcgi_index index.php; # Default file to serve\n\t\tfastcgi_param SCRIPT_FILENAME $document_root/$fastcgi_script_name; # Set the script filename\n\t}\n\n\t# Location block for serving a specific file (contents.json)\n\tlocation = /contents.json\n\t{\n\t\talias /var/www/html/contents.json; # Directly serve contents.json file from path\n\t}\n}\n```\n\n## Discord/Betterdiscord Installer\n\n### What it is\n\n![Discord update popup](https://static.404wolf.com/https://static.404wolf.com/discords-lucky-day-hits-arch-btw-once-again-with-no-update-v0-p4j4bweuu0ca1_0001.webp)\n\n[Discord](https://discord.com) (chatting app) requires you to completely redownload the app whenever there are updates on Desbian. It makes a popup that says that you need to download a whole new binary each time there is an update. Additionally, I use a client called [BetterDiscord](https://betterdiscord.app) that requires you to \"patch\" Discord every time you install it. This means that every now and then, I open discord, and have to manually install a new version and then also re-patch it with Betterdiscord. It's a pain in the neck every time updates are released.\n\n```bash\n#!/usr/bin/bash\n\n# get the \"location\" header from https://discord.com/api/download/stable?platform=linux&format=tar.gz and store it in a variable\n\n\n# code for finding location and cleaning it up is a friend's\n# ===== GET THE DOWNLOAD URL =====\nlocation=$(curl -sI \"https://discord.com/api/download/stable?platform=linux&format=tar.gz\" | grep -i location | awk '{print $2}')\n\n# fix formatting of location to prevent \"bad substitution\" error\nlocation=$(\n    echo $location | sed 's/\\r//'\n)\n\n# ===== GET THE DOWNLOAD URL =====\n\n# download the discord.tar.gz (overwrite if it already exists)\ncurl -L -o discord.tar.gz $location\n\n# Extract the tar file and overwrite ~/.local/share/Discord\n# Modified code from a friend.\n# -x = extract files from archive\n# -v verbose\n# -f use the following tarball file\n# The program currently doesn't run on my main laptop because discord's location doesn't seem to be ~/.local/share\ntar -xvf discord.tar.gz -C ~/.local/share --overwrite\n\n# The following is all my code. It uses Betterdiscordctl to patch discord if it isn't already patched\n\n# Remove the tar file from the current directory that we just downloaded it to\nrm discord.tar.gz\n\n# Define betterdiscordctl path\nbetterdiscordctl=/usr/local/bin/betterdiscordctl\n\n# Check if BetterDiscord is already installed\nif ! $betterdiscordctl status | grep -q \"no\"; then\n  # If BetterDiscord is already installed, print a message and do nothing\n  echo \"BetterDiscord is installed.\"\n  # Check if Discord is running and restart it after installing BetterDiscord\n  else\n    discordRunning=$(pgrep Discord)\n    killall Discord\n    $betterdiscordctl install\n    if [ $discordRunning ]; then\n      nohup discord &\n    fi\nfi\n```\n\nOutput of running script:\n\n```terminal\nwolf@wolfs-laptop:~/Scripts/BetterDiscord$ source install.sh\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 96.8M  100 96.8M    0     0  24.3M      0  0:00:03  0:00:03 --:--:-- 24.3M\nDiscord/\nDiscord/libffmpeg.so\n... the various things that get unpacked unpack ...\nDiscord/discord.desktop\nBetterDiscord is installed.\n```\n\nOriginally this script only installed Betterdiscord, but I added the part to install Discord itself too after.\n\nI added the part that installs Discord after and changed it slightly for my needs, which a friend had written for themselves. I wrote the part that installs betterdiscord myself, which uses an open source tool called `betterdiscordctl`. Basically, it checks to see if betterdiscord is installed, and if it isn't then it re-patches discord.\n\nI then put it in my `crontab` to run automatically every day using\n\n```\n0 10 * * * /home/wolf/Scripts/BetterDiscord/install.sh\n```\n\nI won't know if this works until Discord releases an update, though.\n\n## Case Room Selection Utility\n\n![Website](https://static.404wolf.com/Screenshot_from_2024-04-21_16-15-04_0001.png)\n![Loading... Part](https://static.404wolf.com/Screenshot_from_2024-04-21_16-14-57_0001.png)\n\nI made a very complex python webserver with a selenium virtual chromedriver to get an auth token to Case's room reservation system. Then I use that token to find all rooms that are not taken from X to Y time, so I can find a study room. I created a basic html/css/js page that hits the website and displays vacant rooms, and has textual input. It uses the API I built previously.\n\nTLDR: I have an API to find empty rooms on campus. I made a frontend for it.\n\nDISCLAIMER:\nI wrote this HTML/JS for this course portfolio, but it doesn't work at the moment only because of a dependency that I wrote outside of this course. I'm still going to include it since I think it's pretty cool.\n\nThe API was down when writing this to get screenshots, and I'm currently fixing a part of the authing flow. However, the general idea is that you can see it load and then fetch all empty rooms on campus.\n\n### Changelog\n\n- Make basic page to view the courses that lists all empty rooms\n- Add user inputs to specify hours and duration\n- Add loading animation, add clickable links to share\n\n```html\n\u003Chtml>\n  \u003Cscript type=\"text/javascript\">\n    const url = \"http://149.28.40.6:5000/find-rooms\";\n\n    function getRoomURL(duration_hours, hours_from_now) {\n      const params = {\n        duration_hours: duration_hours,\n        hours_from_now: hours_from_now,\n      };\n      const queryString = Object.keys(params)\n        .map((key) => key + \"=\" + params[key])\n        .join(\"&\");\n      return url + \"?\" + queryString;\n    }\n\n    function findRooms(duration_hours, hours_from_now) {\n      const path = getRoomURL(duration_hours, hours_from_now);\n\n      return fetch(path, {\n        headers: {\n          \"Content-Type\": \"application/json\",\n        },\n      }).then((resp) => resp.json());\n    }\n\n    function parseFoundRooms(rooms) {\n      rooms = rooms[\"rooms\"];\n      rooms = rooms.sort((a, b) =>\n        a.building_code > b.building_code ? 1 : -1,\n      );\n      return rooms\n        .map((room) => room.building_code + \" \" + room.room_code)\n        .join(\"&#10;\");\n    }\n\n    function displayResults(results) {\n      const resultsBox = document.getElementById(\"results-box\");\n      resultsBox.innerHTML = results;\n    }\n\n    function onGetResultsClick() {\n      // Get the form values\n      const duration_hours = document.getElementById(\"duration_hours\").value;\n      const hours_from_now = document.getElementById(\"hours_from_now\").value;\n\n      // Run the query\n      findRooms(duration_hours, hours_from_now)\n        .then((results) => parseFoundRooms(results))\n        .then(displayResults);\n      document.getElementById(\"results-url\").href = getRoomURL(\n        duration_hours,\n        hours_from_now,\n      );\n\n      // Update the results area header\n      document.getElementById(\"results-area-head\").innerHTML =\n        \"Results for \" +\n        duration_hours +\n        \" hours from now, for \" +\n        hours_from_now +\n        \" hours\";\n      document.getElementById(\"results-box\").innerHTML = \"Loading...\";\n\n      // Reset the form\n      document.getElementById(\"duration_hours\").value = \"\";\n      document.getElementById(\"hours_from_now\").value = \"\";\n    }\n  \u003C/script>\n\n  \u003Chead>\n    \u003Ctitle>Room Finder\u003C/title>\n  \u003C/head>\n\n  \u003Cbody>\n    \u003C!-- Header -->\n    \u003Ch1 style=\"text-align: center;\">Room Finder\u003C/h1>\n    \u003Ch2 style=\"text-align: center;\">Find an unbooked CWRU room\u003C/h2>\n\n    \u003C!-- Form area -->\n    \u003Cdiv style=\"display: flex; justify-content: space-between;\">\n      \u003Cdiv>\n        \u003Clabel for=\"duration_hours\">Duration in hours\u003C/label>\n        \u003Cinput\n          type=\"number\"\n          id=\"duration_hours\"\n          placeholder=\"Duration in hours\"\n          value=\"0\"\n        />\n      \u003C/div>\n\n      \u003Cdiv>\n        \u003Clabel for=\"hours_from_now\">Hours from now\u003C/label>\n        \u003Cinput\n          type=\"number\"\n          id=\"hours_from_now\"\n          placeholder=\"Hours from now\"\n          value=\"6\"\n        />\n      \u003C/div>\n\n      \u003Cbutton onclick=\"onGetResultsClick()\">Find a room\u003C/button>\n    \u003C/div>\n\n    \u003C!-- Results area -->\n    \u003Cdiv>\n      \u003Ca id=\"results-url\">\u003Ch3 id=\"results-area-head\">Results Area\u003C/h3>\u003C/a>\n      \u003Ctextarea\n        readonly\n        style=\"width: 100%; min-height: 40vh;\"\n        id=\"results-box\"\n      >\nResults will appear here\n            \u003C/textarea\n      >\n    \u003C/div>\n  \u003C/body>\n\u003C/html>\n```\n\n## Archive Utility\n\n### What is it?\n\nA tool that lets you zip something and then move it into `/home/Archive` automatically.\n\nBasically, you run `bash archive.sh file_to_be_archived.extension`, and it automatically 7z compresses it, moves the file, and deletes the old uncompressed file.\n\nAfter I made it I added some basic error handling, and automatically will add a `_121` (counter) to the back of the file if there are duplicates already in the out directory (`_121` indicates 120 other files already exist with its name).\n\n### Changelog\n\n- Make basic working version that archives an input\n- Add filename checking\n- Prevent duplicate clobbering by incrementing filename\n\n```bash\n#!/bin/bash\n\n# Name the argument for the filename\nfile=$1;\n\n# Grab the extension and file name seperately and assign them to variables\nfilename=$(echo $file | grep -o '^[^\\.]*');\nextension=$(echo $file | grep -o '\\..*$');\nout_filename=$filename;\n\n# VERSION 2 -- ADD FILENAME CHECK\n# If the file is not passed exit\nif [ -z $file ]; then\n  echo \"No filename provided\";\n  exit 1;\nfi\n\n# If the file does exist then make a new one with a affixed ID\n# VERSION 3 -- ADD FILE NAME INCREMENT\nif [ -e \"$out_filename.7z\" ]; then\n  ticker=1;\n  while [ -e \"$file_$ticker.7z\" ]; do\n    ((ticker++)); # Increment the counter\n  done\n  out_filename=\"${filename}_${ticker}\";\nfi;\n\nout_filename=\"${out_filename}.7z\";\necho \"Archiving $file to $out_filename.7z\";\n7z a \"$out_filename\" \"$file\";\n# Need to keep ~/Archive/ out of quotes since ~ must be expanded properly\nmv $out_filename ~/Archive/\n\n# Check status and if the archive was successful report it and delete the old file\nif [ $? -eq 0 ]; then\n  echo \"Archive $filename.7z created successfully\";\n  rm -i -r $file;\nelse\n  echo \"Failed to create archive $filename.7z\"\nfi\n```\n\n### Example use:\n\n```shell\nwolf@wolfs-laptop:~/Desktop/Projects/Archiver$ tree\n.\n└── archive.sh\n\n0 directories, 1 file\nwolf@wolfs-laptop:~/Desktop/Projects/Archiver$ echo \"{ 'test' : 'test' }\" > test.json\nwolf@wolfs-laptop:~/Desktop/Projects/Archiver$ tree\n.\n├── archive.sh\n└── test.json\n\n0 directories, 2 files\nwolf@wolfs-laptop:~/Desktop/Projects/Archiver$ alias archive=\"bash archive.sh\"\nwolf@wolfs-laptop:~/Desktop/Projects/Archiver$ archive test.json\nArchiving test.json to test.7z.7z\n\n7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\np7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,8 CPUs 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (806C1),ASM,AES-NI)\n\nScanning the drive:\n1 file, 20 bytes (1 KiB)\n\nCreating archive: test.7z\n\nItems to compress: 1\n\n\nFiles read from disk: 1\nArchive size: 146 bytes (1 KiB)\nEverything is Ok\nArchive test.7z created successfully\nrm: remove regular file 'test.json'? yes\nwolf@wolfs-laptop:~/Desktop/Projects/Archiver$ ls\narchive.sh\nwolf@wolfs-laptop:~/Desktop/Projects/Archiver$ z ~/Archive\nwolf@wolfs-laptop:~/Archive$ ls\ntest.7z\n```\n\n## Move types into folders\n\nI made a very basic script that moves files into folders named after their file type. It iterates through files in the current directory and moves each file to a folder named after its extension.\n\n### Changelog\n\n- Make a basic script to move different filetypes into different folders\n- Add protections, like ensuring the script file itself isn't moved, or that directories aren't touched or changed.\n\nChatGPT helped me figure out how to iterate over files in a directory (it is shockingly easy!).\n\n```bash\nfor file in ./*; do\n\t# Skip if the file is the script itself.\n\tif [ $file == \"./folderFileType.sh\" ]; then\n\t\techo \"Skipping $file because it is the script itself.\";\n\t\tcontinue;\n\tfi;\n\n\t# Skip if the file is a folder.\n\tif [ -d $file ]; then\n\t\techo \"Skipping $file because it is a folder.\";\n\t\tcontinue;\n\tfi;\n\n\techo \"Processing $file\";\n\n\t# Get the suffix of the file.\n\t# \"##\" means remove the longest match from the beginning.\n\t# Note that \"*.\" is not regex, it's a shell pattern.\n\tFILE_SUFFIX=${file##*.};\n\n\t# Create a folder with the same name as the suffix.\n\t# \"-p\" means create the parent folder if it doesn't exist.\n\t# \"-v\" means print the name of the folder.\n\tmkdir -p -v $FILE_SUFFIX;\n\tmv -v $file $FILE_SUFFIX;\n\techo \"Processed $file by moving it to $FILE_SUFFIX\";\ndone;\necho \"All files processed.\";\n```\n\n### Before, during, and after\n\n```bash\nwolf@wolfs-laptop:~/Scripts/Tests$ tree\n.\n├── anotherTest.c\n├── anotherTest.cc\n├── anothertest.js\n├── anotherTest.ts\n├── folderFileType.sh\n├── test.py\n├── test.test\n├── test.ts\n└── test.txt\n```\n\n```bash\nProcessing ./anotherTest.c\nmkdir: created directory 'c'\nrenamed './anotherTest.c' -> 'c/anotherTest.c'\nProcessed ./anotherTest.c by moving it to c\nProcessing ./anotherTest.cc\nmkdir: created directory 'cc'\nrenamed './anotherTest.cc' -> 'cc/anotherTest.cc'\nProcessed ./anotherTest.cc by moving it to cc\nProcessing ./anothertest.js\nmkdir: created directory 'js'\nrenamed './anothertest.js' -> 'js/anothertest.js'\nProcessed ./anothertest.js by moving it to js\nProcessing ./anotherTest.ts\nmkdir: created directory 'ts'\nrenamed './anotherTest.ts' -> 'ts/anotherTest.ts'\nProcessed ./anotherTest.ts by moving it to ts\nSkipping ./folderFileType.sh because it is the script itself.\nProcessing ./test.py\nmkdir: created directory 'py'\nrenamed './test.py' -> 'py/test.py'\nProcessed ./test.py by moving it to py\nProcessing ./test.test\nmkdir: created directory 'test'\nrenamed './test.test' -> 'test/test.test'\nProcessed ./test.test by moving it to test\nProcessing ./test.ts\nrenamed './test.ts' -> 'ts/test.ts'\nProcessed ./test.ts by moving it to ts\nProcessing ./test.txt\nmkdir: created directory 'txt'\nrenamed './test.txt' -> 'txt/test.txt'\nProcessed ./test.txt by moving it to txt\nAll files processed.\n```\n\n```bash\nwolf@wolfs-laptop:~/Scripts/Tests$ tree\n.\n├── c\n│   └── anotherTest.c\n├── cc\n│   └── anotherTest.cc\n├── folderFileType.sh\n├── js\n│   └── anothertest.js\n├── py\n│   └── test.py\n├── test\n│   └── test.test\n├── ts\n│   ├── anotherTest.ts\n│   └── test.ts\n└── txt\n    └── test.txt\n\n7 directories, 9 files\n```\n\n## React Native Boot Script\n\n![Video of it running](Screencast_from_04-23-2024_062229_PM_0001.webm|float=none|width=100)\n\n![Example of it running](https://static.404wolf.com/Pasted_image_20240414232043_0001.png)\n\n### TLDR\n\n```\nwolf@wolfs-laptop:~$ lt -p 8080\nyour url is: https://petite-ends-stay.loca.lt\n```\n\nLocaltunnel maps a public URL to your localhost at a port. This is a script that runs `lt -p 8080` in the background, extracts the URL, exports it as an env variable, and then launches a process that requires it. It also does some basic environment setup.\n\n### Why?\n\nWhen I boot a react native app (mobile app development framework that I'm using to make an Android app) project with the Metro bundler (a development tool for shipping the app to a virtual Android device) to get it to run usually my project needs me to manually do these things:\n\n1. Start the android emulator and press `super shift t` to set it to be always on top (so it sits on top of my IDE)\n2. Start a HTTPS tunnel so I can access `localhost:8080` (where my API lives) from the android device\n3. Run the bundler to boot the app on the emulator\n4. Enter the letter \"a\" to get the bundler to know that I want to run the app on android\n\nIt's all really annoying, so I wrote a bash script to do it all for me. What was fun about this is that I got to learn how to use `xdotool` to actually simulate a keypress which I added later on (chatGPT definitely helped). In the future I want to figure out if there's a proper non-interactive way to boot Metro for Android.\n\n```shell\n~/Android/Sdk/emulator/emulator @mainAndroid & sleep 3 && xdotool key super+shift+t\n# Call `lt -p 8080`, and pipe the output into /tmp/lt_out. Then sleep to wait for it to start, and use the output that was buffered in the temp file to grab the URL\nexport SERVER_ADDRESS=$(lt -p 8080 > /tmp/lt_out & sleep 2 && cat /tmp/lt_out | grep -o 'https://.*')\necho \"Server address: $SERVER_ADDRESS\"\n\n# An annoying thing that needs to be in the environment that it can't grab from .env for some reason\nexport ANDROID_HOME=$HOME/Android/Sdk\necho \"ANDROID_HOME: $ANDROID_HOME\"\n\n# Run the `sleep 8 && xdotool type 'a'` command in the background.\n# Run `npx react-natvie start --port 9097` in the foreground.\n# Running react native metro is blocking so it never terminates\n# (what coes to the right of & runs in the background without waiting\n# for the thing to the left of it to terminate)\nsleep 8 && xdotool type 'a' & npx react-native start --port 9097\n```\n\n## Course Snipe Autoclicker\n\n![Successful click at 7:00:00!](image_0001.png|width=35)\n\nFor course registration I made a super simple `Python` script to click the register button at exactly 7AM. It's a very simple script that simulates a left mouse click. I left the cursor over the register button, and ran it on a headed Linux system so the clock was super super accurate. I was able to get all the courses I wanted for next semester (all of which were very competitive) this way. It's Python, but it's definitely a script in the style of this course.\n\n```python\nimport pyautogui\nimport datetime\nimport time\n\ndef click_at_time(time_str):\n    target_time = datetime.datetime.strptime(time_str, \"%H:%M\").time()\n    while True:\n        now = datetime.datetime.now().time()\n        if (\n            now.hour == target_time.hour\n            and now.minute == target_time.minute\n            and now.second == 0\n            and now.microsecond \u003C 100000\n        ):\n            time.sleep(0.05)\n            pyautogui.click()\n            break\n        time.sleep(0.01)\n\nif __name__ == \"__main__\":\n    target = input(\"Enter the time in HH:MM format: \")\n    click_at_time(target)\n```\n\n## Board game listing\n\n![Annoying to parse page](https://static.404wolf.com/Screenshot_from_2024-05-05_01-53-46_0001.png)\n![Finding the API](https://static.404wolf.com/Screenshot_from_2024-05-05_01-54-33_0001.png)\n\n### TLDR\n\nA simple bash script that uses `JQ` piping and an `API` I found to fetch a list of names of board games produced by a specific company.\n\nI recently was interested in finding a list of all board games that the board game producing company Funforge had produced. They make a lot of great board games and I was curious to learn of new ones and also investigate resale potential for some of their older ones. I checked board game geek, a forum and data source for board games, and they have lists of games for specific publishers, but it's paginated and annoying to parse.\n\nI decided to open network tab to see if there were any requests with `Json` data being sent from an API, and it turned out that there was. I tinkered a bit with getting the right parameters, and figured out that the API endpoint was paginating the board games that Funforge had produced. So, I wrote a simple bash script with a loop to list out all the games that they've produced, and automatically deal with the pagination.\n\n### Example of Content to Parse\n\n```json\n{\n  \"items\": [\n    {\n      \"usersrated\": \"72478\",\n      \"average\": \"7.87762\",\n      \"avgweight\": \"3.6369\",\n      \"numowned\": \"85351\",\n      \"numprevowned\": \"9222\",\n      \"numtrading\": \"1393\",\n      \"numwanting\": \"1145\",\n      \"numwish\": \"12127\",\n      \"numcomments\": \"13733\",\n      \"yearpublished\": \"2007\",\n      \"rank\": \"52\",\n      \"name\": \"Agricola\",\n      \"postdate\": \"2007-08-09 15:05:03\",\n      \"linkid\": \"8215175\",\n      \"linktype\": \"boardgamepublisher\",\n      \"objecttype\": \"thing\",\n      \"objectid\": \"31260\",\n      \"itemstate\": \"approved\",\n      \"rep_imageid\": \"831744\",\n      \"subtype\": \"boardgame\",\n      \"links\": [],\n      \"href\": \"/boardgame/31260/agricola\",\n      \"images\": {\n        \"thumb\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__thumb/img/GHGdnCfeysoP_34gLnofJcNivW8=/fit-in/200x150/filters:strip_icc()/pic831744.jpg\",\n        \"micro\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__micro/img/SZgGqufNqaW8BCFT29wkYPaRXOE=/fit-in/64x64/filters:strip_icc()/pic831744.jpg\",\n        \"square\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__square/img/buzgMbAtE6uf5rX-1-PwqvBnzDY=/75x75/filters:strip_icc()/pic831744.jpg\",\n        \"squarefit\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__squarefit/img/nqUrgCUx_0WWtpCtOrQdSUxQkVU=/fit-in/75x75/filters:strip_icc()/pic831744.jpg\",\n        \"tallthumb\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__tallthumb/img/mlIqrJemOrOnqg8Ha2WiXfdFtWE=/fit-in/75x125/filters:strip_icc()/pic831744.jpg\",\n        \"previewthumb\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__previewthumb/img/MoFOfTG1NMtI-fKAyegRhCBlzmc=/fit-in/300x320/filters:strip_icc()/pic831744.jpg\",\n        \"square200\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__square200/img/bhWPgT6a0vKXqTw448T-mhJy_rQ=/200x200/filters:strip_icc()/pic831744.jpg\",\n        \"original\": \"https://cf.geekdo-images.com/dDDo2Hexl80ucK1IlqTk-g__original/img/toobKoejPiHpfpHk4SYd1UAJafw=/0x0/filters:format(jpeg)/pic831744.jpg\"\n      }\n    },\n    {\n      \"usersrated\": \"17602\",\n      \"average\": \"7.95942\",\n      \"avgweight\": \"3.4502\",\n      \"numowned\": \"24475\",\n      \"numprevowned\": \"2212\",\n      \"numtrading\": \"272\",\n      \"numwanting\": \"428\",\n      \"numwish\": \"3442\",\n      \"numcomments\": \"2254\",\n      \"yearpublished\": \"2016\",\n      \"rank\": \"76\",\n      \"name\": \"Agricola (Revised Edition)\",\n      \"postdate\": \"2016-05-23 15:43:12\",\n      \"linkid\": \"5670975\",\n      \"linktype\": \"boardgamepublisher\",\n      \"objecttype\": \"thing\",\n      \"objectid\": \"200680\",\n      \"itemstate\": \"approved\",\n      \"rep_imageid\": \"8093340\",\n      \"subtype\": \"boardgame\",\n      \"links\": [],\n      \"href\": \"/boardgame/200680/agricola-revised-edition\",\n      \"images\": {\n        \"thumb\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__thumb/img/h_Rp2XYqaNElM2hrYxUSzMxRRgM=/fit-in/200x150/filters:strip_icc()/pic8093340.jpg\",\n        \"micro\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__micro/img/GQNkMukGtKD2cVOgpUk4ZSmpUfA=/fit-in/64x64/filters:strip_icc()/pic8093340.jpg\",\n        \"square\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__square/img/KjlOw3u2349C_-_Bewth-UotKPY=/75x75/filters:strip_icc()/pic8093340.jpg\",\n        \"squarefit\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__squarefit/img/LjiHLhRV8Js7M-Yw2kIn9jUNqYs=/fit-in/75x75/filters:strip_icc()/pic8093340.jpg\",\n        \"tallthumb\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__tallthumb/img/E1CGspVGwdQl011_rBuC-FLS-Lg=/fit-in/75x125/filters:strip_icc()/pic8093340.jpg\",\n        \"previewthumb\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__previewthumb/img/8U7iPhmzZXjytK2qS_-M5SpJ028=/fit-in/300x320/filters:strip_icc()/pic8093340.jpg\",\n        \"square200\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__square200/img/Yyxaz3YRjIEo1EZBN4ipT3gpEzY=/200x200/filters:strip_icc()/pic8093340.jpg\",\n        \"original\": \"https://cf.geekdo-images.com/YCGWJMFwOI5efji2RJ2mSw__original/img/jC_He46LcIcKWU-kSwkYdr9Z45E=/0x0/filters:format(jpeg)/pic8093340.jpg\"\n      }\n    }\n  ],\n  \"itemdata\": [\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"name\",\n      \"title\": \"Primary Name\",\n      \"primaryname\": true,\n      \"required\": true,\n      \"unclickable\": true,\n      \"fullcredits\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"name\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"alternatename\",\n      \"title\": \"Alternate Names\",\n      \"alternate\": true,\n      \"unclickable\": true,\n      \"fullcredits\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"alternatename\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"yearpublished\",\n      \"title\": \"Year Released\",\n      \"fullcredits\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"yearpublished\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"minplayers\",\n      \"title\": \"Minimum Players\",\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"minplayers\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"maxplayers\",\n      \"title\": \"Maximum Players\",\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"maxplayers\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"minplaytime\",\n      \"title\": \"Minimum Playing Time\",\n      \"createposttext\": \" minutes\",\n      \"posttext\": \" minutes\",\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"minplaytime\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"maxplaytime\",\n      \"title\": \"Maximum Playing Time\",\n      \"createposttext\": \" minutes\",\n      \"posttext\": \" minutes\",\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"maxplaytime\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"minage\",\n      \"title\": \"Mfg Suggested Ages\",\n      \"createtitle\": \"Minimum Age\",\n      \"posttext\": \" and up\",\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"minage\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"override_rankable\",\n      \"title\": \"Override Rankable\",\n      \"table\": \"geekitem_items\",\n      \"options\": [\n        {\n          \"value\": 1,\n          \"title\": \"yes\"\n        },\n        {\n          \"value\": 0,\n          \"title\": \"no\"\n        }\n      ],\n      \"adminonly\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"override_rankable\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"targetco_url\",\n      \"unclickable\": true,\n      \"title\": \"Target Co Order Link\",\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"targetco_url\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"walmart_id\",\n      \"unclickable\": true,\n      \"title\": \"Walmart Item Id\",\n      \"nullable\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"walmart_id\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"instructional_videoid\",\n      \"unclickable\": true,\n      \"title\": \"Promoted Instructional Video ID\",\n      \"validatemethod\": \"ValidateVideoid\",\n      \"nullable\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"instructional_videoid\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"summary_videoid\",\n      \"unclickable\": true,\n      \"title\": \"Promoted Summary Video ID\",\n      \"validatemethod\": \"ValidateVideoid\",\n      \"nullable\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"summary_videoid\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"playthrough_videoid\",\n      \"unclickable\": true,\n      \"title\": \"Promoted Playthrough Video ID\",\n      \"validatemethod\": \"ValidateVideoid\",\n      \"nullable\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"playthrough_videoid\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"focus_videoid\",\n      \"unclickable\": true,\n      \"title\": \"Promoted In Focus Video ID\",\n      \"validatemethod\": \"ValidateVideoid\",\n      \"nullable\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"focus_videoid\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"howtoplay_videoid\",\n      \"unclickable\": true,\n      \"title\": \"Promoted BGG How to Play Video ID\",\n      \"validatemethod\": \"ValidateVideoid\",\n      \"nullable\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"howtoplay_videoid\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"bggstore_product\",\n      \"unclickable\": true,\n      \"title\": \"Promoted BGG Store Product Name\",\n      \"nullable\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"bggstore_product\"\n    },\n    {\n      \"datatype\": \"geekitem_fielddata\",\n      \"fieldname\": \"short_description\",\n      \"title\": \"Short Description\",\n      \"table\": \"geekitem_items\",\n      \"maxlength\": 85,\n      \"editfieldsize\": 60,\n      \"required\": true,\n      \"subtype\": \"boardgame\",\n      \"keyname\": \"short_description\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgamedesigner\",\n      \"linktype\": \"boardgamedesigner\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Designer\",\n      \"titlepl\": \"Designers\",\n      \"fullcredits\": true,\n      \"schema\": {\n        \"itemprop\": \"creator\",\n        \"itemtype\": \"https://schema.org/Person\"\n      },\n      \"keyname\": \"boardgamedesigner\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgamesolodesigner\",\n      \"linktype\": \"boardgamesolodesigner\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Solo Designer\",\n      \"titlepl\": \"Solo Designers\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgamesolodesigner\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgameartist\",\n      \"linktype\": \"boardgameartist\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Artist\",\n      \"titlepl\": \"Artists\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgameartist\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"company\",\n      \"other_subtype\": \"boardgamepublisher\",\n      \"linktype\": \"boardgamepublisher\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Publisher\",\n      \"titlepl\": \"Publishers\",\n      \"required\": true,\n      \"fullcredits\": true,\n      \"schema\": {\n        \"itemprop\": \"publisher\",\n        \"itemtype\": \"https://schema.org/Organization\"\n      },\n      \"keyname\": \"boardgamepublisher\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgamedeveloper\",\n      \"linktype\": \"boardgamedeveloper\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Developer\",\n      \"titlepl\": \"Developers\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgamedeveloper\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgamegraphicdesigner\",\n      \"linktype\": \"boardgamegraphicdesigner\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Graphic Designer\",\n      \"titlepl\": \"Graphic Designers\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgamegraphicdesigner\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgamesculptor\",\n      \"linktype\": \"boardgamesculptor\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Sculptor\",\n      \"titlepl\": \"Sculptors\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgamesculptor\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgameeditor\",\n      \"linktype\": \"boardgameeditor\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Editor\",\n      \"titlepl\": \"Editors\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgameeditor\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgamewriter\",\n      \"linktype\": \"boardgamewriter\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Writer\",\n      \"titlepl\": \"Writers\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgamewriter\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"person\",\n      \"other_subtype\": \"boardgameinsertdesigner\",\n      \"linktype\": \"boardgameinsertdesigner\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Insert Designer\",\n      \"titlepl\": \"Insert Designers\",\n      \"fullcredits\": true,\n      \"keyname\": \"boardgameinsertdesigner\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"family\",\n      \"other_subtype\": \"boardgamehonor\",\n      \"lookup_subtype\": \"boardgamehonor\",\n      \"linktype\": \"boardgamehonor\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Honors\",\n      \"keyname\": \"boardgamehonor\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"property\",\n      \"other_subtype\": \"boardgamecategory\",\n      \"lookup_subtype\": \"boardgamecategory\",\n      \"linktype\": \"boardgamecategory\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Category\",\n      \"titlepl\": \"Categories\",\n      \"showall_ctrl\": true,\n      \"fullcredits\": true,\n      \"overview_count\": 5,\n      \"keyname\": \"boardgamecategory\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"property\",\n      \"other_subtype\": \"boardgamemechanic\",\n      \"lookup_subtype\": \"boardgamemechanic\",\n      \"linktype\": \"boardgamemechanic\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Mechanism\",\n      \"titlepl\": \"Mechanisms\",\n      \"showall_ctrl\": true,\n      \"fullcredits\": true,\n      \"overview_count\": 5,\n      \"keyname\": \"boardgamemechanic\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"lookup_subtype\": \"boardgame\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgameexpansion\",\n      \"linktype\": \"boardgameexpansion\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Expansion\",\n      \"keyname\": \"boardgameexpansion\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"version\",\n      \"other_subtype\": \"boardgameversion\",\n      \"linktype\": \"boardgameversion\",\n      \"other_is_dependent\": true,\n      \"required\": true,\n      \"loadlinks\": true,\n      \"self_prefix\": \"src\",\n      \"title\": \"Version\",\n      \"createtitle\": \"Versions\",\n      \"hidecontrols\": true,\n      \"keyname\": \"boardgameversion\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgame\",\n      \"lookup_subtype\": \"boardgame\",\n      \"linktype\": \"boardgameexpansion\",\n      \"self_prefix\": \"dst\",\n      \"title\": \"Expands\",\n      \"overview_count\": 100,\n      \"keyname\": \"expandsboardgame\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgame\",\n      \"lookup_subtype\": \"boardgame\",\n      \"linktype\": \"boardgameintegration\",\n      \"correctioncomment\": \"Only for stand-alone games that integrate with other stand-alone games. \\u003Cb\\u003ENOT\\u003C/b\\u003E for expansions.\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Integrates With\",\n      \"overview_count\": 4,\n      \"keyname\": \"boardgameintegration\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgame\",\n      \"lookup_subtype\": \"boardgame\",\n      \"linktype\": \"boardgamecompilation\",\n      \"self_prefix\": \"dst\",\n      \"correctioncomment\": \"Items contained in this item (if this is a compilation, for example)\",\n      \"title\": \"Contains\",\n      \"overview_count\": 4,\n      \"keyname\": \"contains\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"lookup_subtype\": \"boardgame\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgame\",\n      \"linktype\": \"boardgamecompilation\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Contained in\",\n      \"keyname\": \"containedin\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"lookup_subtype\": \"boardgame\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgame\",\n      \"linktype\": \"boardgameimplementation\",\n      \"self_prefix\": \"src\",\n      \"correctioncomment\": \"Add the \\\"child\\\" item(s) that reimplement this game\",\n      \"title\": \"Reimplemented By\",\n      \"overview_count\": 4,\n      \"keyname\": \"reimplementation\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgame\",\n      \"lookup_subtype\": \"boardgame\",\n      \"linktype\": \"boardgameimplementation\",\n      \"self_prefix\": \"dst\",\n      \"correctioncomment\": \"Add the \\\"parent\\\" item(s) for this game, if it reimplements a previous game\",\n      \"title\": \"Reimplements\",\n      \"overview_count\": 4,\n      \"keyname\": \"reimplements\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"family\",\n      \"other_subtype\": \"boardgamefamily\",\n      \"lookup_subtype\": \"boardgamefamily\",\n      \"linktype\": \"boardgamefamily\",\n      \"self_prefix\": \"src\",\n      \"fullcredits\": true,\n      \"title\": \"Family\",\n      \"overview_count\": 10,\n      \"keyname\": \"boardgamefamily\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"videogamebg\",\n      \"lookup_subtype\": \"videogame\",\n      \"linktype\": \"videogamebg\",\n      \"self_prefix\": \"src\",\n      \"adminonly\": true,\n      \"title\": \"Video Game Adaptation\",\n      \"titlepl\": \"Video Game Adaptations\",\n      \"keyname\": \"videogamebg\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"family\",\n      \"other_subtype\": \"boardgamesubdomain\",\n      \"lookup_subtype\": \"boardgamesubdomain\",\n      \"linktype\": \"boardgamesubdomain\",\n      \"polltype\": \"boardgamesubdomain\",\n      \"display_inline\": true,\n      \"self_prefix\": \"src\",\n      \"title\": \"Type\",\n      \"showall_ctrl\": true,\n      \"hidecontrols\": true,\n      \"createposttext\": \"Enter the subdomain for this item.\",\n      \"keyname\": \"boardgamesubdomain\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"thing\",\n      \"other_subtype\": \"boardgameaccessory\",\n      \"lookup_subtype\": \"boardgameaccessory\",\n      \"linktype\": \"boardgameaccessory\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Accessory\",\n      \"titlepl\": \"Accessories\",\n      \"addnew\": true,\n      \"keyname\": \"boardgameaccessory\"\n    },\n    {\n      \"datatype\": \"geekitem_linkdata\",\n      \"other_objecttype\": \"family\",\n      \"other_subtype\": \"cardset\",\n      \"linktype\": \"cardset\",\n      \"self_prefix\": \"src\",\n      \"title\": \"Card Set\",\n      \"hidecontrols\": true,\n      \"keyname\": \"cardset\"\n    },\n    {\n      \"datatype\": \"geekitem_polldata\",\n      \"title\": \"User Suggested # of Players\",\n      \"polltype\": \"numplayers\",\n      \"keyname\": \"userplayers\"\n    },\n    {\n      \"datatype\": \"geekitem_polldata\",\n      \"title\": \"User Suggested Ages\",\n      \"polltype\": \"playerage\",\n      \"keyname\": \"playerage\"\n    },\n    {\n      \"datatype\": \"geekitem_polldata\",\n      \"title\": \"Language Dependence\",\n      \"polltype\": \"languagedependence\",\n      \"keyname\": \"languagedependence\"\n    },\n    {\n      \"datatype\": \"geekitem_polldata\",\n      \"title\": \"Subdomain\",\n      \"polltype\": \"boardgamesubdomain\",\n      \"keyname\": \"subdomain\"\n    },\n    {\n      \"datatype\": \"geekitem_polldata\",\n      \"title\": \"Weight\",\n      \"polltype\": \"boardgameweight\",\n      \"keyname\": \"boardgameweight\"\n    }\n  ],\n  \"linkdata\": [],\n  \"config\": {\n    \"numitems\": 100,\n    \"sortdata\": [\n      {\n        \"title\": \"Name\",\n        \"hidden\": true,\n        \"key\": \"name\"\n      },\n      {\n        \"title\": \"Rank\",\n        \"onzero\": \"N/A\",\n        \"key\": \"rank\"\n      },\n      {\n        \"title\": \"Num Ratings\",\n        \"href\": \"/collection/items/{$other_subtype}/{$item.objectid}?rated=1\",\n        \"key\": \"usersrated\"\n      },\n      {\n        \"title\": \"Average Rating\",\n        \"string_format\": \"%0.2f\",\n        \"key\": \"average\"\n      },\n      {\n        \"title\": \"Average Weight\",\n        \"string_format\": \"%0.2f\",\n        \"key\": \"avgweight\"\n      },\n      {\n        \"title\": \"Num Owned\",\n        \"href\": \"/collection/items/{$other_subtype}/{$item.objectid}?own=1\",\n        \"key\": \"numowned\"\n      },\n      {\n        \"title\": \"Prev. Owned\",\n        \"href\": \"/collection/items/{$other_subtype}/{$item.objectid}?prevown=1\",\n        \"key\": \"numprevowned\"\n      },\n      {\n        \"title\": \"For Trade\",\n        \"href\": \"/collection/items/{$other_subtype}/{$item.objectid}?fortrade=1\",\n        \"key\": \"numtrading\"\n      },\n      {\n        \"title\": \"Want in Trade\",\n        \"href\": \"/collection/items/{$other_subtype}/{$item.objectid}?want=1\",\n        \"key\": \"numwanting\"\n      },\n      {\n        \"title\": \"Wishlist\",\n        \"href\": \"/collection/items/{$other_subtype}/{$item.objectid}?wishlist=1\",\n        \"key\": \"numwish\"\n      },\n      {\n        \"title\": \"Comments\",\n        \"href\": \"/collection/items/{$other_subtype}/{$item.objectid}?comment=1\",\n        \"key\": \"numcomments\"\n      },\n      {\n        \"title\": \"Year Released\",\n        \"key\": \"yearpublished\"\n      }\n    ],\n    \"filters\": [\n      {\n        \"key\": \"categoryfilter\",\n        \"options\": [\n          {\n            \"objectid\": \"1009\",\n            \"name\": \"Abstract Strategy\"\n          },\n          {\n            \"objectid\": \"1032\",\n            \"name\": \"Action / Dexterity\"\n          },\n          {\n            \"objectid\": \"1022\",\n            \"name\": \"Adventure\"\n          },\n          {\n            \"objectid\": \"2726\",\n            \"name\": \"Age of Reason\"\n          },\n          {\n            \"objectid\": \"1055\",\n            \"name\": \"American West\"\n          },\n          {\n            \"objectid\": \"1050\",\n            \"name\": \"Ancient\"\n          },\n          {\n            \"objectid\": \"1089\",\n            \"name\": \"Animals\"\n          },\n          {\n            \"objectid\": \"2650\",\n            \"name\": \"Aviation / Flight\"\n          },\n          {\n            \"objectid\": \"1023\",\n            \"name\": \"Bluffing\"\n          },\n          {\n            \"objectid\": \"1002\",\n            \"name\": \"Card Game\"\n          },\n          {\n            \"objectid\": \"1029\",\n            \"name\": \"City Building\"\n          },\n          {\n            \"objectid\": \"1015\",\n            \"name\": \"Civilization\"\n          },\n          {\n            \"objectid\": \"1044\",\n            \"name\": \"Collectible Components\"\n          },\n          {\n            \"objectid\": \"1116\",\n            \"name\": \"Comic Book / Strip\"\n          },\n          {\n            \"objectid\": \"1039\",\n            \"name\": \"Deduction\"\n          },\n          {\n            \"objectid\": \"1017\",\n            \"name\": \"Dice\"\n          },\n          {\n            \"objectid\": \"1021\",\n            \"name\": \"Economic\"\n          },\n          {\n            \"objectid\": \"1094\",\n            \"name\": \"Educational\"\n          },\n          {\n            \"objectid\": \"1084\",\n            \"name\": \"Environmental\"\n          },\n          {\n            \"objectid\": \"1042\",\n            \"name\": \"Expansion for Base-game\"\n          },\n          {\n            \"objectid\": \"1020\",\n            \"name\": \"Exploration\"\n          },\n          {\n            \"objectid\": \"1010\",\n            \"name\": \"Fantasy\"\n          },\n          {\n            \"objectid\": \"1013\",\n            \"name\": \"Farming\"\n          },\n          {\n            \"objectid\": \"1046\",\n            \"name\": \"Fighting\"\n          },\n          {\n            \"objectid\": \"1024\",\n            \"name\": \"Horror\"\n          },\n          {\n            \"objectid\": \"1079\",\n            \"name\": \"Humor\"\n          },\n          {\n            \"objectid\": \"1088\",\n            \"name\": \"Industry / Manufacturing\"\n          },\n          {\n            \"objectid\": \"1035\",\n            \"name\": \"Medieval\"\n          },\n          {\n            \"objectid\": \"1047\",\n            \"name\": \"Miniatures\"\n          },\n          {\n            \"objectid\": \"1064\",\n            \"name\": \"Movies / TV / Radio theme\"\n          },\n          {\n            \"objectid\": \"1082\",\n            \"name\": \"Mythology\"\n          },\n          {\n            \"objectid\": \"1008\",\n            \"name\": \"Nautical\"\n          },\n          {\n            \"objectid\": \"1026\",\n            \"name\": \"Negotiation\"\n          },\n          {\n            \"objectid\": \"1093\",\n            \"name\": \"Novel-based\"\n          },\n          {\n            \"objectid\": \"1098\",\n            \"name\": \"Number\"\n          },\n          {\n            \"objectid\": \"1030\",\n            \"name\": \"Party Game\"\n          },\n          {\n            \"objectid\": \"1090\",\n            \"name\": \"Pirates\"\n          },\n          {\n            \"objectid\": \"2710\",\n            \"name\": \"Post-Napoleonic\"\n          },\n          {\n            \"objectid\": \"1036\",\n            \"name\": \"Prehistoric\"\n          },\n          {\n            \"objectid\": \"1120\",\n            \"name\": \"Print & Play\"\n          },\n          {\n            \"objectid\": \"1028\",\n            \"name\": \"Puzzle\"\n          },\n          {\n            \"objectid\": \"1031\",\n            \"name\": \"Racing\"\n          },\n          {\n            \"objectid\": \"1037\",\n            \"name\": \"Real-time\"\n          },\n          {\n            \"objectid\": \"1115\",\n            \"name\": \"Religious\"\n          },\n          {\n            \"objectid\": \"1016\",\n            \"name\": \"Science Fiction\"\n          },\n          {\n            \"objectid\": \"1113\",\n            \"name\": \"Space Exploration\"\n          },\n          {\n            \"objectid\": \"1081\",\n            \"name\": \"Spies/Secret Agents\"\n          },\n          {\n            \"objectid\": \"1086\",\n            \"name\": \"Territory Building\"\n          },\n          {\n            \"objectid\": \"1034\",\n            \"name\": \"Trains\"\n          },\n          {\n            \"objectid\": \"1011\",\n            \"name\": \"Transportation\"\n          },\n          {\n            \"objectid\": \"1097\",\n            \"name\": \"Travel\"\n          },\n          {\n            \"objectid\": \"1101\",\n            \"name\": \"Video Game Theme\"\n          },\n          {\n            \"objectid\": \"1019\",\n            \"name\": \"Wargame\"\n          },\n          {\n            \"objectid\": \"2481\",\n            \"name\": \"Zombies\"\n          }\n        ],\n        \"title\": \"Category\"\n      },\n      {\n        \"key\": \"mechanicfilter\",\n        \"options\": [\n          {\n            \"objectid\": \"2073\",\n            \"name\": \"Acting\"\n          },\n          {\n            \"objectid\": \"2838\",\n            \"name\": \"Action Drafting\"\n          },\n          {\n            \"objectid\": \"2001\",\n            \"name\": \"Action Points\"\n          },\n          {\n            \"objectid\": \"2689\",\n            \"name\": \"Action Queue\"\n          },\n          {\n            \"objectid\": \"2847\",\n            \"name\": \"Advantage Token\"\n          },\n          {\n            \"objectid\": \"2916\",\n            \"name\": \"Alliances\"\n          },\n          {\n            \"objectid\": \"2080\",\n            \"name\": \"Area Majority / Influence\"\n          },\n          {\n            \"objectid\": \"2046\",\n            \"name\": \"Area Movement\"\n          },\n          {\n            \"objectid\": \"2920\",\n            \"name\": \"Auction: Sealed Bid\"\n          },\n          {\n            \"objectid\": \"2012\",\n            \"name\": \"Auction/Bidding\"\n          },\n          {\n            \"objectid\": \"2903\",\n            \"name\": \"Automatic Resource Growth\"\n          },\n          {\n            \"objectid\": \"2014\",\n            \"name\": \"Betting and Bluffing\"\n          },\n          {\n            \"objectid\": \"2999\",\n            \"name\": \"Bingo\"\n          },\n          {\n            \"objectid\": \"2913\",\n            \"name\": \"Bribery\"\n          },\n          {\n            \"objectid\": \"2018\",\n            \"name\": \"Campaign / Battle Card Driven\"\n          },\n          {\n            \"objectid\": \"2857\",\n            \"name\": \"Card Play Conflict Resolution\"\n          },\n          {\n            \"objectid\": \"2887\",\n            \"name\": \"Catch the Leader\"\n          },\n          {\n            \"objectid\": \"2956\",\n            \"name\": \"Chaining\"\n          },\n          {\n            \"objectid\": \"2984\",\n            \"name\": \"Closed Drafting\"\n          },\n          {\n            \"objectid\": \"2013\",\n            \"name\": \"Commodity Speculation\"\n          },\n          {\n            \"objectid\": \"2912\",\n            \"name\": \"Contracts\"\n          },\n          {\n            \"objectid\": \"2023\",\n            \"name\": \"Cooperative Game\"\n          },\n          {\n            \"objectid\": \"2664\",\n            \"name\": \"Deck, Bag, and Pool Building\"\n          },\n          {\n            \"objectid\": \"2072\",\n            \"name\": \"Dice Rolling\"\n          },\n          {\n            \"objectid\": \"2856\",\n            \"name\": \"Die Icon Resolution\"\n          },\n          {\n            \"objectid\": \"3096\",\n            \"name\": \"Drawing\"\n          },\n          {\n            \"objectid\": \"2882\",\n            \"name\": \"Elapsed Real Time Ending\"\n          },\n          {\n            \"objectid\": \"2043\",\n            \"name\": \"Enclosure\"\n          },\n          {\n            \"objectid\": \"2875\",\n            \"name\": \"End Game Bonuses\"\n          },\n          {\n            \"objectid\": \"2850\",\n            \"name\": \"Events\"\n          },\n          {\n            \"objectid\": \"2885\",\n            \"name\": \"Finale Ending\"\n          },\n          {\n            \"objectid\": \"2978\",\n            \"name\": \"Grid Coverage\"\n          },\n          {\n            \"objectid\": \"2676\",\n            \"name\": \"Grid Movement\"\n          },\n          {\n            \"objectid\": \"2040\",\n            \"name\": \"Hand Management\"\n          },\n          {\n            \"objectid\": \"2026\",\n            \"name\": \"Hexagon Grid\"\n          },\n          {\n            \"objectid\": \"2891\",\n            \"name\": \"Hidden Roles\"\n          },\n          {\n            \"objectid\": \"2987\",\n            \"name\": \"Hidden Victory Points\"\n          },\n          {\n            \"objectid\": \"2906\",\n            \"name\": \"I Cut, You Choose\"\n          },\n          {\n            \"objectid\": \"2902\",\n            \"name\": \"Income\"\n          },\n          {\n            \"objectid\": \"2914\",\n            \"name\": \"Increase Value of Unchosen Resources\"\n          },\n          {\n            \"objectid\": \"2837\",\n            \"name\": \"Interrupts\"\n          },\n          {\n            \"objectid\": \"3001\",\n            \"name\": \"Layering\"\n          },\n          {\n            \"objectid\": \"2975\",\n            \"name\": \"Line of Sight\"\n          },\n          {\n            \"objectid\": \"2904\",\n            \"name\": \"Loans\"\n          },\n          {\n            \"objectid\": \"2959\",\n            \"name\": \"Map Addition\"\n          },\n          {\n            \"objectid\": \"2900\",\n            \"name\": \"Market\"\n          },\n          {\n            \"objectid\": \"2047\",\n            \"name\": \"Memory\"\n          },\n          {\n            \"objectid\": \"2011\",\n            \"name\": \"Modular Board\"\n          },\n          {\n            \"objectid\": \"2962\",\n            \"name\": \"Move Through Deck\"\n          },\n          {\n            \"objectid\": \"3099\",\n            \"name\": \"Multi-Use Cards\"\n          },\n          {\n            \"objectid\": \"2851\",\n            \"name\": \"Narrative Choice / Paragraph\"\n          },\n          {\n            \"objectid\": \"2915\",\n            \"name\": \"Negotiation\"\n          },\n          {\n            \"objectid\": \"2081\",\n            \"name\": \"Network and Route Building\"\n          },\n          {\n            \"objectid\": \"2846\",\n            \"name\": \"Once-Per-Game Abilities\"\n          },\n          {\n            \"objectid\": \"2041\",\n            \"name\": \"Open Drafting\"\n          },\n          {\n            \"objectid\": \"2055\",\n            \"name\": \"Paper-and-Pencil\"\n          },\n          {\n            \"objectid\": \"2048\",\n            \"name\": \"Pattern Building\"\n          },\n          {\n            \"objectid\": \"2685\",\n            \"name\": \"Player Elimination\"\n          },\n          {\n            \"objectid\": \"2078\",\n            \"name\": \"Point to Point Movement\"\n          },\n          {\n            \"objectid\": \"2661\",\n            \"name\": \"Push Your Luck\"\n          },\n          {\n            \"objectid\": \"2876\",\n            \"name\": \"Race\"\n          },\n          {\n            \"objectid\": \"2870\",\n            \"name\": \"Re-rolling and Locking\"\n          },\n          {\n            \"objectid\": \"2831\",\n            \"name\": \"Real-Time\"\n          },\n          {\n            \"objectid\": \"3103\",\n            \"name\": \"Resource Queue\"\n          },\n          {\n            \"objectid\": \"2028\",\n            \"name\": \"Role Playing\"\n          },\n          {\n            \"objectid\": \"2035\",\n            \"name\": \"Roll / Spin and Move\"\n          },\n          {\n            \"objectid\": \"2813\",\n            \"name\": \"Rondel\"\n          },\n          {\n            \"objectid\": \"2822\",\n            \"name\": \"Scenario / Mission / Campaign Game\"\n          },\n          {\n            \"objectid\": \"2016\",\n            \"name\": \"Secret Unit Deployment\"\n          },\n          {\n            \"objectid\": \"2820\",\n            \"name\": \"Semi-Cooperative Game\"\n          },\n          {\n            \"objectid\": \"2004\",\n            \"name\": \"Set Collection\"\n          },\n          {\n            \"objectid\": \"2070\",\n            \"name\": \"Simulation\"\n          },\n          {\n            \"objectid\": \"2020\",\n            \"name\": \"Simultaneous Action Selection\"\n          },\n          {\n            \"objectid\": \"3005\",\n            \"name\": \"Slide/Push\"\n          },\n          {\n            \"objectid\": \"2819\",\n            \"name\": \"Solo / Solitaire Game\"\n          },\n          {\n            \"objectid\": \"2940\",\n            \"name\": \"Square Grid\"\n          },\n          {\n            \"objectid\": \"2853\",\n            \"name\": \"Stat Check Resolution\"\n          },\n          {\n            \"objectid\": \"2861\",\n            \"name\": \"Static Capture\"\n          },\n          {\n            \"objectid\": \"2027\",\n            \"name\": \"Storytelling\"\n          },\n          {\n            \"objectid\": \"3100\",\n            \"name\": \"Tags\"\n          },\n          {\n            \"objectid\": \"2686\",\n            \"name\": \"Take That\"\n          },\n          {\n            \"objectid\": \"2019\",\n            \"name\": \"Team-Based Game\"\n          },\n          {\n            \"objectid\": \"2849\",\n            \"name\": \"Tech Trees / Tech Tracks\"\n          },\n          {\n            \"objectid\": \"2002\",\n            \"name\": \"Tile Placement\"\n          },\n          {\n            \"objectid\": \"2939\",\n            \"name\": \"Track Movement\"\n          },\n          {\n            \"objectid\": \"2008\",\n            \"name\": \"Trading\"\n          },\n          {\n            \"objectid\": \"2814\",\n            \"name\": \"Traitor Game\"\n          },\n          {\n            \"objectid\": \"2888\",\n            \"name\": \"Tug of War\"\n          },\n          {\n            \"objectid\": \"2829\",\n            \"name\": \"Turn Order: Claim Action\"\n          },\n          {\n            \"objectid\": \"2828\",\n            \"name\": \"Turn Order: Progressive\"\n          },\n          {\n            \"objectid\": \"2826\",\n            \"name\": \"Turn Order: Stat-Based\"\n          },\n          {\n            \"objectid\": \"2663\",\n            \"name\": \"Turn Order: Time Track\"\n          },\n          {\n            \"objectid\": \"2015\",\n            \"name\": \"Variable Player Powers\"\n          },\n          {\n            \"objectid\": \"2897\",\n            \"name\": \"Variable Set-up\"\n          },\n          {\n            \"objectid\": \"2874\",\n            \"name\": \"Victory Points as a Resource\"\n          },\n          {\n            \"objectid\": \"2017\",\n            \"name\": \"Voting\"\n          },\n          {\n            \"objectid\": \"2082\",\n            \"name\": \"Worker Placement\"\n          },\n          {\n            \"objectid\": \"2933\",\n            \"name\": \"Worker Placement, Different Worker Types\"\n          },\n          {\n            \"objectid\": \"2974\",\n            \"name\": \"Zone of Control\"\n          }\n        ],\n        \"title\": \"Mechanic\"\n      }\n    ]\n  }\n}\n```\n\nAfter, I added the `-s` flag for `CURL` to prevent getting status logs and just get the list of board games. I found that the for loop could iterate to an arbitrarily large value, like `50`, and that all the requests would be empty afterwards anyway.\n\n```bash\nfor (( i=0; i\u003C50; i++ )); do\n    # Fetch data using curl and parse it with jq\n    # The -s flag is used to suppress the progress meter and other non-error output\n    result=$(curl -s GET \"https://api.geekdo.com/api/geekitem/linkeditems?ajax=1&linkdata_index=boardgame&nosession=1&objectid=8832&objecttype=company&pageid=$i&showcount=25&sort=name&subtype=boardgamepublisher\")\n\n    # Use jq to parse JSON and extract the .items[].name field\n    echo \"$result\" | jq '.items[].name'\ndone\n```\n\nI improved the script to automatically terminate instead of using an arbitrary guess for the number of pages by implementing a while loop, and using the `-z` bash flag to check if null.\n\n```bash\ni=0;\nwhile true; do\n    ((i++));\n    # Fetch data using curl and parse it with jq\n    # The -s flag is used to suppress the progress meter and other non-error output\n    result=$(curl -s GET \"https://api.geekdo.com/api/geekitem/linkeditems?ajax=1&linkdata_index=boardgame&nosession=1&objectid=8832&objecttype=company&pageid=$i&showcount=25&sort=name&subtype=boardgamepublisher\");\n\n    # Use jq to parse JSON and extract the .items[].name field\n    parsed=$(echo \"$result\" | jq '.items[].name');\n    if [ -z \"$parsed\" ]; then\n        break\n    fi\n    echo \"$parsed\";\ndone\n```\n\n```shell\n\"Agricola\"\n\"Agricola (Revised Edition)\"\n\"Agricola: All Creatures Big and Small – The Big Box\"\n\"Agricola: Artifex Deck\"\n\"Agricola: Corbarius Deck\"\n\"Agricola: Family Edition\"\n\"Airship City\"\n\"Bärenpark\"\n\"Bärenpark: The Bad News Bears\"\n\"The Big Idea\"\n\"The Big Idea: La Science-Fiction Médiévale\"\n\"The Binding of Isaac: Four Souls\"\n\"The Binding of Isaac: Four Souls – Tapeworm Promo Cards\"\n\"The Binding of Isaac: Four Souls – Ultimate Collector's Edition\"\n\"The Binding of Isaac: Four Souls +\"\n\"The Binding of Isaac: Four Souls Requiem\"\n\"Bloodborne: The Board Game\"\n\"Brass: Birmingham\"\n\"Brass: Lancashire\"\n\"Caverna: Cave vs Cave\"\n\"Caverna: The Cave Farmers\"\n\"DONUTS\"\n\"Evolution\"\n\"Evolution: Climate\"\n\"Evolution: Promo Pack IV\"\n\"Agricola\"\n\"Agricola (Revised Edition)\"\n\"Agricola: All Creatures Big and Small – The Big Box\"\n\"Agricola: Artifex Deck\"\n\"Agricola: Corbarius Deck\"\n\"Agricola: Family Edition\"\n\"Airship City\"\n\"Bärenpark\"\n\"Bärenpark: The Bad News Bears\"\n\"The Big Idea\"\n\"The Big Idea: La Science-Fiction Médiévale\"\n\"The Binding of Isaac: Four Souls\"\n\"The Binding of Isaac: Four Souls – Tapeworm Promo Cards\"\n\"The Binding of Isaac: Four Souls – Ultimate Collector's Edition\"\n\"The Binding of Isaac: Four Souls +\"\n\"The Binding of Isaac: Four Souls Requiem\"\n\"Bloodborne: The Board Game\"\n\"Brass: Birmingham\"\n\"Brass: Lancashire\"\n\"Caverna: Cave vs Cave\"\n\"Caverna: The Cave Farmers\"\n\"DONUTS\"\n\"Evolution\"\n\"Evolution: Climate\"\n\"Evolution: Promo Pack IV\"\n\"Expedition to Newdale\"\n\"Fairy Trails\"\n\"Far Cry: Beyond\"\n\"Fight for Olympus\"\n\"Foothills\"\n\"Gingerbread House\"\n\"Glasgow\"\n\"Grand Austria Hotel\"\n\"Great Plains\"\n\"Hallertau\"\n\"HOP!\"\n\"Illusio\"\n\"Isla Dorada\"\n\"Isle of Skye: Druids\"\n\"Isle of Skye: From Chieftain to King\"\n\"Isle of Skye: Journeyman\"\n\"Llamaland\"\n\"Mandala\"\n\"Monumental\"\n\"Monumental Duel: Espionage\"\n\"Monumental Duel: Exploration\"\n\"Monumental Duel: Trade\"\n\"Monumental: African Empires\"\n\"Monumental: Lost Kingdoms\"\n\"Namiji\"\n\"Namiji: Aquamarine\"\n\"Namiji: Deluxe Edition\"\n\"Nemesis\"\n\"Nemesis: Lockdown\"\n\"Nemesis: Lockdown – Stretch Goals\"\n\"Nemesis: Untold Stories #1\"\n\"Nemesis: Untold Stories #2\"\n\"Night of the Living Dead: A Zombicide Game\"\n\"Oceans\"\n\"Patchwork\"\n\"Patchwork Doodle\"\n\"Patchwork Express\"\n\"The Phantom Society\"\n\"Piepmatz\"\n\"Pocket Madness\"\n\"Pony Express\"\n\"Port Royal: Big Box\"\n\"Professor Evil and The Citadel of Time\"\n\"Professor Evil and the Citadel of Time: Professor Evil and the Architects of Magic\"\n\"Project: ELITE\"\n\"Quantum\"\n\"Quantum: Entanglement Add-on Pack\"\n\"Quantum: The Void\"\n\"Robin of Locksley\"\n\"Runemasters\"\n\"Sagani\"\n\"Samurai Spirit\"\n\"Samurai Spirit: The 8th Boss\"\n\"Sheriff of Nottingham: 2nd Edition\"\n\"Spy Connection\"\n\"Tapas\"\n\"Tindaya\"\n\"Titan Race\"\n\"Tokaido\"\n\"Tokaido Collector's Edition\"\n\"Tokaido Duo\"\n\"Tokaido: Crossroads\"\n\"Tokaido: Deluxe Edition\"\n\"Tokaido: Eriku\"\n\"Tokaido: Felicia Promo Card\"\n\"Tokaido: Matsuri\"\n\"Tokaido: The New Encounters\"\n\"Trambahn\"\n\"Viceroy\"\n\"Warehouse 51\"\n\"Warehouse 51: Promo Cards\"\n\"Who Would Win\"\n\"WolfWalkers: My Story\"\n\"ZNA\"\n\"Zona: The Secret of Chernobyl\"\n```\n\n# Other Random Linux Scripts/Things\n\nTowards the latter half of the semester I switched from Windows to PopOs (an Ubuntu fork), and have been loving it. Here's a list of random Linux-y things I've figured out and done...\n\n## Desktop Entries\n\n![Desktop entry syntax](https://static.404wolf.com/https://static.404wolf.com/Linux-desktopentry_0001.webp)\n\nI learned a bit about how to set up desktop entries on popos with gnome desktop. These are items displayed on the desktop of the computer, that have customized functionality specified in a specially formatted desktop file. Archwiki explains,\n\n> Desktop entries for applications, or .desktop files, are generally a combination of meta information resources and a shortcut of an application. These files usually reside in `/usr/share/applications/` or `/usr/local/share/applications/` for applications installed system-wide, or `~/.local/share/applications/` for user-specific applications. User entries take precedence over system entries.\n\n```shell\n[Desktop Entry]\nType=Application\nTerminal=false\nName=Chrome - Primary\nExec=/usr/bin/google-chrome-stable --profile-directory=\"Default\"\nIcon=google-chrome\n```\n\n![My desktop entries](https://static.404wolf.com/Screenshot_from_2024-04-18_19-09-41_0001.png)\n\nThis then makes icons on your desktop that can do specific actions. I added some for chrome so that it launches chrome with a specific chrome profile (for example, a chrome profile on my desktop that launches me into my CWRU google account when it boots). It's super useful. Later on I added some for other accounts too.\n\n## Getting Fingerprint Sensor working\n\nGetting fingerprint detection to work on my laptop with Linux was a bit annoying. I was able to make it work with a lot of trial and error and some help from `ChatGPT`. After I got it working, I wanted to be able to use my fingerprint for `sudo` instead of typing in my password every single time. To get this working, I followed the following steps...\n\nChatGPT instructions that seemed to work\n\n```markdown\n1. install fprintd: use the following command to install fprintd. sudo apt-get install fprintd\n2. enroll your fingerprint: enroll your right index finger with the following command. `fprintd-enroll -f right-index-finger`\n3. install libpam-fprintd: install this pam module to enable fingerprint authentication. `sudo apt-get install libpam-fprintd`  \n   who uses 4 configure pam: open /etc/pam.d/common-auth in a text editor with root privileges. You can use nano editor with the following command. sudo nano /etc/pam.d/common-auth\n4. add the following line at the top of the file. `auth [success=2 default=ignore] pam_fprintd.so`\n\n> The auth [success=2 default=ignore] pam_fprintd.so line in the PAM (Pluggable Authentication Modules)  \n> configuration file is used for fingerprint authentication. If the fingerprint authentication is successful,\n> it will skip the next two lines specified in the configuration. If fingerprint authentication fails, it  \n> will continue with the default behavior specified in the configuration.\n\n6. save and close the file. if you are using nano, you can do this by pressing ctrl + x, then y, then enter.\n7. test: try using sudo command. it should now ask for your fingerprint.\n```\n\n![The place where fingerprints get stored](https://static.404wolf.com/Screenshot_from_2024-04-21_21-06-17_0001.png)\n\nAfter a bit of additional research:\n\n- `fprintd` is a library for storing fingerprints of a user in a local database. It stores them (by default) in `/var/lib/fprint/`. I was curious, so I searched and found the actual fingerpint file, which was a binary file,, under `/var/lib/fprint/wolf/goodixmoc/UIDFAE70212_XXXX_MOC_B0/7`. You can use commands like `fprintd-enroll` and `fprintd-verify` to manage fingerprints.\n- PAM seems to be some sort of tool that acts as an intermediary between the actual authentication methods and the program trying to do authentication. So like, you can use fingerprint auth, password auth, or something else, and just change the PAM config.\n\n## Getting Hibernation working\n\nI followed [this](https://abskmj.github.io/notes/) guide to set up a swap partition and get hibernation to work. It was a bit annoying to do but I got it working where when my computer hibernates it moves all the ram into a specific disc swap partition and then powers off, and can restore from it.\n\n## Automatic mount Google Drive\n\nI wrote a very simple cronjob to call a python script I wrote to automatically mount my Google Drives as hard drives using `rclone`, which is a CLI tool for mounting cloud storage drives with an interface similar to `rsync`.\n\nThen, later, after writing the script I added an automatic call to my crontab.\n\n`@reboot nohup /usr/bin/python3 /home/wolf/Scripts/rclone.py`\n\n```python\nimport subprocess\nfrom time import sleep\nimport logging\nfrom os import listdir, makedirs as mkdirs\n\nREMOTES = (\"Primary\", \"School\",)\nBINARY = \"/usr/bin/rclone\"\nLOGS = \"/home/wolf/Scripts/logs\"\n\n\nopen(LOGS + \"/rclone.log\", \"a\", encoding=\"utf-8\").close()\nlogger = logging.getLogger(__name__)\nlogging.basicConfig(\n\tlevel=logging.INFO,\n    filename=LOGS + \"/rclone.log\",\n    format='%(asctime)s %(levelname)s - %(message)s'\n)\n\ndef mount(binary, remote, directory):\n    subprocess.Popen([binary, \"mount\", f\"{remote}:\", directory])\n    logging.info(f\"Mounted {remote} to {directory}\")\n\ndef isMounted(directory):\n    try:\n        if listdir(directory):\n            logger.debug(\"Remote %s is already mounted\", remote)\n            return True\n        else:\n            logger.debug(\"Remote %s is not mounted.\", remote)\n            return False\n    except FileNotFoundError:\n        logger.warning(\"Creating directory for remote %s since it did not exist\", remote)\n        mkdirs(directory)\n        return False\n\nwhile True:\n    for remote in REMOTES:\n        directory = f\"~/GDrive/{remote}\"\n\n        if not isMounted(directory):\n            mount(BINARY, remote, directory)\n\n    sleep(2)\n```\n\n## Random Vim Things\n\n![NVim telescope search](https://static.404wolf.com/Screenshot_from_2024-04-16_18-17-38_0001.png)\n![NVim With File Tree](https://static.404wolf.com/Screenshot_from_2024-04-16_18-15-57_0001.png)\n\nSince the start of this course I've begun to use vimkeys for everything. I touch type very fast (120+) so I thought it'd be worth the effort to learn keybinds. Here's some fun things I've figured out:\n\n- I configured `neovim` using `vim-plug` to have language engine support so that I can get error checking. I also have symbol tab support and set up github Copilot.\n- `zz` centers your cursor on the page. If the majority of the page is above the cursor this can help center things so you can see more on either side of the cursor.\n- `vi\"` selects everything inside quotes. Then you can do `\"+p` to paste from clipboard into them\n- Following two keybinds work for any letter (not just \"A\"):\n  - `mA` sets a global marker `A` which you can go to with \\`A.\n  - `qa` begins recording a macro `a`. Then `q` again to stop recording. Then `@a` to play it back. Or `\u003Cnum>@a`!\n  - `==` automatically aligns the current line\n  - `V` selects the current line. So you can also do `Vd` instead of `dd` to delete a line.\n  - `T` (not `t`) goes up to the first occurrence backwards. Then pressing `;` to progress forward through matches also goes backwards.\n\n```lua\n-- My NVIM config (scrapped together from various internet sources with some personalizations too)\n\nlocal vim = vim\nlocal Plug = vim.fn['plug#']\n\nvim.opt.relativenumber = true\nvim.opt.tabstop = 2\nvim.opt.shiftwidth = 2\n\nvim.g.loaded_netrw = 1\nvim.g.loaded_netrwPlugin = 1\n\nvim.api.nvim_set_keymap('i', '\u003CC-j>', '\u003CC-n>', {noremap = true, silent = true})\nvim.api.nvim_set_keymap('i', '\u003CC-k>', '\u003CC-p>', {noremap = true, silent = true})\n\nvim.api.nvim_set_keymap('i', '\u003CS-Tab>', 'coc#_select_confirm()', {expr = true, silent = true})\n\nvim.call('plug#begin')\n\n-- Add basic plugins\nPlug('junegunn/vim-easy-align')\nPlug('neoclide/coc.nvim')\nPlug('nvim-tree/nvim-tree.lua')\nPlug('nvim-tree/nvim-web-devicons')\n\n-- Setup bar for tabs\nPlug('lewis6991/gitsigns.nvim')\nPlug('nvim-tree/nvim-web-devicons')\nPlug('romgrk/barbar.nvim')\n\n-- Add search plugin\nPlug('nvim-lua/plenary.nvim')\nPlug('nvim-telescope/telescope.nvim')\n\nvim.call('plug#end')\n\n-- Setup telescope\nlocal builtin = require('telescope.builtin')\nvim.keymap.set('n', '\u003Cleader>ff', builtin.find_files, {})\nvim.keymap.set('n', '\u003Cleader>fg', builtin.live_grep, {})\nvim.keymap.set('n', '\u003Cleader>fb', builtin.buffers, {})\nvim.keymap.set('n', '\u003Cleader>fh', builtin.help_tags, {})\n\n-- Finish setting up nvim tree\nrequire(\"nvim-tree\").setup({\n  sort = {\n    sorter = \"case_sensitive\",\n  },\n  view = {\n    width = 30,\n  },\n  renderer = {\n    group_empty = true,\n  },\n  filters = {\n    dotfiles = true,\n  },\n})\n```\n\nI also configured my vscode vimkeys settings. I made it so that `control + u`, which normally scrolls up half a page, automatically then aligns the page such that the cursor is centered. Also, I added cords for `leader, h` and `leader l` to switch between split screen tabs. Finally, one interesting and slightly solution to a problem I was facing: I remapped `o` to `[\"I\", \"Enter\"]`, which puts the cursor in insert mode at the end of the current line, and presses enter. This does the same thing as `o`, but in order to trigger Github copilot you need to press enter, and this seems to get it to trigger (whereas just pressing `o` to open a line does not).\n\n```json\n[\n  {\n    \"before\": [\"\u003CC-u>\"],\n    \"after\": [\"\u003CC-u>\", \"z\", \"z\"]\n  },\n  {\n    \"before\": [\"\u003CC-d>\"],\n    \"after\": [\"\u003CC-d>\", \"z\", \"z\"]\n  },\n  {\n    \"before\": [\"\u003Cleader>\", \"h\"],\n    \"commands\": [\"workbench.action.focusLeftGroup\"]\n  },\n  {\n    \"before\": [\"\u003Cleader>\", \"l\"],\n    \"commands\": [\"workbench.action.focusRightGroup\"]\n  },\n  {\n    \"before\": [\"\u003Cleader>\", \"s\", \"p\"],\n    \"commands\": [\"editor.action.quickFix\"]\n  },\n  {\n    \"before\": [\"\u003Cleader>\", \"s\"],\n    \"commands\": [\"workbench.view.explorer\"]\n  },\n  {\n    \"before\": [\"o\"],\n    \"after\": [\"A\", \"Enter\"]\n  },\n  {\n    \"before\": [\"O\"],\n    \"after\": [\"I\", \"Enter\", \"Up\"]\n  },\n  {\n    \"before\": [\"\u003Cleader>\", \"p\"],\n    \"commands\": [\"editor.action.formatDocument\"]\n  }\n]\n```\n\n## Stuff I added to my `.bashrc`\n\nThis was all iterative and I added more things as the semester went along. The main things of note:\n\n- Aliases for:\n  - `suspend` and `hibernate`\n  - Editing my `bashrc` itself and then reloading it\n  - Launching `chrome` with a specific user logged in to Google\n- My `Zoxide` installation (an alternative for CD that remembers commonly used paths to help you find them)\n- `control k` or `control j`\n- Exporting some API keys that I always want access to\n\n```bash\n# Basic power aliases\nalias hibernate=\"systemctl hibernate\"\nalias suspend=\"systemctl suspend\"\n\n# Add alias for editing this file\nalias shelledit='vim ~/.bashrc'\nalias shellreload='source ~/.bashrc'\n\n# Add alias for passing clipboard\nalias clip='xclip -selection clipboard'\n\n# Install zoxide CD alternative\neval \"$(zoxide init bash)\"\n\n# Improve shell history\nbind \"\\C-k\":history-search-backward\nbind \"\\C-j\":history-search-forward\n\n# Add pip alises\nalias gpt='/home/wolf/.local/bin/gpt --model gpt-4 --log_file ~/Logs/gpt4'\nalias cheapt='/home/wolf/.local/bin/gpt --model gpt-3.5-turbo-0125 --log_file ~/Logs/gpt3'\nalias black='/home/wolf/.local/bin/black'\n\n# Add open with explorer alias\nalias explorer='nautilus .'\n\n# Add chrome open alias\nalias chrome='/usr/bin/google-chrome-stable --profile-directory=\"Default\"'\nalias chrome-school='/usr/bin/google-chrome-stable --profile-directory=\"Profile 3\"'\n\n# Add alias for listing services\nalias services='systemctl list-unit-files --type service -all'\n\nexport OPENAI_API_KEY=[REDACTED]\n\n# Add open with explorer alias\nalias explorer='nautilus .'\n\n# Add chrome open alias\nalias chrome='/usr/bin/google-chrome-stable --profile-directory=\"Default\"'\nalias chrome-school='/usr/bin/google-chrome-stable --profile-directory=\"Profile 3\"'\n\n# Add alias for listing services\nalias services='systemctl list-unit-files --type service -all'\n```","src/posts/LinuxClassPortfolio.mdx","0d292cb35d212082","literallyeverything",{"id":152,"data":154,"body":160,"filePath":161,"digest":162,"deferredRender":26},{"title":155,"type":15,"date":16,"covers":156,"tags":158,"description":159},"Literally Everything (in Python)",[157],"https://static.404wolf.com/everythingcli_0001.png",[35],"Using OpenAI's's API I've made it possible to literally import anything \"from everything\"! Any function you can imagine, dynamically generated at runtime, accessible with a simple import. When you import \\\u003Canything> from everything, my project uses Python's AST to scan your source, and find all usages of \\\u003Canything>. It then will merge a few lines of context on both sides of every function call, along with the call itself. Then, it will use OpenAI's gpt-4o model to generate a Python function, which you can then use in your code.\n","# I've Done Everything\n\nLast Tuesday, on July 2nd, 2024, I implemented everything in python. There is literally nothing left to implement, I've now done it all.\n\nHere is the\n[Github](https://github.com/404Wolf/everything) and the\n[PyPi](https://pypi.org/project/dothething/)\n\nAnd here's a real world demo...\n\n```py\nfrom everything import sort_list, stylized_greeting\n\n# Print a greeting for Wolf\nprint(stylized_greeting(\"Wolf\", \"Angry\"))\n\n# Sort a list\nprint(sort_list([3, 2, 1, 0, -5, 2.5]))\n```\n\n```cmd\n>> pip install dothething\n>> OPENAI_API_TOKEN=...\n>> python example.py\nWHAT DO YOU WANT, WOLF?!\n[-5, 0, 1, 2, 2.5, 3]\n```\n\nIt is, in a word, everything.\n\n## Inspiration\n\nThe idea hit out of the blue, quite literally, in a conversation with a friend about abstractions for parallel computing. It hit me, why not be able to use your own abstractions created on a whim at runtime?\n\n![The idea!](https://static.404wolf.com/2024-07-05-20240705020336355_0001.webp)\n\n# How's it work?\n\nWhen you import \\\u003Canything\\> from everything, dothething will use Python's AST library to scan your source code, and find all usages of \\\u003Canything\\>. I've defined methods that will search for all usages of given functions, and can then grab parts of the code. Python's AST library is really nice because it provides line numbers with references to the exact location in the source code of different elements. It then will merge a few lines of context on both sides of every function call, along with the call itself. Then, it will use OpenAI's gpt-4o model to generate a Python function, which you can then use in your code.\n\n![Everything CLI](https://static.404wolf.com/everythingcli_0001.png)\n\nIt also works in a `repl`, and scans the history of the interactive shell to see if there's any relevant context. This part is a bit glitchy, and is probably shell and terminal dependent to some extent. It's using python's `readline` library to get access to shell environment stuff.\n\n### Execs\n\nTo actually bring the LLM code into the codebase, I'm using `exec` and a context, where I dump the function into a localized environment and then wrap the function, and call the resulting function with the wrapper. Here's where I actually inject the LLM code...\n\n```py\nfunction_name = re.findall(r\"def (\\w[\\w\\d]+)\\(\", generated_function.split(\"\\n\")[0])\n    function_name = function_name[0] if function_name is not None else \"error\"\n    _LOGGER.debug(f\"Function generated had name {function_name}\")\n\n    def the_thing(*args, **kwargs):\n        exec(generated_function)\n        context = locals()\n        exec(f\"result = {function_name}(*args,**kwargs)\", context)\n        return context[\"result\"]\n```\n\n### Dynamic Imports\n\nTo actually handle being able to import anything, under the hood I've modified the _module's_ `__getattr__`, so that it can create the function when it is imported. My `__init__.py` for the module looks something like this...\n\n```py\n# __init__.py\n\"\"\"Top-level package for everything.\"\"\"\n\n__author__ = \"\"\"Wolf Mermelstein\"\"\"\n__email__ = \"wolfmermelstein@gmail.com\"\n__version__ = \"0.1.0\"\n\n\ndef __getattr__(name: str):\n    from .makethething import make_the_thing\n\n    return make_the_thing(name)\n```\n\n`__init__.py` files are files that are a directive to python that a given folder is a `module`, and they are run when you load the module.\n\nBecause of how module caching works, if you import the same name in different places in your project, it will only generate the function once and then will reuse it multiple times.\n\n![pep 562](https://static.404wolf.com/thePep_0001.png)\n\nBut, as it turns out, this is a relatively new feature that was added in [PEP562](https://peps.python.org/pep-0562/) (PEP = project enhancement protocol). Previously, you had to rely on a hack that the creator of Python himself suggested, overwriting the module with a class that overrides the `__getattr__`.\n\n```python\n\"\"\"Top-level package for everything.\"\"\"\n\n__author__ = \"\"\"Wolf Mermelstein\"\"\"\n__email__ = \"wolfmermelstein@gmail.com\"\n__version__ = \"0.1.0\"\n\n\nfrom typing import Callable\nfrom everything.generator import runtime_generate_function\nimport sys\n\nclass Everything:\n    def __getattr__(name: str) -> Callable:\n        return runtime_generate_function(name)\n\nsys.modules[__name__] = Everything()\n```\n\n# Next Steps\n\nNow that it's working, I've had the idea to take it to the next level by adding a compilation step. Basically, I want to be able to import `everything` throughout my codebase, and even submodules like `everything.finance.irr`, and have my program _build_ a library for you based on the way you use it.\n\nThe idea is that you can use a library that doesn't exist as you want, and then `everything` can \"poof\" it into existence by running something like `everything build`. It would generate a `everything` folder with all the content in it, so you could modify the code if necessary (but that's against the spirit of the library).\n\n## Improvements\n\nThere's a lot of open questions on what I'd need to do to get this to work, and how I can make it better. For one, I want to figure out how to give OpenAi generated functions access to arbitrary Python libraries on PyPi. I also want to be able to lint and verify the code, and black the code to format it.\n\n# Naming\n\nSo, I was thinking, wouldn't it be so awesome if you literally could `pip install everything`? Currently it's [dothething](https://pypi.org/project/dothething/) on PyPi, which is kinda lame.\n\nI looked into it, and it appears that `everything` was not taken on PyPi! However, it's reserved, probably to prevent name hoarding or abuse. I did a lot of research on this, and found out about [PEP 541](https://peps.python.org/pep-0541/), which is an approved Python PEP (project enhancement proposal) for reclaiming unused or unmaintained namespaces on PyPi. I made a request [here](https://github.com/pypi/support/issues/4320), as a github issue, which is the method they suggest, and am currently waiting to hear back.\n\n![The guy!](https://static.404wolf.com/2024-07-04-20240705021721024_0001.webp)\n![Reaching out](https://static.404wolf.com/2024-07-04-20240705021825560_0001.webp)\n\nA bit more research scanning similar requests though, it doesn't seem like PyPi really handles 541 requests anymore. The requests pile up, but only the admins can actually resolve them. This led me on a search to try to find an admin that I might be able to contact directly to get the name `everything`. After a bit of searching, I found Ee, the head of infrastructure for the Python Foundation, and learned that he was a Recurse Center alum too. I reached out to him to see if he'd be able to help, and current am waiting for a response.","src/posts/LiterallyEverything.mdx","8c00cd1fc7c0fb29","msnemails",{"id":163,"data":165,"body":173,"filePath":174,"digest":175,"deferredRender":26},{"title":166,"type":9,"date":80,"covers":167,"tags":171,"description":172},"MSN Emails",[168,169,170],"https://static.404wolf.com/caffeinate_creation.webp","https://static.404wolf.com/covid_msn.webp","https://static.404wolf.com/make_email.webp",[35],"A few years ago I discovered a Microsoft account creation captcha bypass exploit that allowed you to create @msn.com email accounts through an old piece of microsoft software called MSN explorer. I submitted a vulnerability report and got it approved, and a captcha added to the endpoint. I talk about how the process works, how I was able to figure it out, and, at the end, I provide an explanation of how it's still possible (in 2023+!) to create a Microsoft account with the domain via a straightforward step-by-step walk through.\n","# Inspiration\n\n![Allowed email domains (2023)](https://static.404wolf.com/2023_email_creation.webp)\n\nWhen I first saw it, it was extremely intriguing, but also slightly confusing. On a website where people resell social media accounts with fancy usernames, I came across a strange blog post online offering to create and then sell brand new Microsoft email accounts with the `@msn.com` email domain name for $35 each. It's weird since, though Microsoft has gone through various versions of its email service and has formerly offered domains including `@live.com` `@passport.com` and `@msn.com` domains, currently, for years you've only been able to create accounts with emails ending in `@outlook.com` and `@hotmail.com`. But yet someone had discovered a method to create `@msn.com`-suffixed emails, which was really strange. Did they work at Microsoft, or did they find a bug? As soon as I saw the post, I got to work, scouring Google for more information about the history of the domain. It wasn't long before I struck success, and figured it out for myself.\n\n## MSN Network\n\n![Welcome screen](https://static.404wolf.com/msn_premium_welcome.webp)\n\nTo start, I began by researching the history of the `@msn.com` domain a bit further, thinking that perhaps some old tool associated with the domain would have left an endpoint in existence to create emails with the antiquated domain. It didn't take long to learn that MSN stands for Microsoft network, which was closely associated with a collection of eclectic Windows applications released in 1995. At the time, various network services were offered at a low monthly rate, and users could connect to the servers through Dial-Up. Around that time was also when Microsoft released `@msn.com` email addresses for subscribers of what they called \"MSN premium subscriptions.\" Though they later switched to Hotmail and made it so that users without MSN premium could create Microsoft email accounts for free, they never actually got rid of the old MSN premium subscription. They've undergone various stages of rebranding for their email services, but nevertheless, their program [Msn Premium](https://www.microsoft.com/en-us/p/msn-premium/CFQ7TTC0KGVF) still exists, and is currently $9 a month, with the ability to get a full refund before month end.\n\n### MSN Explorer\n\n![MSN Premium (2023)](ttps://static.404wolf.com/msn_explorer.webp)\n![Install wizard](https://static.404wolf.com/install_wizard.webp)\n\nAs I carefully read through the product's description, things started looking promising: they offer \"computer wide security software, advanced phishing filter technology, pop-up guard\" but, most importantly, \"**multiple e-mail accounts**.\" It wasn't explicitly stated, but it seemed like those \"multiple emails\" were likely to be somehow program-specific, and perhaps `@msn.com`-suffixed. Upon finding the subscription page I eagerly purchased a month subscription, fully intending to cancel right after exploration. I installed the program, which had, of course, a pleasant built-in installer soundtrack, and was greeted by a friendly, informative, archaic welcome screen and only slightly creepy \"Hello, Wolf\" cortana voice. It took a bit of time, but eventually I found what I was looking for. In the accounts tab of settings, under the \"add user\" form, in the \"create user\" subform, I found an ancient Microsoft webpage meant for creating `@msn.com` emails.\n\n# My first @msn\n\n![My first @msn email](https://static.404wolf.com/caffeinate_creation.webp)\n\nThe form was a straightforward, requiring me to enter the desired email, along with some additional information, such as birthdate, location, and name. Interestingly, there was a \"security question\" field: a long-removed layer of security that has since been replaced with two-factor authentication and email/sms verification. Once I reached the end of the form, unlike the light grey TOS checkboxes of the present day, I was required to type in my full name to proceed. And then, it was there! A new email address had been created. After a quick login on Microsoft's normal log in page, I indeed had created a brand new, 2023 `@msn.com` email. Of course, I wasn't done yet; I decided to continue tinkering.\n\n### Extracting the form\n\nAfter more carefully inspecting the user flow, it occurred to me how truly insecure the process was: the process lacked a captcha or verification of any kind; it was a simple ASPX (predecessor to PHP!) form. So, what's to stop someone like me from creating a script to automate the process, and generate thousands of accounts automatically? Apparently nothing, and so I tried doing just that, as a proof-of-concept. I carefully inspected the form, looking for ways to extract the endpoint of the form requests. Something that I noticed in was that, for the brief loading gaps between pages of the form, a link flashed at the top of the email creation widget. With a timely screenshot I was able to extract the link, and with a long night of scouring and reverse engineering network requests, I was able to write a script to reverse the process. Though each paying `@msn.com` user was allowed to create 10 sub-user accounts, I quickly figured out that detaching the sub-users from the main paying account was meaningless, since the accounts were automatically ported to brand new Microsoft accounts anyway. I was quickly able to make a tool to extract and parse the HTML, make appropriate HTTP requests, and then load up a json with 1k accounts. The process was seamless, and the brand new accounts were fully usable with a working email, onedrive, and all.\n\n### Reporting the exploit\n\nThis was my first time discovering a website vulnerability, so I wasn't quite sure how to proceed. I knew something had to be done, because it was evident that if anyone else with more computational and network power than I were to come along they'd be able to create hundreds of thousands of accounts automatically, which they could use easily use for scamming or email spamming. After a bit of Googling, I came across the [Microsoft Security Response Center](https://msrc.microsoft.com/) vulnerability report form, and wrote up a report along with a simple proof-of-concept script and video showcase. It took a while, but a few months later Microsoft was able to reproduce the bug, and a month after that they resolved the issue by adding a simple captcha to the form, which is still in place to this day. It's just a simple text-captcha that can likely be solved with simple OCR, but I suppose it's better than nothing.\n\n## The names\n\n![covid@msn.com](https://static.404wolf.com/covid_msn.webp)\n\nOne thing I quickly learned through this process was how truly archaic `@msn.com` email addresses really are. I quickly realized that, as an inevitable result of there being no longer easily available, there were many unclaimed emails with modern English words and topics. I began claiming emails like `covid@msn.com`, `airpod@msn.com`, `JoeBiden@msn.com`, `technophile@msn.com`, `ethereum@msn.com`, `spotify@msn.com`, and more. Since I was, at the time, waiting for the captcha bypass vulnerability to get patched, I decided to write a script for fun to automatically snag most of the Pokemon, and a bunch of modern youtube channel names. I also figured out that one easy and effective way to check if an `@msn.com` email exists is to simply use the default account recovery form, wherein it only provides you a continue-confirmation if the account exists, and tells you that the account doesn't exist (and thus _can_ be taken) otherwise.\n\n# Make your own @msn email\n\n## As of recently...\n\n![Email creation page](https://static.404wolf.com/make_email.webp)\n\nAs is stands now, @msn.com emails are still acquirable through the method outlined above, but because of my report to MSRC there is now a captcha in place. I imagine that as long as MSN Premium remains available, `@msn.com` emails will remain available with it. Since Microsoft has a reputation for supporting antiquated projects for long amounts of time, I anticipate that this technique will work for a long time to come.\n\n## The steps\n\n**Disclaimer: Multiple people have emailed me now telling me that this no longer works, and it seems like Microsoft disabled creating @msn.com emails all together.**\n\nHere's a straightforward list of the steps you can take to create an `@msn.com` email account in 2023 and beyond. If you have any questions, feel free to contact me.\n\n1. Go to the [msn premium purchase page](http://www.microsoft.com/en-us/p/msn-premium/CFQ7TTC0KGVF) and purchase 1 month of msn premium (~$10). As noted previously, you'll be able to cancel this later for a full refund.\n\n2. Visit [membercenter.msn.com/signin.aspx](http://membercenter.msn.com/signin.aspx), the member center sign in page on their website.\n\n3. Click \"Sign In,\" and sign in with the same Microsoft you just purchased msn premium on.\n\n4. Visit [texreg2.msn.com/wbum/Selector.aspx](http://texreg2.msn.com/wbum/Selector.aspx). This is the specific link that is embedded into Msn Explorer, and lets you add emails.\n\n5. Click \"Add a member,\" and fill out the form that follows. The information is arbitrary, but make sure to save everything. After that, click next. You will have to complete a captcha as part of this process. Note that clicking enter after filling out the captcha box will reset it, so you need to manually click on the submit button.\n\n6. Enter the same name you entered prior in the name signature box and then click \"Accept.\" If a few seconds later it says \"You have successfully added \\\u003Cemail> to your membership\" everything was done correctly.\n\n7. Go to login.live.com and sign in to the account as normal.\n\n8. Enter the new email you created for the email and click \"Next.\"\n\n9. Your account should be successfully created and operational!","src/posts/MSNEmails.mdx","b4a25bdc0a3725ab","markdownimageblocks",{"id":176,"data":178,"body":184,"filePath":185,"digest":186,"deferredRender":26},{"title":179,"type":9,"date":93,"covers":180,"tags":182,"description":183},"Markdown Image Blocks",[181],"https://static.404wolf.com/carouselExample_0001.png",[35,20],"I talk about how I got my markdown to include image groups with many images side-by-side, automatically. I’ve scoured my way through eclectic convoluted docs, pained past unsensical bugs, and have finally begun to wrap my head around the world of JS markdown parsing. With a general overview and some useful snippets, you’ll too learn how to customize markdown rendering for your own purposes.\n","# Background\n\n![Markdown flow](https://static.404wolf.com/markdown-flowchart_0001.webp)\n\nBefore I discuss exactly what the purpose of this endeavor was, here's some context. I use `markdown` to write my blogs, a simple rich-text language format that doesn't pack in too much support for that type of customization. Markdown is nice because it lets you define in plain-text things like images, headings, tables, and more, but at the end of the day it's just a syntax for writing rich text; it's the job of the renderer to actually display it in its final form.\n\nA simple markdown script may look something like this, with various headings and graphics. Here's [more information on the syntax](https://www.markdownguide.org/basic-syntax/) if you're interested.\n\n```md\n# Heading\n\n## Subheading\n\n### Subsubheading\n\n![imgName](imgSrc)\n[link](src)\n\n| column1 | column2 |\n| ------- | ------- |\n```\n\nPart of what makes Markdown so popular is the fact that once you've finished writing `markdown`, there's many different frameworks in many different programming languages that allow for rendering the file. On the web, this usually means converting `markdown` text into `HTML`, so as to display the various elements visually. These frameworks abstract-ify the process, and make it as easy as inserting a few lines of code to get the `markdown` to render properly. Unfortunately for me, for my blogs I wasn't quite content with the default configuration of my renderer.\n\n## Markdown Images\n\nMy ultimate problem with my renderer was related to how it displayed images. In regular `markdown`, to include an image you use `![alt](src)` syntax. Then, when rendered, markdown places an image in between the text above and below the image declaration. When I write blogs, however, I often want to include many different images of the same thing, or same content. A grid of graphics to showcase every perspective of an object or a sequence of photos to display a process. 'Vanilla' markdown on its own does not provide any other level of customization, but after some research I did determine that there are indeed some external solutions, outlined below, of which none quite met my needs.\n\n### Flavored Markdown\n\nSome flavors of markdown, such as [Github flavored markdown (GFL)](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax), allow for some limited customization with particular inline html syntax. For example, with GFL you can write `\u003Cimg align=\"left\" src=\"img.jpg\">` to define a left floating image, taking advantage of the special `align` prop. Other customizations are allowed inline, like setting the dimensions of images. To specify a specific pixel width of an image in markdown, you can use `![alt](src|width=123)` syntax.\n\n### MDX Markdown\n\n`MDX` markdown is a special type of markdown file that is denoted with the file extension `.mdx`. With MDX markdown, you can include `React` components inline, much like you can with `JSX`. `JSX` is a syntax extension to `javascript` that allows for inline `HTML`, and `MDX` is a syntax extension for `JSX` that allows for inline `markdown`. Without getting too far into the details, with `MDX` markdown you could theoretically implement some sort of custom image component, and use tags instead of `markdown` image syntax to place the customized images.\n\n## The Problem\n\nThis issue with these methods is that in all these various methods of customizing markdown inline `HTML` in some form or another is involved. This takes away from the beauty of vanilla `markdown`, since to customize how images render I have to type out tags and deal with properties to some extent or another. Sure, it can be minimized with proper planning and implementation, but only to an extent. What I like is simplicity, and so I decided to implement my own solution to get images to render my way. Perhaps the task was unnecessarily overkill, but gaining a better grasp of the rendering process was really rewarding, and extremely interesting.\n\n## The goal\n\nFor the final product, I decided to apply two different alterations to vanilla `markdown` rendering. Firstly, I wanted to be able to include \"blocks\" of images, so that I could cluster images together; secondly, I wanted regular images to be customizable with inline properties (more on this soon).\n\n### Image blocks\n\nMy decision, before even beginning to research how to go about it, was to have it so that markdown like this...\n\n```md\n# This is a header\n\n![This is an image](https://static.404wolf.com/src1.png)\n![This is an image](https://static.404wolf.com/src2.png)\n![This is an image](https://static.404wolf.com/src3.png)\n\nThis is a paragraph within the markdown.\n![This is a regular image](https://static.404wolf.com/src4.png)\n```\n\n![Image carousel](https://static.404wolf.com/carouselExample_0001.png)\nWould render such that the three images that have a newline above and below them would appear as a carousel of images, and the regular paragraph images would automatically float so as to not disrupt reading of the text.\n\n### Image properties\n\nAdditionally, I decided that it would be best to allow for all image customization to occur in the definition of the images themselves, and, to ensure consistency with `GFM`, I chose to take advantage of the absolute-value-equals-sign syntax. All images could by default float to the right, but I'd want to be able to change their floating direction to the left by writing out something along the lines of `![alt](src|float=left)`. For now I chose to include the ability to customize the `float` and `width` of images, but it was important to me to design the system to allow for future extension.\n\n# Implementation\n\nMy website's frontend is currently created with `React`, a framework that allows for component-based web UI development. To implement a feature like markdown rendering into a react website, the common first step would be to do a quick Google to see if any `component`s exist that do what I need, since many extensions to `React` are component-libraries. As it turns out, there indeed existed a component for the job: [react-markdown](https://github.com/remarkjs/react-markdown).\n\n## React markdown\n\nReact markdown is a library that is essentially a wrapper on the [unified](https://github.com/unifiedjs/unified) ecosystem, a `javascript` package that implements abstract syntax trees (ASTs). `unified` allows for many different extensions, including a very popular one called [remark](https://github.com/remarkjs/remark) to parse a markdown string into a `unified` AST, and another popular one called [rehype](https://github.com/rehypejs/rehype) for `HTML` parsing. To understand how react markdown works, it's important to understand how to render markdown to raw `HTML` with `unified` first. For this, let's take a look at a super simple `unified` script that I wrote during the tinkering phase of this project, which is along the lines of the boilerplate that `ReactMarkdown` conceals.\n\n```js\n...\nconst buffer = fs.readFileSync(\"./example.md\");\n\nretext()\n    .use(remarkParse)\n    .use(remarkRehype)\n    .use(rehypeStringify)\n    .process(buffer, (err, file) => {\n        const rendered = prettify(file.value);\n        console.log(rendered);\n        fs.writeFileSync(\"./example.html\", rendered)\n    });\n```\n\nHere we begin with plaintext and load it into retext, a part of the `unified` collective that is meant for raw text. Then we build up a chain of plugins to funnel our markdown through. First we use `remarkParse` to convert the markdown string into a `mdast`, a markdown AST. Then we use `remarkRehype` to mutate that tree into a `hast`, a `HTML` AST, and finally we use `rehypeStringify` to deconstruct the tree into an `HTML` string, which we finally dump into a file.\n\nEach of the things that we \".use()\" is a `javascript` function that takes the `tree` and, optionally, `file` metadata as input, does stuff with it (like mutating the tree), and then spits back out the tree to be used by the next extension in the chain. The render is then stored in a `VFile` object, from which the output `HTML` string can be extracted.\n\nReact markdown makes this process super-simple, since it handles this process for you, and then also parses the output `HTML` string into `React` components. It can be used by simply passing the markdown in as the child element, as so...\n\n```html\n\u003CReactMarkdown>\n  # Hello, *world*! This is an example of how to use react-markdown.\n\u003C/ReactMarkdown>\n```\n\nIt only uses the bare minimum \".use()\"s to convert the markdown into `HTML`, but it does allow you to pass `remarkPlugins` and `rehypePlugins` to further customize the `mdast` and `hast` ASTs. They provide a nice diagram of this process.\n\n```txt\n                                                           react-markdown\n         +----------------------------------------------------------------------------------------------------------------+\n         |                                                                                                                |\n         |  +----------+        +----------------+        +---------------+       +----------------+       +------------+ |\n         |  |          |        |                |        |               |       |                |       |            | |\nmarkdown-+->+  remark  +-mdast->+ remark plugins +-mdast->+ remark-rehype +-hast->+ rehype plugins +-hast->+ components +-+->react elements\n         |  |          |        |                |        |               |       |                |       |            | |\n         |  +----------+        +----------------+        +---------------+       +----------------+       +------------+ |\n         |                                                                                                                |\n         +----------------------------------------------------------------------------------------------------------------+\n```\n\nBy understanding that the library is simply a wrapper atop a much more complex process, it becomes critical to understand the actual render process itself. For example, at first the optional prop `remarkRehypeOptions` makes no sense, but as will soon become apparent, being able to set options for the `remarkRehype` stage in the render process (which will be discussed soon) is critical to implementing my custom image blocks.\n\nAnother important part of react markdown that I noticed in my research was concerned was the ability to set component overrides. You see, once react markdown has reached the final stage of rendering and has an `HTML` string, it then proceeds to convert that `HTML` into `React` components. It does this by using sensical defaults, such as the `\u003Cimg>` component for images, `\u003Cp>` for paragraphs, and the like. However, the library allows you to set overrides on components, by defining your own components and then setting it in the options of the `ReactMarkdown` component. Here's the example [their documentation](https://github.com/remarkjs/react-markdown#appendix-b-components) provides...\n\n```html\n\u003CReactMarkdown\n  components={{\n    // Map `h1` (`# heading`) to use `h2`s.\n    h1: 'h2',\n    // Rewrite `em`s (`*like so*`) to `i` with a red foreground color.\n    em: ({node, ...props}) => \u003Ci style={{color: 'red'}} {...props} />\n  }}\n/>\n```\n\n![The aha moment](inspiration_0001.png|width=60)\n\nIt seemed that to incorporate clustered images, the simplest solution would be to have the groups of images in my markdown turn into some sort of fake `HTML` component with props including _all_ the images data, so that I could then define an override for that component, to render it the way I wanted. In other words, if a cluster of images in `markdown` could transform into something of the form `\u003CimgBlock alts=\"alt1;alt2;alt3\" srcs=\"src1;src2;src3\"/>` I could then define a `React` component of the form `ImgBlock (alts, srcs) { ... }` to handle the rendering. The hard part would be to locate and modify the rendering process to have the output string include those custom `\u003CImgBlock>`s\n\n## Render process\n\nNow, before adding any custom plugins or alterations, let's take a look at the example I was working with, and discuss how the rendering flow actually works.\n\nFor the initial tests, the input looked like this...\n\n```md\n# An example document with a multiimage\n\nTest1\n\n![Image #1](https://src-to-img-1.com)\n![Image #2](https://src-to-img-2.com)\n![Image #3](https://src-to-img-2.com)\n![Image #4](https://src-to-img-2.com)\n\nTest2\n![Normal Image](https://src-to-normal-img.com|float=left|width=50)\n\n![Normal Image But Isolated](https://src-to-normal-img.com|width=35|float=right)\n```\n\nAnd the output like this...\n\n```html\n\u003Ch1>An example document with a multiimage\u003C/h1>\n\u003Cp>Test1\u003C/p>\n\u003Cp>\n  \u003Cimg src=\"https://src-to-img-1.com\" alt=\"Image #1\" />\n  \u003Cimg src=\"https://src-to-img-2.com\" alt=\"Image #2\" />\n  \u003Cimg src=\"https://src-to-img-2.com\" alt=\"Image #3\" />\n  \u003Cimg src=\"https://src-to-img-2.com\" alt=\"Image #4\" />\n\u003C/p>\n\u003Cp>\n  Test2\n  \u003Cimg\n    src=\"https://src-to-normal-img.com%7Cfloat=left%7Cwidth=50\"\n    alt=\"Normal Image\"\n  />\n\u003C/p>\n\u003Cp>\n  \u003Cimg\n    src=\"https://src-to-normal-img.com%7Cwidth=35%7Cfloat=right\"\n    alt=\"Normal Image But Isolated\"\n  />\n\u003C/p>\n```\n\n## Creating a plugin\n\nCreating a plugin would involve simply adding a function to the chain. Part of what makes `unified` so great is that it provides [tons of utilities](https://unifiedjs.com/explore/project/syntax-tree/) that allow you to easily locate parents, traverse specific parts of the tree, search for nodes, and more. For my purpose, I'd just need [unified-visit](https://unifiedjs.com/explore/package/unist-util-visit/) to walk the tree, which handily provides the ability to walk all nodes that pass a specific filter only. Looking back at the example, it appeared to be the case that all clustered images were determined to be the children of a paragraph, so I'd only care about paragraph nodes. To start, I wrote the plugin to just print them out, to see what I was working with.\n\n```js\n{\n  type: 'paragraph',\n  children: [ { type: 'text', value: 'Test1', position: [Object] } ],\n  position: {\n    start: { line: 3, column: 1, offset: 43 },\n    end: { line: 3, column: 6, offset: 48 }\n  }\n}\n{\n  type: 'paragraph',\n  children: [\n    {\n      type: 'image',\n      title: null,\n      url: 'https://src-to-img-1.com',\n      alt: 'Image #1',\n      position: [Object]\n    },\n    { type: 'text', value: '\\r\\n', position: [Object] },\n    {\n      type: 'image',\n      title: null,\n      url: 'https://src-to-img-2.com',\n      alt: 'Image #2',\n      position: [Object]\n    },\n    { type: 'text', value: '\\r\\n', position: [Object] },\n    {\n      type: 'image',\n      title: null,\n      url: 'https://src-to-img-2.com',\n      alt: 'Image #3',\n      position: [Object]\n    },\n    { type: 'text', value: '\\r\\n', position: [Object] },\n    {\n      type: 'image',\n      title: null,\n      url: 'https://src-to-img-2.com',\n      alt: 'Image #4',\n      position: [Object]\n    }\n  ],\n  position: {\n    start: { line: 5, column: 1, offset: 52 },\n    end: { line: 8, column: 38, offset: 206 }\n  }\n}\n{\n  type: 'paragraph',\n  children: [\n    { type: 'text', value: 'Test2\\r\\n', position: [Object] },\n    {\n      type: 'image',\n      title: null,\n      url: 'https://src-to-normal-img.com|float=left|width=50',\n      alt: 'Normal Image',\n      position: [Object]\n    }\n  ],\n  position: {\n    start: { line: 10, column: 1, offset: 210 },\n    end: { line: 11, column: 67, offset: 283 }\n  }\n}\n{\n  type: 'paragraph',\n  children: [\n    {\n      type: 'image',\n      title: null,\n      url: 'https://src-to-normal-img.com|width=35|float=right',\n      alt: 'Normal Image But Isolated',\n      position: [Object]\n    }\n  ],\n  position: {\n    start: { line: 13, column: 1, offset: 287 },\n    end: { line: 13, column: 81, offset: 367 }\n  }\n}\n```\n\nLooking at the output, I identified the image block to be the `paragraph` node on line 10, which I immediately started scouring for patterns that I may be able to check against. As can be seen, images on subsequent lines are pretty easily identifiable: the children of the parent `paragraph` element simply contains alternating `image` and `text` tags with `text` having a value of `\\r\\n`. Here's the plugin I wrote to swap out the alternating images and texts with image block nodes...\n\n```js\nimport { visit } from \"unist-util-visit\";\n\nexport default function remarkImageBlock() {\n  return (tree, file) => {\n    visit(tree, \"paragraph\", (node, index, parent) => {\n      if (node.children) {\n        const children = node.children.filter(\n          (child) => !(child.type === \"text\" && child.value === \"\\r\\n\"),\n        );\n        if (\n          children &&\n          children.every((child) => child.type === \"image\") &&\n          children.length > 1\n        ) {\n          parent.children[index] = {\n            type: \"imgBlock\",\n            alts: children.map((child) => child.alt),\n            srcs: children.map((child) =>\n              child.url.includes(\"|\") ? child.url.split(\"|\")[0] : child.url,\n            ),\n            titles: children.map((child) => child.title),\n            properties: children.map((child) =>\n              child.url.includes(\"|\") ? child.url.split(\"|\").slice(1) : \"\",\n            ),\n            position: {\n              start: children[0].position.start,\n              end: children.slice(-1)[0].position.end,\n            },\n            children: [],\n          };\n        }\n      }\n    });\n    return tree;\n  };\n}\n```\n\nWhile iterating over all the paragraph nodes, we get rid of all the `text` child nodes that have a value of `\\r\\n`, and then check to see if there's more than one child `image` left. If there is, we've located an image block, and swap the paragraph out for a custom `imgBlock` node by mutating the parent of the `paragraph`'s children at `paragraph`'s index.\n\nNow, I adjusted the `unified` flow to include the new plugin.\n\n```js\nretext()\n  .use(remarkParse)\n  .use(remarkImageBlock)\n  .use(remarkRehype)\n  .use(rehypeStringify)\n  .process(buffer, (err, file) => {\n    fs.writeFileSync(\"./example.html\", file.value);\n  });\n```\n\nBefore changing the `mdast` (markdown AST) to a `hast` (HTML AST), I modify the `mdast` with my plugin to create `imgBlock` nodes where needed, swapping out old `paragraph` nodes. But upon printing the output, it didn't quite work.\n\n## Where did the imgBlocks go?\n\nInstead of having the fake `HTML` `\u003CimgBlock>`s that I expected, I got an empty div.\n\n```html\n\u003Ch1>An example document with a multiimage\u003C/h1>\n\u003Cp>Test1\u003C/p>\n\u003Cdiv>\u003C/div>\n\u003Cp>\n  Test2\n  \u003Cimg\n    src=\"https://src-to-normal-img.com%7Cfloat=left%7Cwidth=50\"\n    alt=\"Normal Image\"\n  />\n\u003C/p>\n\u003Cp>\n  \u003Cimg\n    src=\"https://src-to-normal-img.com%7Cwidth=35%7Cfloat=right\"\n    alt=\"Normal Image But Isolated\"\n  />\n\u003C/p>\n```\n\nBut, when printing out the tree at the stage before `remarkRehype`, it looked like this...\n\n```js\n{\n  type: 'root',\n  children: [\n    {\n      type: 'heading',\n      depth: 1,\n      children: [Array],\n      position: [Object]\n    },\n    { type: 'paragraph', children:\n [Array], position: [Object] },\n    {\n      type: 'imgBlock',\n      alts: [Array],\n      srcs: [Array],\n      titles: [Array],\n      properties: [Array],\n      position: [Object],\n      children: []\n    },\n    { type: 'paragraph', children:\n [Array], position: [Object] },\n    { type: 'paragraph', children:\n [Array], position: [Object] }\n  ],\n  position: {\n    start: { line: 1, column: 1, offset: 0 },\n    end: { line: 13, column: 81, offset: 367 }\n  }\n}\n```\n\n## The culprit\n\nIt turned out that the `imgBlock`s were getting lost during the `remarkRehype` stage, since `remarkRehype` didn't know how to handle the foreign `imgBlock` nodes. When `remarkRehype` converts the `mdast` to an `hdast` it uses special predefined handlers, which can all be found [here](https://github.com/syntax-tree/mdast-util-to-hast/tree/main/lib/handlers), and take the form of something along the lines of this...\n\n```js\nimport { normalizeUri } from \"micromark-util-sanitize-uri\";\n\nexport function image(state, node) {\n  const properties = { src: normalizeUri(node.url) };\n\n  if (node.alt !== null && node.alt !== undefined) {\n    properties.alt = node.alt;\n  }\n\n  if (node.title !== null && node.title !== undefined) {\n    properties.title = node.title;\n  }\n\n  const result = { type: \"element\", tagName: \"img\", properties, children: [] };\n  state.patch(node, result);\n  return state.applyData(node, result);\n}\n```\n\nEach has slight modifications based to port the markdown to HTML, but the general format is the same. In order to create an `\u003CimgBlock>` HTML component, I'd need to define my own handler, and pass it into the `remarkRehype` plugin. Creating the handler was simple, since I could just reuse a similar schema to the above `\u003Cimg>` handler definition.\n\nAt this stage, since I already had access to the `alt`s, `src`s, and `title`s of the images, I thought I mine as well scrape out properties from the `src`. That is, an image that was spelled out in markdown like `![alt](src.png|width=50|float=left)` would have its `src` be `src.png|width=50|float=left`. This would be a good point to strip off those extra image configs and pass them down the chain as a separate properties prop.\n\n```js\nexport function imgBlockHandler(state, node, parent) {\n  return {\n    type: \"element\",\n    tagName: \"imgBlock\",\n    properties: {\n      alts: node.alts.join(\";\"),\n      srcs: node.srcs.map(normalizeUri).join(\";\"),\n      titles: node.titles.join(\";\"),\n      properties: node.properties.join(\";\"),\n    },\n    children: [],\n  };\n}\n\nexport function imgHandler(state, node, parent) {\n  const properties = {};\n  for (const property of node.url.matchAll(/((\\w+)=(\\w+))/g)) {\n    properties[property[2]] = property[3];\n  }\n  const url = /\\w*|\\w=*/.test(node.url)\n    ? node.url.match(/([^\\s^\\|]*)\\|/)[1]\n    : node.url;\n\n  return {\n    type: \"element\",\n    tagName: \"img\",\n    properties: {\n      alt: node.alt,\n      src: url,\n      title: node.title,\n      ...properties, // like float: left, width: 50, etc.\n    },\n    children: [],\n  };\n}\n```\n\nI decided to split the `alt`s, `src`s, and `title`s with semicolons, since I wanted to allow for an arbitrary number of images in a block. Since the markdown would become a html string before becoming a react components, any javascript privatives like `Array`s would get lost, so this seemed to be the best solution.\n\nI modified the`unified` script to be as follows, including these custom handlers in the `mdast` to `hdast` conversion process...\n\n```js\nretext()\n  .use(remarkParse)\n  .use(remarkImageBlock)\n  .use(remarkRehype, {\n    handlers: { imgBlock: imgBlockHandler, image: imgHandler },\n  })\n  .use(rehypeStringify)\n  .process(buffer, (err, file) => {\n    fs.writeFileSync(\"./example.html\", file.value);\n  });\n```\n\nAnd now, with the custom handlers in place, I executed the `unified` script, and vola!\n\n```js\n\u003Ch1>An example document with a multiimage\u003C/h1>\n\u003Cp>Test1\u003C/p>\n\u003CimgBlock\n    alts=\"Image #1;Image #2;Image #3;Image #4\"\n    srcs=\"https://src-to-img-1.com;https://src-to-img-2.com;https://src-to-img-2.com;https://src-to-img-2.com\"\n    titles=\";;;\"\n    properties=\";;;\"\n>\u003C/imgBlock>\n\u003Cp>\n    Test2 \u003Cimg alt=\"Normal Image\" src=\"https://src-to-normal-img.com\" float=\"left\" width=\"50\" />\n\u003C/p>\n\u003Cp>\n    \u003Cimg\n        alt=\"Normal Image But Isolated\"\n        src=\"https://src-to-normal-img.com\"\n        width=\"35\"\n        float=\"right\"\n    />\n\u003C/p>\n```\n\nSuccess!\n\n## React component override\n\nNow all that there was left to do was to define a react component to override the fake `\u003CimgBlock>`s with, since browsers on their own don't know how to deal with them. I wrote out some react components for the purpose, and then slotted them into the components override prop of `ReactMarkdown`. With everythinig properly in place, the markdown rendering component now looked like this...\n\n```js\n\u003CReactMarkdown\n  children={markdown}\n  className=\"markdown\"\n  remarkPlugins={[remarkImageBlock]}\n  remarkRehypeOptions={{\n    handlers: { imgBlock: imgBlockHandler, image: imgHandler },\n  }}\n  components={{\n    img: ({ node, ...props }) => (\n      \u003CMdImage\n        alt={props.alt}\n        title={props.title}\n        src={props.src}\n        width={props.width}\n        float={props.float}\n        label={props.alt}\n        resourceMap={resourceMap}\n      />\n    ),\n    imgBlock: ({ node, ...props }) => (\n      \u003CImageBlock\n        alts={props.alts}\n        titles={props.titles}\n        srcs={props.srcs}\n        resourceMap={resourceMap}\n      />\n    ),\n  }}\n/>\n```\n\nAnd it worked! This is the current renderer that I use for my website, with custom overrides for images and image blocks. I've also since added a code block rendering override, and may add another override for videos and/or gifs in the future.\n\n# Implications\n\nAs now can be seen, the process I used is extremely powerful. People have coded plugins to display inline LaTeX, display codeblocks (like the ones in my blog posts!), and so, so much more. What's unique and tricky about my process is how I take advantage of custom component overrides to add brand new components to markdown.\n\nI can see infinite different ways that this same process could be utilized: adding brand new elements to inline markdown without requiring any inline HTML, modifying how certain paterns of elements display on screen, adding video support to markdown, and much more.","src/posts/MarkdownImageBlocks.mdx","fe37a3ca94d3165a","minecraftusernameautoclaiming",{"id":187,"data":189,"body":195,"filePath":196,"digest":197,"deferredRender":26},{"title":190,"type":15,"date":80,"covers":191,"tags":193,"description":194},"Ember Sniper",[192],"https://static.404wolf.com/the_queue.jpg",[35],"For many, it's a sandbox for creativity, and a haven for ingenuity. And yeah, it is that. But for me a few years back, it was much much more: it was a lucrative business opportunity. At the time, I had first entered the realm of Minecraft-username-trading. A corner of the internet dedicated to buying/selling accounts with cool names for exorbitant prices. But what caught my eye was a niche of the niche: username-sniping—using bots to 'snipe' accounts with cool (and valuable) usernames right as they become available. Though it sounded simple, it turned out to be an intense, competitive game of tactic.\n","# Inspiration\n\nPreviously, Minecraft had been to me, much like it is to the rest of the world, a videogame. I had done some tinkering with datapacks, experimented with the interesting mechanics of redstone, and contrived some unique art with WorldEdit, but none of my prior experience was anything like what was to come. The first stage of the journey was discovery of the Minecraft-specific social media company [NameMc](https://namemc.com). NameMC is a website dedicated to indexing all Minecraft accounts, and then producing profiles wherein you can link your contacts and socials. The goal is to help people find information about account owners, share your account's \"skin\" (your avatar's exterior), and more. However, NameMC was more than just a profile based Minecraft social media network. It also cataloged name changes and account cosmetics like capes.\n\nOn NameMC, one specific page caught my eye above the rest: [the minecraft names droptime table](https://namemc.com/minecraft-names). This page neatly listed all usernames soon to be available for claiming, and showed when they were to free up. It was able to list out all the names because NameMC, by polling accounts and caching the information was able to store the name-change history of all accounts, and automatically could list people who had recently changed their username. As I scoured the page, I saw that there were some really neat usernames soon to become available, and began wondering how hard it would be to claim them.\n\nThe first name of interest happened to be \"adult,\" which I thought would be a really unique account name, so, instinctively, I got myself situated at my desk, logged into my account's settings page, entered the name, and carefully hovered my cursor over the \"Change Your Username\" button. But, as it turned out, my single hopeful click, also known as a \"hand snipe,\" was no match for the storm of thousands of automated 'sniper' requests that I would soon learn about. When the time came for the name to become publicly claimable the page momentarily lagged out, and then the name was snatched away by a big-name username 'sniping' organization.\n\n# Research phase\n\nAs usual for these sorts of projects, my adventure into the world of username sniping began with extensive research. The Minecraft username community turned out to mostly take the form of a fairly decentralized array of Discord servers. I hopped from one to another, making friends and further exploring the community. I came across many smaller organizations just starting out, trying to make a name for themselves. I traversed many larger scale marketplaces for Minecraft accounts, some having complex auction systems and account proxying services (offering to sell your account through their system for a fee). I encountered middlemen that had built up reputations for trading tens of thousands of dollars worth of accounts, and much much more. Through my traipses, though it seemed insane to me that people were paying thousands for videogame accounts with cool names, I knew that there was potential for me to start a service of my own.\n\n### Sniping Services\n\nOne unique category of Discord server that I found interesting was that of username snipers. These servers had brands associated with them, such as the popular \"Hydra\" or \"Cupid\" sniping service. These services would go after the high-value usernames like \"adult\" with dozens of accounts and servers running proprietary software, and would then hold high-stakes auctions for names that they successfully obtained. Almost all snipes would go to these big players, since the more money they made the more they could reinvest in accounts and servers, and the more time they could afford to spend developing their snipers. Since Mojang technically doesn't allow you to sell accounts, the sales process, unless you were using an expensive middleman, heavily involved trust, and was always carried out with non-refundable cryptocurrency. It was clear to me that to be a popular sniper, you'd need to first build a reputation.\n\nSince I was interested in a more hobbyist take on sniping, I started out by searching for tools to get started tinkering with. As it turned out, there were already many open source public autoclaimers out there to mess with, such as the first one I tried [McSniperPy](https://github.com/MCsniperPY/MCsniperPY), a popular choice written in Python. It was preconfigured and easy to use, and was open source. To me it seemed like gold mining: just for fun, with a chance of extreme success. I also came across [the fascinating youtuber Xinabox](https://www.youtube.com/user/XinaboxGaming), along with a few others, who produce content specifically on the \"og minecraft community\" (a catch-all term for those interested in valuable accounts). At this point, I knew I wanted to get involved, but would need to further research the technicalities first. At that time, I was attempting snipes with a single account to claim names that interested me personally.\n\n## Getting started\n\nBut, I wasn't ready to settle for a popular open source sniper, and was sure I could do better. After weeks of learning about network requests for the first time, toying with async Python and multithreading, and exploring the actual endpoints of Mojang, I was beginning to get a better grasp of what I'd need to do. As it turned out, names release a few milliseconds early, so I'd need to extensively experiment. Each account was allotted only a few name-change-requests a minute, so I'd need many accounts. And, same-IP-requests led to processing gaps, so I'd need many servers. For every server I could only fit a few accounts, so there'd be an expensive recurring investment in compute time in addition to the actual account costs.\n\n## The partnership\n\n![Friend's skin art shop](https://static.404wolf.com/friend_name_mc_art.webp)\n\nOne of my first friends in the community, someone who went by \"wro\" (and I later came to know as Michael, and only years later got to meet in person!) had carved out a particularly interesting niche for himself selling NameMC skin art. NameMC skin art, potentially the subject of a future post, takes advantage of NameMC's skin history display to showcase art on your NameMC profile page. NameMC displays a grid of your 27 most recent Minecraft account's avatar's faces, so by designing pixel art and then converting it to many skin files, one can build up a grid to take the form of an pixel artpiece. My friend was offering to create the art and skin files as a service, which I found really cool.\n\n![Example skin art (by me)](https://static.404wolf.com/my_skin_art.webp)\n\nHe told me that he'd had some experience sniping usernames, and we began discussing some of his past experiences and successes. He said that in the past he'd sniped some lower tier accounts and made enough money to scale to around 9 accounts, and that it was around then that he struck success sniping the username \"vac,\" which was sold for a significant amount of money. He knew a lot about the pre-drop delay (an important username autoclaiming configuration option), and other configuration related matters. He was interested in getting back in the game, but wasn't quite ready to make such a large investment, and didn't know how to code well enough to code a sniper of his own.\n\n(On an unrelated note, I've coded a tool to apply any NameMc art of your choosing to your profile, which can be found [here](https://github.com/404Wolf/AutoSkin))\n\n### The offer\n\nThe problem was that, as it turns out, Minecraft accounts are really expensive. Used accounts can be acquired much cheaper, but they aren't popular in the sniping scene for a few reasons. For one, it's less secure to buy a used account from a sniper, since Mojang only recognizes the first owner as the true owner, and so without the codes found in the confirmation email from purchasing the game, there's no way to prove to Mojang 100% that it's you're account if anything were to go wrong and you were to get locked out of the account. Secondly, at the time when we were considering trying to snipe names, an approach called \"Giftcard Sniping\" was much more popular than trying to change the name of used accounts right at drop time. With \"Giftcard Sniping,\" you'd claim a Minecraft giftcard on a brand-new Microsoft account, and then close out of the tab on the \"choose your username\" page. It turned out that the \"set your username\" button on that page had a rate limit of 6 requests per minute, up from 3 from the \"change username\" button for older used accounts. In other words, by using brand-new prepaid Minecraft accounts and activating them with a specific username at droptime you'd have a better shot than changing the name on already existent accounts.\n\nTo get us started, I had the single account that I had bought from my own testing, and wro had an extra account of his own that the he also had used for tinkering. However, it didn't take long to realize that two accounts was nothing compared to what our competition had. Some other snipers were sniping with thousands of dollars worth of brand new accounts, and thus were automatically sending thousands of requests. Some weren't as ethical, and used myraid stolen accounts, and though I was strongly against the ethics of that, they were a threat to our business notwithtstanding. But where things took took an unexpected and exciting turn was when someone reached out offering wro a substantial discount on bulk Minecraft account giftcards. When buying in bulk, this anonymous figure offered us brand new accounts for only 5 a piece, down from 25. Wro wanted me to go half in with him on 20 accounts, and start a sniping organization of our own. With such a large number of accounts, we'd have a much higher chance of winning names, and so it seemed like a reasonable investment. And that's where it all began.\n\n# The beginning\n\n![First few sales](https://static.404wolf.com/first_few_sales.webp)\n\nI still reminisce of the first few days of set up: we created a Google spreadsheet to log transactions before we even had any, set up a discord server to garner customers, and spent a while deliberating on what to name our organization (we eventually decided to name ourselves \"Ember\"). We began by sniping lower 'tier' usernames, such as random 3 character long ones, using McSniperPy on a few [Vultr servers](https://www.vultr.com/). Through the process we were able to get a better grasp of the configurations of our sniper. For the first few weeks we spent all our money reinvesting in discounted accounts, building up our request capacity and slowly buying more and more servers.\n\nWe quickly realized, however, that while McSniperPy is great for first timers and people sniping with just a single account, it was unideal for larger sniping organizations. It was designed to work with only a few accounts, and we needed to set up each server one by one on manually with only 2-3 accounts per server. Most of the major competitors had custom, larger codebases, with tools to automatically queue snipes and more accurately send name change requests at the second of drop. To get us started, my friend was able to get a proprietary socket-request based Python sniper from an old friend in the community. As we continued expanding, I began forking it to allow for name queuing with a discord bot, using a simple Flask API to create threads of the sniper on the servers. But as we continued growing, even this quickly outgrew our needs.\n\n## Expansion\n\nWhile co-managing our auctions and facilitating transactions, I spent significant time making our systems more scalable and efficient. For the first few stages I improved the discord bot interface, and then proceeded to add more advanced features to attempt boost our odds. I made it so that we could set up a queue of many names, and have them automatically get 'sniped.' I added a channel in our main discord server that would announce successful snipes automatically, so that customers could start bidding right away, and that would automatically remove the account data from the list of accounts to snipe with when an account had its name changed. And, I added the ability to spread out the request offsets across our servers, so that we didn't have to bet on just a single droptime. Also, taking inspiration from many other snipers, we made it so that when our sniper were to succeed, it'd automatically swap the brand-new-account's skin to a skin with our logo. That way customers checking NameMC to see who got the name would know it was us when we won.\n\n## The gamechanger\n\nAfter a few weeks of obsessive coding and growing our operations, we were at the point where we were sniping many names a day with upwards of 15 VPSes running at all times, causing operational costs to spike to over 100 a month. We were still profitable, but it was a huge money suck. The more accounts we had, the more servers we'd need, the higher the price. But together, we worked up an ingenious solution. If the VPSes only required 10 minutes to authenticate all our accounts and send the name-change requests, then why'd we need to pay for 15 24/7 VPSes? Sure, you can better tune the servers and get a sense of their individual latencies, but was it really that big of a deal? Instead, we could just have one central server deploy (create) all the servers we need for all the accounts 10 minutes before droptime, and automatically 'ship' the accounts and settings to them. It was an extensive, elaborate undertaking, and I didn't have much of an idea as to where to get started, but it seemed to definitely be the best way forward. While our competitors were spending hundreds a month on server overhead, we could focus our spending on accounts and maximize our number of requests. The more requests, the higher the chance that a single one of them wins.\n\n# The system\n\n![Queueing many names](https://static.404wolf.com/queue_bulk_add.webp)\n\nAfter coming up with the plan, I got to work. I read up on [Vultr's REST API](https://www.vultr.com/api/), and created a script to automatically deploy servers. With [async ssh](https://asyncssh.readthedocs.io/en/latest/) I made it so that, as planned, one parent server would automatically spawn a 'sniping' child sever for every 2 accounts, and added a queueing system. We elected to make our interface Discord-based because of the ease of implementation, and because that was where we were holding our auctions. To put a name in the queue all we had to do was type `/queue \u003Cname` into Discord; it was super convenient. And, as can be seen to the right, I made it so that a simple slash command one could add many names to the queue at once, which would then get setup prior to drop. We'd spend times together scrolling through NameMC's monthly drop-list, pre-queuing all the names we thought we'd be able to turn a profit on.\n\n## Operations\n\n![Deploying VPSes](https://static.404wolf.com/setting_up1.webp)\n![VPS set up confirmations](https://static.404wolf.com/setting_up2.webp)\n![Set up confirmations](https://static.404wolf.com/setting_up3.webp)\n![Log of name-change requests](https://static.404wolf.com/requests.webp)\n\nAs time went on, I continued adding innovative and unique features to our sniper to increase our success odds and streamline operations. One of the next improvements I made was to send many requests evenly distributed within a specific interval small time interval, so that we'd not miss the often unpredictable droptime-window. More competitive names tended to generally take longer to release due to the sheer amount of requests other people sent, due to server lag. By spreading out requests, we'd be more likely to send the request right at the moment the name were to become free..\n\nThe finalized system was super efficient. It'd wait until 10 minutes before the last item on the queue was to drop, would automatically deploy a server for every few accounts where each server was staggered by a fraction of a second, and, after the servers were finished loading, via SFTP would ship the account login data to each server. The parent server would concurrently SSH in and run a setup Python script, along with syncing the clock and other setup. The child servers would ping mojang to attempt to change the username of the accounts that they were serving, and then would automatically destroy themselves (undeploy) to save on server costs.\n\nThe system was quite finiky at first, but improved with time. As I worked on it we had an inventory of 50-80 accounts, and so when anything went wrong we'd be left with 30-50 Vultr servers running concurrently and billing me .05/hr each. Even short intervals of time spent with servers left over from testing running added up to 100s of extra expenses, but the ultimate system saved us so much money that it quickly paid for itself. Not only did we save money on server hosting, but we also saved time that would otherwise need to be spent manually authing into and configuring servers.\n\n# Ending operations\n\n![Sniping explicitly not allowed](https://static.404wolf.com/inedNoSniping_0001.png)\n\nEventually, though, sniping became more challenging. Some snipers began taking things too seriously, and were actually DDOSing Mojang's servers. Mojang was forced to modify their systems so as to deter username sniping, and eventually Ined, one of the admins at Mojang, actually Tweeted to officially note that sniping is not allowed. They started out by cutting the rate limit for accounts, but that didn't stop the problem. They reworked the API a bit, and eventually our sniper broke, and offsets were completely different. Since the API for their systems is not technically supposed to be a public open API, it was completely reasonable for them to do what they wanted with their API, and using it to snipe names was inherently always at risk of an overhaul. Since we hadn't won snipes for a while and because with my senior year of high school approaching I had limited freetime, we decided that it'd be a good time to end the project. Given how large the community is, it wasn't that hard to find someone to buy all our unused Minecraft accounts that we were using to snipe with in bulk, and with that sale the project was over. For a while before the API changes we received various offers for large amounts of money to actually buy the software that I developed, which we never were able to end up selling once its lost its value. We were still lucky, though, since shortly after selling all our accounts Mojang finally began blocking all requests from datacenter IPs with Cloudflare, which made sniping completely impractical. Some people continued by using residential proxies, but to continue that way would be a major, major expense. Ultimately, the experience was definitely really fun, and decently profitable experience, but the project was more than anything extremely educational. It's how I initially learned Python to the extent that I know it now, and gave me experience with various web frameworks for the first time.","src/posts/MinecraftUsernameAutoclaiming.mdx","0e92d5894bc6c32e","obsidiancontactimporter",{"id":198,"data":200,"body":206,"filePath":207,"digest":208,"deferredRender":26},{"title":201,"type":15,"date":16,"covers":202,"tags":204,"description":205},"Obsidian Contact Importer",[203],"https://static.404wolf.com/Post-20240806180300351.webp",[35],"A project to bring phone contacts into Obsidian as markdown files, converting vCard (.vcf) files exported from phones or Google Contacts into nicely formatted notes. By storing contacts as markdown, users can take better notes about people they meet and maintain richer context around relationships, while keeping everything in their Obsidian vault. The tool uses customizable templates and handles contact details like names, phones, emails, addresses and even contact photos, making contact information easily searchable and editable within Obsidian's ecosystem.&#x20;\n","# Everything in One Place\n\n[Obsidian](https://obsidian.md) is a very cool markdown driven notetaking app. It's a very general purpose note taking app, and can do everything that every other note taking app can. It is also super extendable, which is really nice -- it is an electron desktop app, so plugins can be literally anything. There are plugins that add full on react UI components, and plugins that mess with webasm. Plugins are implemented by hooking onto type declarations that Obsidian provides, and it all is very well integrated into the app.\n\n![Markdown all the way down](https://static.404wolf.com/https://static.404wolf.com/Post-20240802183939700.webp)\n\nThe coolest part of Obsidian though, in my opinion, is the fact that all of your notes live as a hierarchy of [obsidian flavored markdown](https://help.obsidian.md/Editing+and+formatting/Obsidian+Flavored+Markdown) files (which is just a superset of markdown that adds things like highlighting, comments, and callouts). Obsidian itself is closed source, but I'm okay with using it anyway since my files are not obfuscated in any way.\n\nA lot of people have extended obsidian with its powerful plugin plugin system, to let you do more than just take notes. One philosophy that seems to be catching on is to use Obsidian as a life manager; as an all in one tool.\n\n## Plugin Ecosystem\n\nObsidian is [Electron](https://www.electronjs.org/), so it can do anything a browser can. It's implemented very well and you don't really notice this unless you try, but if you want to _create_ for Obsidian, the sky is the limit -- heck, [you can create plugins with React](https://docs.obsidian.md/Plugins/Getting+started/Use+React+in+your+plugin).\n\n![Obsidian full calendar](https://static.404wolf.com/Post-20240806165246984.webp)\n\nOne plugin I've started using is [Obsidian Full Calendar](https://github.com/obsidian-community/obsidian-full-calendar), which a cool calendar plugin for Obsidian that lets you unidirectionally sync iCal calendars, and then also manage events within Obsidian, where it can treat events as markdown files. That means that I can create an event within Obsidian, and it can create a corresponding event markdown file, that has the actual metadata for the event in it.\n\nThis is a paradigm that I really like -- treating usually structured and rigid data as semi-structured markdown.\n\nI have started to use templates to create other types of \"typically _structured_ dataforms\" in unstructured markdown. The nice thing about Obsidian is that this does **not** mean copying and pasting every single template. Templating in Obsidian is pretty mature at this point, it comes with a [built in templating plugin](https://help.obsidian.md/Plugins/Templates), and the community has created a much more powerful [Templator](https://github.com/SilentVoid13/Templater) plugin. You can plug in everything from the current note's file name, to the date, to arbitrary javascript function results.\n\n![Omnisearch](https://static.404wolf.com/Post-20240806170104437.webp)\n\nI think one of the coolest Obsidian plugins, that really does totally change the experience, is [Omnisearch](https://github.com/scambier/obsidian-omnisearch), which is a super powerful search engine for your entire note vault. It does weighted fuzzy finding across all vault contents, and it even OCRs images and PDFs. What that means is that the search results are always as relevant as possible -- if you search for a file, files with some of that name (it's fuzzy!) show up first, followed by notes with titles, and contents. This means that if all of my life is stored as markdown in my Obsidian vault, then it's easy to find things later.\n\n## The dilemma\n\nPart of this does mean that I'm restarting systems that I've had in place for a really long time. I really like Google Calendar, but I _prefer_ being able to put whatever I want into _semi structured_ markdown files for events. Part of switching to this new system means that my old calendar events are not going to be in my Obsidian vault.\n\nImporting old calendar events is good enough for now, because since the plugin supports linking iCal I still can view all my old events, I just don't have the ability to have corresponding markdown files. I probably could figure out how to import them that way with some scripting, but that's not really worth it for me since those events are in the past and I'm probably not still taking notes on them.\n\n![My options](https://static.404wolf.com/Post-20240806171003276.webp)\n\nOne area of my note-taking life that I would like to include in my Obsidian vault, though, is my contacts. All my contacts before this project were, as was the case for most people, stored in [Google Contacts](contacts.google.com), and on my phone in the Contacts app.\n\nWhat I wanted was a system to load my contacts into structured markdown files (ideally following some sort of template that I could fine tune and specify). Obsidian has a plugin registry built into the app, which you can contribute to by just PRing to a repo. It is pretty extensive, but there were really limited options that showed up. It's possible there's some project out there on Github, since Obsidian plugins get loaded by just plopping a manifest and js bundle into a specific spot, but I couldn't find any.\n\n## But also\n\nBut also, I want to get better at remembering people. I encounter a lot of people on a fairly regular basis, but I think I could do a better job of remembering what people do, interesting things I talk about with them, and that sort of thing.\n\nBy having all my contacts in raw markdown, I think it will both lower the barrier to someone being a \"contact,\" and will allow me to keep better records of how I know people and track my conversations with them over time.\n\n# The Project\n\n## Research\n\n![Google Contact export](https://static.404wolf.com/Post-20240806171751994.webp)\n\nIf I assume that all my contacts are in Google contacts (a bold proposition), then I can export them as a CSV and then use them that way. But that also means that anyone who uses my tool will also need to be using Google contacts. I guess I could have asked people to upload their contacts to Google so that they could then download them as a CSV, but that's clunky, so I decided to look into how they exist on the phone itself.\n\nI can't really know how Apple is storing them on the file system because of how closed source it is, but one thing I did figure out is that Apple let's you export your contacts in a uniquely unintuitive way: press and hold on a contact \"list\", or \"all contacts\", and choose to Export (or email every single contact in your phone! I will not be doing that, though.).\n\n![Export all contacts](https://static.404wolf.com/Post-20240806172024892.webp)\n![What?](https://static.404wolf.com/Post-20240806172020774.webp)\n![Where to?](https://static.404wolf.com/Post-20240806172014834.webp)\n\n### VCards\n\nIt turns out that the format that gets exported is the `vCard` format, which is the same format that gets used when you share contacts: if you text a friend your contact what you've sent them is a `vCard` file.\n\nvCards are kinda a pain. There's a proper [RFC](https://www.rfc-editor.org/rfc/rfc6350.html) on the spec. It's a 74 page PDF. [The vCard format was originally developed by Apple, AT\\&T, IBM, and Siemens.](https://www.loc.gov/preservation/digital/formats/fdd/fdd000616.shtml) as a new unified standard for contact storage, but it's very powerful.\n\nThe US library of congress has a section for the format, so I'll drop in their description and move on\n\n> Virtual Card Format (vCard) is a versatile data format designed for exchanging electronic representations of contact information. vCard is commonly referred to as an [\"electronic business card\"](https://www.nationalarchives.gov.uk/PRONOM/fmt/395) and is fully and openly standardized through IETF [RFC 6350](http://tools.ietf.org/html/rfc6350). The vCard file [contains](https://docs.fileformat.com/email/vcf/) the same type of content typically found on a physical business card, such as a contact’s name, address, phone number and email but may also list more personal data such as birthday or even organizational data such as line of supervision. Being digital, vCards can contain graphics (including headshots or ID photos), video, and audio as well as textual data. These files are shared across a wide variety of communication channels including email, instant messaging, text messaging, and website embedding. A single vCard file can contain information for one or more contacts. These digital cards are versatile, extending beyond personal descriptions to potentially represent various directory objects, including organizations, departments, or even buildings. However, the [predominant use](https://www.oreilly.com/library/view/programming-internet-email/9780596802585/) remains the representation of individuals.\n\nThat's right, you can store arbitrary data in vCards! Pretty cool.\n\n## Parsing VCards\n\nSo, vCards are plain text that store contact information. Great, that means we can look at them (and diff them, and all the other fun things that plain text let's us do)...\n\nHere's my vCard\n\n```vcard\nBEGIN:VCARD\nVERSION:3.0\nPRODID:-//Apple Inc.//iPhone OS 17.5.1//EN\nN:Mermelstein;Wolf;;;\nFN:Wolf Mermelstein\nX-PHONETIC-FIRST-NAME:Wolf\nEMAIL;type=INTERNET;type=pref:wsm32@case.edu\nitem1.EMAIL;type=INTERNET:wolf.mermelstein@case.edu\nitem1.X-ABLabel:University Alt\nitem2.EMAIL;type=INTERNET:wsm32@cwru.edu\nitem2.X-ABLabel:University\nEMAIL;type=INTERNET:uptothebird@gmail.com\nitem3.X-ABLabel:Primary\nitem5.TEL;type=pref:(917) XXX-7875\nitem5.X-ABLabel:Backup\nTEL;type=CELL;type=VOICE:(929) XXX-7180\nNOTE:This is me.\nitem6.URL;type=pref:https://404wolf.com\nitem6.X-ABLabel:_$!\u003CHomePage>!$_\nBDAY:XXXX-REDACTED-08\nPHOTO;ENCODING=b;TYPE=JPEG:/9j/4AAQSkZJ....SIJ\nEND:VCARD\n```\n\nI got it by clicking \"share contact,\" and then I shared it via email with myself, and downloaded the email attachment.\n\nIt's pretty gnarly. I mean, it has all I need, but how do I actually yoink out the relevant pieces of information. Also notice that the image is just a regular base64 image -- that's pretty nice.\n\n![My options](https://static.404wolf.com/https://static.404wolf.com/Post-20240806173810683.webp)\n\nSo I looked into it a bit.\n\nIt turns out that there's not a ton of good options. I tried three different ones before arriving on [vcf](https://www.npmjs.com/package/vcf), and faced a few issues:\n\n- Wrong type of vCard. There's 4 different versions that aren't fully compatible.\n- Commonjs hell. I'm using [bun](https://bun.sh), which makes life so much easier, (you can import and require in the same file!), but I don't want to require. I want a pure esm solution.\n- Types. I want types. Typescript is a good thing.\n\n![VCF library](https://static.404wolf.com/https://static.404wolf.com/Post-20240806174857068.webp)\n\nSo, `vcf` isn't typed, but it does have type declarations, and works reasonably well. And, it turns out it's wicked fast with `bun`, which is really nice. I don't even have to bundle, just running it as a script is fast with `bun` (but we'll bundle later since I do need to package it with nix, since of course we do).\n\n```js\nvCard {\n  version: \"3.0\",\n  data: {\n    version: Property {\n      _field: \"version\",\n      _data: \"3.0\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    prodid: Property {\n      _field: \"prodid\",\n      _data: \"-//Apple Inc.//iPhone OS 17.5.1//EN\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    n: Property {\n      _field: \"n\",\n      _data: \"Mermelstein;Wolf;;;\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    fn: Property {\n      _field: \"fn\",\n      _data: \"Wolf Mermelstein\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    xPhoneticFirstName: Property {\n      _field: \"xPhoneticFirstName\",\n      _data: \"Wolf\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    email: [\n      [Object ...], [Object ...], [Object ...], [Object ...]\n    ],\n    xAbLabel: [\n      [Object ...], [Object ...], [Object ...], [Object ...], [Object ...]\n    ],\n    tel: [\n      [Object ...], [Object ...]\n    ],\n    note: Property {\n      _field: \"note\",\n      _data: \"This is me.\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    url: Property {\n      group: \"item6\",\n      type: \"pref\",\n      _field: \"url\",\n      _data: \"https://404wolf.com\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    bday: Property {\n      _field: \"bday\",\n      _data: \"XXXX-REDACTED-08\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n    photo: Property {\n      encoding: \"b\",\n      type: \"jpeg\",\n      _field: \"photo\",\n      _data: \"/9j/4An/1/...........S/+gpXY19Bc8RrU/9k=\",\n      is: [Function: is],\n      isEmpty: [Function: isEmpty],\n      clone: [Function: clone],\n      toString: [Function: toString],\n      valueOf: [Function: valueOf],\n      toJSON: [Function: toJSON],\n    },\n  },\n  get: [Function: get],\n  set: [Function: set],\n  add: [Function: add],\n  setProperty: [Function: setProperty],\n  addProperty: [Function: addProperty],\n  parse: [Function: parse],\n  toString: [Function: toString],\n  toJCard: [Function: toJCard],\n  toJSON: [Function: toJSON],\n}\n```\n\nSo we have what we need, and we can interface with it with `typescript` now. It seems everything that we need is there, but it's just a pain in the neck to extract anything.\n\n_some hours later_\n\nI decided to move on anyway, and write a wrapper that uses `vcf` to extract the necessary pieces of information from the `vCard` to craft a `Contact` object.\n\n```json\n{\n  \"name\": {\n    \"first\": \"Wolf\",\n    \"last\": \"Mermelstein\",\n    \"pronunciation\": \"Wolf\"\n  },\n  \"organization\": \"\",\n  \"title\": \"\",\n  \"phones\": [\n    {\n      \"number\": \"(917) XXX-7875\",\n      \"type\": \"Backup\"\n    },\n    {\n      \"number\": \"(929) XXX-7180\",\n      \"type\": \"Misc\"\n    }\n  ],\n  \"emails\": [\n    {\n      \"address\": \"wsm32@case.edu\",\n      \"type\": \"Misc\"\n    },\n    {\n      \"address\": \"wolf.mermelstein@case.edu\",\n      \"type\": \"University Alt\"\n    },\n    {\n      \"address\": \"wsm32@cwru.edu\",\n      \"type\": \"University\"\n    },\n    {\n      \"address\": \"uptothebird@gmail.com\",\n      \"type\": \"Misc\"\n    }\n  ],\n  \"addresses\": [],\n  \"websites\": [\n    {\n      \"url\": \"https://404wolf.com\",\n      \"label\": \"HomePage\"\n    }\n  ],\n  \"birthday\": \"undefined 8, XXXX\",\n  \"notes\": \"This is me.\",\n  \"image\": {\n    \"data\": \"/9j/4AAQSkrwZ/x..........XY19Bc8RrU/9k=\",\n    \"type\": \"jpeg\"\n  }\n}\n```\n\nMuch, much better.\n\nMost of the pain was in dealing with how Apple hacks about the `vCard` spec: for many of the elements in the parsed response I got, I would find that things like phone numbers would be labeled with tags like `label1`, `label2`, and `label3`, corresponding to `personal`, `home`, etc, where the mapping would exist elsewhere in the `vCard`, but not in one consistent spot.\n\nTo solve this, I just created a global hashmap for each `vCard` that had all of the label references and their corresponding proper labels...\n\n```typescript\nconst rawLabels = this.getPropertyJSONs(\"xAbLabel\");\nlet labelMap = [];\nif (rawLabels !== null) {\n  labelMap = Object.fromEntries(\n    rawLabels.map((label: any) => [\n      (label[1] as any).group,\n      sanitizeVCardLabel(label[3]).trim(),\n    ]),\n  );\n}\nconst getLabel = (label: string) => {\n  if (label in labelMap) return labelMap[label];\n  else return labelFallback;\n};\n```\n\nNow that I have a function that can take a contact and give me a pretty JSON, I'm just about ready to start generating markdown.\n\nFor this, I have a few options, but it was a tricky decision.\n\n## Creating Markdown\n\n![The template](https://static.404wolf.com/https://static.404wolf.com/Post-20240806180300351.webp)\n\nOne cool idea I had pretty early on for this project was the ability for the process to be bidirectional. That is, I thought it'd be pretty neat if you could take vCard contacts and turn them into markdown, and then eventually go the other direction: take the markdown you generated, and maybe some hand written contacts that follow the schema, and create vCards that you can load back into your phone.\n\nAlso, it would be important to parse the generated markdown later on just so that I could change the template if I ever wanted to. I love configuring things, and I think it's pretty likely that I would want to make some changes to the template down the line, like moving different sections of the contacts to different spots in the template.\n\nNo matter what I did, I'd probably be using [remark](https://unifiedjs.com/explore/package/remark/) to parse the markdown, which is a plugin for the `unified` AST ecosystem. It lets you create a traversable AST from a plaintext markdown file. I was thinking it might be fun in the future to create my own vCard parser using `unified` in pure `typescript`.\n\nThis was a really tough decision, I was brainstorming and devised a few different options that would be potentially bidirectional\n\nIt turns out that markdown allows you to inject something called \"frontmatter\", which is basically a yaml, at the top of your markdown file, surrounded by `---` on either side. That is, something like\n\n```\n---\nfoo: \"bar\"\ntags: foo, bar, buzz\n---\n```\n\n![Blog post metadata in frontmatter](https://static.404wolf.com/https://static.404wolf.com/Post-20240806180922110.webp)\n\nThis is something I do for the Obsidian plugin for my website; I embed metadata about the blog posts at the top of the blog post files.\n\nOne idea then, using this, would be to pick a template and stick to it, and write a parser that can parse it into a specific format. Then I could add something like \"parser-top-use\" (in more practicality, probably something like \"version\" or \"parserid\"), and then dynamically parse notes based on the schema that they are using.\n\nThis is a pretty high effort idea, so another idea I was flirting with was rendering markdown based on the frontmatter. I found a very straightforward Obsidian plugin that does this called [\"Obsidian handlebars\"](https://github.com/sbquinlan/obsidian-handlebars). [Handlebars](https://handlebarsjs.com/) is a javascript library that lets you compile and then use templates for text files. It's a templating language and is pretty good at what it does.\n\nThe plugin's example is something very similar to what I want to do...\n\n```markdown\n---\ntags:\n  - cool\n  - awesome\n---\n\n\\`\\`\\`handlebars\ntags: {{#each frontmatter.tags}}{{.}}, {{/each}}\n\\`\\`\\`\n```\n\nUnfortunately, however, it's one directional.\n\nI found an Obsidian plugin called [\"Obsidian meta bind\"](https://github.com/mProjectsCode/obsidian-meta-bind-plugin) that does something like this in a bidirectional way.\n\n![Obsidain meta bind](https://static.404wolf.com/https://static.404wolf.com/Post-20240806181431211.webp)\n\nYou can create \"inputs\" in the markdown template, and then when you edit them they automatically update the frontmatter, and then when the user edits the inputs OR the frontmatter it automatically updates the note/frontmatter.\n\nIt works pretty good, but it's fairly janky and requires a lot of boilerplate that I rather not deal with. It also seems a bit fragile, since it is assuming that their inputs work properly long term and don't have any weird plugin interactions.\n\nAnother idea that I had was to very simply just create a vCard viewer/editor for Obsidian. I've wanted to learn [Svelt](https://svelte.dev/) for a while, so I might still do this eventually, but for now, I decided on a simpler solution.\n\n## Obsidian Tables\n\nObsidian tables are pretty good for storing tabulated data, and they are very human readable. It's an accessible format, and remark/unified should be able to parse it easily.\n\n```markdown\n| This is a header | This is another header |\n| ---------------- | ---------------------- |\n| This is a value  | This is another value  |\n```\n\nI decided to go with storing the contact data in tables for now, since it'll be easy to parse them later on. To figure out which sections are which, for now I'll just have headings above the tables that say what is in them, that I can regex against when parsing. It is a bit restrictive to require that people structure their contact templates with markdown tables, but it's better than zero flexability, and it will let me figure out a better solution later on.\n\nThe example template that I came up with, which is very table driven to store the key-value pairs, is this.\n\n```markdown\n---\nobsidian-contact-importer-schema-version: \"1.0\"\ntags: [\"person\"]\n---\n\nImported with [Obsidian Markdown Importer](https://github.com/404Wolf/obsidian-contact-importer)\n\n---\n\n{{#if organization}}\n{{#if title}}\n{{title}} @ {{organization}}\n{{else}}\n{{organization}}\n{{/if}}\n{{else}}\n{{#if title}}\n{{title}}\n{{/if}}\n{{/if}}\n{{#if image}}\n![Image]({{image}})\n\n{{/if}}\n\n## Phones\n\n| Type | Number |\n| :--- | :----- |\n\n{{#each phones}}\n| {{type}} | `c!{{number}}`|\n{{/each}}\n\n## Emails\n\n| Type | Address |\n| :--- | :------ |\n\n{{#each emails}}\n| {{type}} | `c!{{address}}` |\n{{/each}}\n\n## Socials\n\n| Type | Handle |\n| :--- | :----- |\n\n## Links\n\n| Type | URL |\n| :--- | :-- |\n\n{{#each websites}}\n| {{label}} | `g!{{url}}` |\n{{/each}}\n\n## Addresses\n\n| Type | Street | City, State | Zip, Country |\n| :--- | :----- | :---------- | :----------- |\n\n{{#each addresses}}\n| {{type}} | {{street}} | {{city}}, {{state}} | {{zip}} {{country}} |\n{{/each}}\n\n## Other\n\n| Type | Value |\n| :--- | :---- |\n\n{{#if birthday}}\n| Birthday | `g!{{birthday}}` |\n{{/if}}\n| Imported | {{imported.month}} {{imported.day}}, {{imported.year}} |\n\n---\n\n{{notes}}\n```\n\nNotice that I'm using handlebars to finally slot the json values into the template. To make this future proof and allow people to modify it to their liking, instead of remapping all of the handlebar fields in the templator function, I'm just dynamically dumping the JSON into the handlebar...\n\n```typescript\nexport default async function templateMarkdown(\n  contact: ContactType,\n  markdownTemplate: string,\n) {\n  const template = handlebars.compile(markdownTemplate);\n  const now = new Date();\n  return template({\n    ...contact, // Dump the entire contact json as-is\n    image:\n      contact.image === null\n        ? null\n        : `${(await getB64Hash(contact.image.data)).slice(0, 16)}.${contact.image.type}`,\n    imported: {\n      month: getFullMonthName(new Date()),\n      day: now.getDate(),\n      year: now.getFullYear(),\n    },\n  });\n}\n```\n\nAnd it works! So now let's package it and call it a day.\n\n## Bun + Nix\n\nI'm not going to go too deep into Nix here, but the TLDR is that it's a programming langauge and utility library that makes it very easy to create extremely pure and consistent, builds of arbitrary files, including executable.\n\nThe catch with `nix` is that it doesn't just try to be pure, it **forces** purity. Purity is, in this context, that whenever you run a build, the output artifact will be bit for bit identical given the same inputs. This makes it annoying to package things some times, since the `sandbox` that `nix` builds happen in is very restrictive -- it doesn't have internet!\n\nThere's a bunch of utility builder functions that are able to prefetch all your dependencies. A common one is `buildNpmPackage`, which is _de facto_ standard for `nixpkgs` packages (packages on the official registry) that are in `ts/js`. I'm using `bun` though, not `npm` or `node`.\n\nPrefetching artifacts for builds is done by specifying the hash of the thing you're fetching, so that you can guarantee that the things you're fetching are what you think they are. This isn't that bad when you have a `package-lock.json` with `npm` or even with `yarn`. In that case all of the hashes already live there, and can be used to safely do the fetches.\n\nBut, in this case, I want to use `nix` to package a `bun` app. `bun` presents a few challenges; namely, it uses a [special binary lock file format](https://bun.sh/docs/install/lockfile) that's super fast and efficient, but isn't easily parseable. You can use `bun` to read it as a `yarn` lock file, and theoretically you could go down that route to do prefetching of deps, but I decided on a much easier approach: `fixed-point-derivations.`\n\n[Fixed point derivations](https://bmcgee.ie/posts/2023/02/nix-what-are-fixed-output-derivations-and-why-use-them/) are when you ALLOW internet access in the sandbox during the build. This sounds scary, and like a bad idea. It kinda is. The catch is that you specify the hash of the output before doing the build. If the build, using the internet during the build, results in an output with the same hash that you pre-specified, then the build succeeds an it's fine, but otherwise the build fails and you get nothing. In the case of `bun` though, this isn't that bad, since `bun` is very good at getting very consistent dependencies using its lock file. So it's probably good enough for now.\n\nHere's what it looks like in action, as a DIY nix builder utility function...\n\n```nix\n{\n  pkgs,\n  src,\n  name,\n  bun ? pkgs.bun,\n  buildCommand ? \"build\",\n  outputHash,\n  outputHashAlgo ? \"sha256\",\n  outputHashMode ? \"recursive\",\n  ...\n}:\npkgs.stdenv.mkDerivation {\n  inherit\n    name\n    src\n    outputHash\n    outputHashMode\n    outputHashAlgo\n    ;\n  buildInputs = [ bun ];\n  buildPhase = # bash\n    ''\n      bun install\n      bun run ${buildCommand}\n    '';\n  installPhase = # bash\n    ''\n      mkdir -p $out/bin;\n      cp -r ./dist/* $out/bin;\n    '';\n}\n```\n\nBasically, do the `bun install` in the sandbox, do the bundling in the sandbox, and then move the output to an output folder. To make it executable, I just wrap it in a shell script...\n\n```nix\ndefault = pkgs.writeShellScriptBin \"obsidian-contact-importer\" ''\n    ${pkgs.bun}/bin/bun run ${bun-utils.lib.${system}.buildBunPackage {\n      src = ./.;\n      name = \"obsidian-contact-importer\";\n      outputHash = \"sha256-H9hWffy5QUN/n9tgaOO51k92XPJyLQ/bneFRgseCiX0=\";\n    }}/bin/index.js\n'';\n```\n\nWhich just runs bun on the output file. Javascript isn't \"compiled\", so this is the best we're going to get. What this does do though is create a nice bundle, and makes the build nicely portable. It also means that anyone with nix can instantly run the project with a single CLI command (see the next section)!\n\n# Using it Yourself\n\nClone [this](https://github.com/404wolf/obsidian-contact-importer) repo, or create a `inputs` folder with a `vcards.vcf` and `template.md` file (see example template if you're creating your own).\n\nRun `nix run github:404wolf/obsidian-contact-importer` if you have `nix`. If not, make sure that `bun` is installed, and then run `bun install`. Export your contacts to a `.vcf` format, and then just run `bun run dev`.\n\n# @ing People\n\nAnother super cool Obsidian plugin, so cool that it's even baked into the program, is \"[Daily Notes](https://help.obsidian.md/Plugins/Daily+notes)\". Daily notes are exactly what they sound like -- Obsidian automatically creates a new note every day that you can dump information into, and by virtue of the structure they get sorted by date. I find it really useful for very quickly jotting things down, and since they're in my vault they're nicely searchable.\n\nA big inspiration for the project is making it easier to take notes on people, so the ability to make people reference-able in my vault with a single hotkey would rapidly reduce the friction needed to begin taking notes on a person. Since I'm used to pinging people on apps like Slack, Zulip, Discord, etc, I thought it'd be handy if I could just @ my contacts in my vault.\n\nEnter [@ symbol linking.](\u003C@ Symbol Linking](https://github.com/Ebonsignori/obsidian-at-symbol-linking)>).\n\n## Fixing [@ Symbol Linking](https://github.com/Ebonsignori/obsidian-at-symbol-linking)\n\nAn important part of Obsidian is the ability to easily link together your notes. Obsidian lets you reference any note in your vault by using `[[Note Title]]`, and it creates a clickable link. You can add a ! to cause the reference to actually show its contents in the current note.\n\n![Notes prefixed with @](https://static.404wolf.com/https://static.404wolf.com/Post-20240806234120398.webp)\n\n@ Symbol linking wasn't actually the first plugin I found for this purpose, though. I started off using [Obsidian at people](https://github.com/saibotsivad/obsidian-at-people), which claims to do literally exactly what I want. Unfortunately, even though there's a setting for it, all of the people notes you create with it end up in the top level directory of your Obsidian vault, when I want them to end up in a `/People` folder.\n\n@ Symbol linking is a pretty straightforward plugin that does the same thing. It's a bit more generalized -- you can use other symbols as prefixes besides @, and you can customize a few more options.\n\nOne thing that I did like that `Obsidian at people` did was prefixing all of my people notes with \"@\", though, which makes it really clear which notes are \"People\" notes. This was a feature lacking in @ Symbol linking so I[decided to implement it myself and PR the change](https://github.com/Ebonsignori/obsidian-at-symbol-linking/pull/34).\n\n![Example from github 1](https://static.404wolf.com/https://static.404wolf.com/Post-20240806233519583.webp)\n![What it becomes](https://static.404wolf.com/https://static.404wolf.com/Post-20240806233455698.webp)\n\n![Setting I added](https://static.404wolf.com/https://static.404wolf.com/Post-20240806233809359.webp)\n\nTheir plugin was written pretty well, though more comments and docs would've been nice. It mostly boiled down to adding\n\n```typescript\nif (settings.keepTriggerSymbol)\n  filePath = value.obj?.filePath.replace(\n    /([^/]+)$/,\n    `${settings.triggerSymbol}$1`,\n  );\nelse filePath = value.obj?.filePath;\n```\n\nAnd the relevant setting. To polish things off, I also updated the \"Create new note\" suggestion to suggest the name with the @ symbol if the setting was enabled.\n\n# Making it Look Pretty\n\n![Inline admonitions](https://static.404wolf.com/https://static.404wolf.com/Post-20240802211800749.webp)\n![Adding one](https://static.404wolf.com/https://static.404wolf.com/Post-20240802211839755.webp)\n\nTo make the templates look nicer, I decided to use a plugin I already was using in my vault for my contacts too. [Obsidian inline admonitions](https://github.com/scottTomaszewski/obsidian-inline-admonitions) lets you change the way that your inline code (\\` \\\u003Cthis type of thing> \\`) renders so that it can have a nice color and even be slightly translucent. I decided to change the template slightly to incorporate these.\n\n# Next Steps\n\n## Big things\n\n- Bidirectionality! I want to be able to take my note files that contain VCard data and then bring the markdown back into VCard format.\n\n## Smaller things\n\n- VCards are a massive spec. I don't implement nearly close to all of the possible things that they could. I want to implement some more things though, like pronouns and nicknames.\n- That is tested with Apple contacts so far. I want to test to see if this works with Google/other flavors of contacts too.","src/posts/ObsidianContactImporter.mdx","237d407e5ae3f14f","predeterminedtextwidths",{"id":209,"data":211,"body":217,"filePath":218,"digest":219,"deferredRender":26},{"title":212,"type":9,"date":16,"covers":213,"tags":215,"description":216},"Predetermined Text Widths",[214],"https://static.404wolf.com/Screenshot_from_2024-03-24_01-44-59_0001.png",[35],"A neat hack that I figured out to get the titles on my website to render in a very specific way. Many titles on my homepage fill in automatically with a typewriter animation. Instead of the titles rendering where their darker background grows wider as the typewriter types, which was the default since I was using fitting width, I found a hack to get the widths to be correct to the size that the text would end up being on the initial load.\n","# Predetermined Title Background Widths\n\n### The issue\n\nOn the main page of [404wolf.com](https://404wolf.com) I have it set up so that various elements' text 'types' into their respective boxes. It's a neat animation that I achieve using the `typewriter-effect` package [that can be found here](https://www.npmjs.com/package/typewriter-effect). It works great out of the box, but since I have unique title styles that I wanted to keep consistent, I ran into a problem.\n\nFor titles on my website that are type-written after loading, I wanted the backgrounds to already exist, and then for the typewriter to type into them. Without any special configuration, the boxes load without a background, and as the typewriter types the boxes expand (since they use fitting width).\n\nTo solve this issue, I originally tried to compute the width by using a basic `document.createElement` method that I wrote (with some GPT help--I didn't know about `.offsetWidth` before this!).\n\n```ts\nfunction getDummyAreaWidth(\n  styles: string,\n  classes: string,\n  type: string,\n  text: string,\n) {\n  const dummyArea = document.createElement(type);\n  dummyArea.textContent = text;\n  dummyArea.setAttribute(\"style\", styles);\n  dummyArea.className = classes;\n  document.body.appendChild(dummyArea);\n  const width = dummyArea.offsetWidth;\n  document.body.removeChild(dummyArea);\n  return width;\n}\n```\n\nBasically, we create an element, set the styles and classes that would cause the width to change, and then yoink it's width. The idea is that I'd then use this function for the title components to give them fixed predetermined widths. However, since `typewriter-effect` uses some wrapper classes and I'm using `tailwind`, it wasn't computing the widths properly. I might have been able to troubleshoot and fix it, but instead I opted for a simpler solution.\n\n## The solution\n\nInstead of using a computed width value, I figured out that it'd be easier to just have the width be computed as if the text were actually there from the start. I realized that if the text were loaded initially without a typewriter, that the width would (expectedly) be correct. So, what I decided to do was make it so that the text did preload into the box, but the text itself was transparent. This would cause the box to fill properly as if there were complex-ly styled variable-width text in it, but appear to be empty while the typewriter were to type into the box. I then made the typewriter text absolute, so that it could type on top of the invisible text that was already in the box.\n\nThe actual code for my homepage's main header was super simple to update with this idea, and worked right away!\n\n```ts\nimport Typewriter from \"typewriter-effect\";\n\nconst Greeter = () => {\n    return (\n        \u003Cdiv className=\"relative\">\n            \u003Cspan className=\"text-transparent\"> {\"Hi! I'm Wolf Mermelstein\"} \u003C/span>\n            \u003Cspan className=\"absolute left-0\" style={{ whiteSpace: \"nowrap\" }}>\n                \u003CTypewriter\n                    onInit={(typewriter) => {\n                        typewriter\n                            .typeString(\"Hi! \")\n                            .pauseFor(700)\n                            .typeString(\"I'm Wolf Mermelstein\")\n                            .start();\n                    }}\n                    options={{ delay: 70, cursor: \"\", autoStart: true }}\n                />\n            \u003C/span>\n        \u003C/div>\n    );\n};\n\nexport default Greeter;\n```","src/posts/PredeterminedTextWidths.mdx","b4b63333638e1401","recursecheckins",{"id":220,"data":222,"body":228,"filePath":229,"digest":230,"deferredRender":26},{"title":223,"type":9,"date":16,"covers":224,"tags":226,"description":227},"Recurse Checkins",[225],"https://static.404wolf.com/recurselogo_0001.png",[35],"My occasional/semi-regular checkins that I wrote to account my time at Recurse Center. The point of checkins are to keep track of what I work on, who I work with, and the social events I go to. These are short but down to the point summaries of what I've done.\n","# Recurse Center Checkins\n\nMy occasional/semi-regular checkins that I wrote to account my time at Recurse Center. The point of checkins are to keep track of what I work on, who I work with, and the social events I go to. These are short but down to the point summaries of what I've done.\n\n# 2024-08-02\n\n[Browser Phone Presentation Link](https://docs.google.com/presentation/d/1jPXBGIdtQc4fyMpHVtzyIo22vKR0f-WfJqxYa3EWqZw/edit?usp=sharing)\n\nWhat I've done\n\n- Browser Phone Stuff:\n  - So much progress! See the slides for more.\n  - Paired with \\[\\[@Sam Woldy]] on handling Janus Gateway h264 encoding -- we figured out how to force Janus to send iFrames when you load the page by toggling `videobufferkf = true`.\n  - Wrapped it all in typescript with [bun](https://bun.sh) (as all things should be). Started using [fluent ffmpeg](https://www.npmjs.com/package/fluent-ffmpeg) which is a super cool ffmpeg wrapper for typescript. Also learned about [adb-ts](https://github.com/Maaaartin/adb-ts), which is something I was considering making for this project that I no longer have to. Wrapping it with typescript made it **more** robust. Who would've thought.\n  - It works! Kinda. I can now stream an android the the browser with very low latency, it loads almost instantly, and it _usually_ does not lag out over time. There's still a bunch of flags and settings I need to adjust though.\n  - [Presented on the progress!](https://docs.google.com/presentation/d/1jPXBGIdtQc4fyMpHVtzyIo22vKR0f-WfJqxYa3EWqZw/edit?usp=sharing) I aimed for 6 seconds per slide, 30 slides. I averaged about 8 :(. This means that I didn't get to see if anyone wants to help on the next part: figuring out how to write typescript C bindings to recreate `scrcpy`'s custom binary data packets for actually controlling the phone. I'll be writing my first lines of C next week hopefully, for the better or the worse. In the words of scrcpy, \"the documentation is the unit tests.\" Also thanks \\[\\[@Eric Hayes]] for helping me figure out a bit about c and c structs. C design patterns do seem a bit funky.\n  - Later I figured out how to modify media encoder options. Basically there are two ways I found from reading some java source:\n    - `video_codec_options=bitrate-mode=4,latency:float=0.5` basically just add the constant's names and their values using this funky syntax. It seems to do things. The [media codec options](https://developer.android.com/reference/android/media/MediaCodec) are all here, and you just need to find the string literal values associated with the constants.\n    - Edit the java code itself. I figured out enough Gradle to build scrcpy server. This is important because they decided to hard code some codec settings that I wanted to change :(\n  - Starting today to dockerize android emulators with nix. This may finally convince me to get a more powerful laptop, since it turns out baking docker images is slow. Or maybe just remote builds on AWS.\n- [Obsidian Contact Importer](https://github.com/404wolf/obsidian-contact-importer)\n  - I use [Obsidian](https://obsidian.md) for a lot, but one thing that I've wanted to use it for for a while but couldn't is contact management. I have a lot of contacts in my phone, and wanted to export them all to schema'd markdown so that I could load it into Obsidian. There were a few challenges, like vCards being a pain in the neck to deal with, or handling base64 images embedded in the vCards, but it works now! You give it a `vcards.vcf` file and a `template.md` and it uses handlebars to produce the output contacts.\n  - Began pairing with \\[\\[Anna Hope|@Anna Hope]] a few weeks ago, and then did a long pairing session with \\[\\[@Eric Hayes|@Eric Hayes]], and afterwards finally got it working for my needs.\n  - PR'd [Obsidian @ linking](https://github.com/Ebonsignori/obsidian-at-symbol-linking/pull/34) to make it so that my contacts get prefixed with a literal `@`\n  - This works well enough for my needs now so I will get back to making this bidirectional (markdown -> vcards) later.\n- [iClicker Store](https://iclickwolf.com)\n  - Some professors at my University require iClickers, which are physical polling devices, for classes. They are really expensive at the book store but I get them very cheap in bulk so that I can resell them. This week I shipped [iclickwolf.com](https://iclickwolf.com) to facilitate preorderes for next year. It was my first stripe integration and was a lot of fun to figure out. Stripe is so easy! My takeaway: the devex for tooling is better whan the people creating the devex are making money on you using it. I don't really like that takeaway though. Also, MUI is great.\n\n# 2024-07-09\n\nWhat I've done\n\n- Got my Obsidian plugin working! I can edit posts, fetch posts, and more! I can now do blogging in Obsidian and ship to my website.\n- More system configuration -- I set up more Hyprland keybinds to deal with multiple monitors.\n- Wrote [some screenshot related scripts](https://github.com/404Wolf/Screen-Capture). I'm almost done with a cool `gif` one where I can select a region of my screen, record a gif, have it copied to clipboard, and then paste it. Bash scripting with nix is so much fun! You have access to basically every binary ever. Maybe I'll give a talk about it.\n\nSocial stuff\n\n- Prospect park run with @**Seamus Edson (he) (S1'24)** and @**Seth Walker (he) (SP2'24)**. Was a really good pace!\n- Board game club! Thanks everyone who came -- there's so many people I won't be able to @ everyone. Looks like there's a lot of Summer-2 board game interest which is great.\n\nNon programming stuff (new bullet!)\n\n- Ordered [the hottest pepper seeds that you can order](https://www.rareseeds.com/pepper-hot-carolina-reaper) and will be doing [closet hydroponics](https://404wolf.com/posts/project/hydroponics) for ghost peppers and carolina reapers! Going to be a lot of fun.\n- Finished trolling a scammer who was offering a fake job that required I pay crypto to do it. Prepared funny slides for non programming talks.\n\nWhat I want to do\n\n- Finish up Obsidian plugin so I can look into the WebRTC stuff that forever seems to get pushed back.\n- Blog about nix, the obsidian plugin creating process, and a few other things.\n- Read Rust book a little -- I've fallen behind. I left my laptop home today, so I decided to instead of heading back and forth, do a virtual focused day at home; it was productive but I look forward to being at the hub again.\n\nIdeas\n\n- Scraping an airline website, making an API for the scraping, then having notifications for price drops. Predicting flight prices by logging huge amounts of data this way would be a fun intro to ML project.\n\n# 2024-07-08\n\nWhat I've done\n\n- Got my Obsidian extension to work for my website for PULLing content. I can download all my blogs and project posts now, and the images are linked properly. I had to do a little bit of remark/unified AST stuff to swap out photo IDs with their filenames, because of how file linking works in Obsidian. I will **probably** present on this because it's so cool!\n- Paired with @**Joseph Martinez (he) (S1'24)** on his medical charting platform. Was really fun to return to [Next.js](https://nextjs.org/), it's been so long! The bug was that he had an element that was trying to access an element directly off of `window`, and `next` and `react` have various rendering stages where `window` doesn't exist in the global scope. In this case, we were using a client side component, but the code was being \"loaded\" during pre-rendering (and maybe within the virtual DOM after mounting?), and couldn't access `window`. The error message was obtuse, I'm going to steal links from Joseph's checkin:[https://nextjs.org/docs/messages/prerender-error](https://nextjs.org/docs/messages/prerender-error \"https://nextjs.org/docs/messages/prerender-error\") & [https://nextjs.org/docs/pages/building-your-application/optimizing/lazy-loading#with-no-ssr](https://nextjs.org/docs/pages/building-your-application/optimizing/lazy-loading#with-no-ssr \"https://nextjs.org/docs/pages/building-your-application/optimizing/lazy-loading#with-no-ssr\")\n- Some more neovim config. I'm really happy with my current setup, it's really nice now. I definitely want to set up a dap (debugger) soon.\n- Did a hello world in rust! I want to start reading \"the book\" and playing around a bit. Hope to pair with @**Rylee Alanza Lyman (they) (S1'24)** to work on some advent of code problems in rust once I get a little bit more fluent.\n- Chatted with Peter (I didn't get a last name and there's so many peters!) about blender stuff. Maybe I'll return to it and play with the API.\n\nWhat I want to do\n\n- Still actually get started on webrtc stuff. I've been so distracted.\n- Starting blogging more. I end up getting too obsessed with the technical side of my blog than actually blogging!\n\n# 2024-07-05\n\nWhat I've done\n\n- I implemented [everything](https://404wolf.com/posts/project/everythingPy) in python! Basically, it's a library that dynamically generates the functions you import from it, so you can import literally anything from it.\n- Some work on an obsidian plugin to sync my website blogs. Paired with @**Thomas Georg Marwitz (he) (S2'24)** to work on this a bit, and got to toy around with debug tools for Obsidian a bit.\n- Chatted with @**Dennis Owrutsky (he) (S2'24)** about his ML project, and about first class objects / functions in Python. Turns out that my understanding of what it means for something to be first class was a bit off. Also lead into a tangent to learn about javascript [symbols](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol)\n\nSocial stuff\n\n- Talked to @**Russell Webb (he) (F1'23)** a bit about how he makes checkins less overwhelming, I might try his approach of reading specific checkins of people with overlapping interests instead of trying to get myself to read every single checkin everyone writes.\n- Went to @**Rylee Alanza Lyman (they) (S1'24)**'s 4th of July party! It was so much fun to hang out with everyone and meet some new people. So many illegal fireworks around the area!\n- [Running group!!!](https://recurse.zulipchat.com/#narrow/stream/18927-social-.28new-york.29/topic/prospect.20park.20running.20club) Ran today with @**Carsten Rodin (he) (S1'24)** and @**Elijah Reissman Kennedy (he) (S1'24)**. Was a good run around the park loop. We discussed the idea of making an IOT locker that locks to bike racks for your backpack when you run -- want to look into how to go about making this.\n\nWhat I want to do\n\n- Get started looking into how webrdp works, if there's rust backends for it, and maybe build a basic front end client for it\n- Clean up my android emulator code and look into generating nix to do android stuff, probably with rust\n\n# 2024-06-30\n\nLearned about [git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules)! Thanks @**Charles Eckman (he) (SP2'24)** for the tip. I have moved out my neovim config to [here](https://github.com/404Wolf/neovim) and now have it as a submodule in my nix configuration.\n\n# 2024-06-27\n\nLots has happened since my last checkin, so this one's going to be rather long. I'm going to try to get into the flow of bi-daily checkins going foward! .\n\nCode stuff:\n\n- Working on wrapping my neovim so that it knows where all my LSPs live. I don't want to use `nixnvim` to build my neovim config, since I want to be able to use the config anywhere. But I also don't want to pollute my path with LSPs. So, I basically just wrapped neovim with a shell script to automatically put LSPs in the path.\n- Paired with @**Charles Eckman (he) (SP2'24)**\n  - Getting a nix dev environment set up for tawaylon -- lots of `LD_LIRBARY_PATH` extension that feels very janky. I want to check \\[this out]\\( [https://github.com/NixOS/patchelf](https://github.com/NixOS/patchelf \"https://github.com/NixOS/patchelf\")) soon, which is an alternative that patches dynamic linked deps with static ones automatically.\n  - Learning a lot about dynamic and static dispatch functions, and a tour of rust. Thank you again, it was super helpful!\n- Mozilla approved [my extension](https://addons.mozilla.org/en-US/firefox/addon/browser-zoom/)! It's a tool to automatically skip past Zoom \"open in desktop app\" popups, taking you directly to browser zoom. Google rejected me twice now, so I need to update the chrome version based on their feedback and try again.\n- Went to [OS Discussion](https://www.recurse.com/calendar/34625) and talked about `dynamic linking` and `systemd` a bit. I was going to set up a `systemd` automount service, but got sidetracked and came in underprepared, so we talked about the dynamic linking I was doing with Charles, which turned out to be very OS-related anyway.\n- Paired with @**Joseph Martinez (he) (S1'24)** to work on mktute a bit more and add tests, but instead we learned about github workflows and set up jest, and I got to do a bit of janky bash scripting. Was a lot of fun!\n- Configured firefox with Nix to build my firefox configuration and extensions in a pure way.\n- Began working on a [Nixified minecraft network](https://github.com/404Wolf/Nixified-Minecraft-Network) to learn arion and nixpkgs docker (a way to build super minimal base docker images). Was able to get a really cool missile wars implementation working, and packaged it with nix and maven. Made a [PR](https://github.com/RedstoneFuture/missilewars/pull/134) and it looks like they aren't as big Nix fans as me. I want to also look into terraform more to automatically deploy it. The idea is that I'll use something like Bungeecord, a reverse proxy for minecraft servers, to manage a network of many nix packaged dockerized servers running different flavors and versions of the game.\n- Got a look at @**Divya \\_ (she) (S1'24)**'s new elixer raft setup. Exlier seems super cool. Also chatted about the possibility of having a group next half batch to watch an opencourseware on distributed systems, which would be super cool.\n- Wrote [Hyprland Dash to Dock](https://github.com/404Wolf/HyprDash.git), a tool to create hideable ephemeral windows with the Hyprland window manager. It's still buggy and implemented a bit jankily, and I kinda want to redo it in rust to learn some rust. Regardless I need to do some bug fixing.\n- Began trying to package [KRDP](https://github.com/KDE/krdp), but wasn't successful. I am going to return to this eventually and make a PR with a nix flake when I get it to work. It's a wayland native RDP client.\n- Learned about [Lotion](https://font.nina.coffee/) font from @**Benjamin Arnav (he/they) (SP2'24)** today, and want to try it out later.\n\nSocial stuff\n\n- ALGORAVE. There are so many people to @ so I'll just leave it at that. Thank you @**Paolo Holinski (he) (SP2'24)** for organizing and for everyone who helped! It was such a fun experience.\n- Sunday picnic! Again so many people to @. It was a great experience and was a ton of fun to hang out with everyone who went!\n- Saw space jam (organized by @**Peter Kang (he) (SP2'24)**). I don't think I've seen it fully before -- it was fun to watch with everyone.\n- Went to AITinkerer's [Prompt Engineering](https://nyc.aitinkerers.org/p/the-basis-ai-tinkerers-prompt-olympics) event with a few people. It was a lot of fun! It was a content to prompt \"low quality\" AI models to behave in specific complex ways.\n- Niceties and end of batch stuff! It's too bad that so many people won't be here the next 6 weeks. Unfortunately I had to go a little bit early since I had an important class (I'm taking a late night corporate finance course) I needed to attend.\n\nTodos\n\n- Fix my sleep schedule! My sleep/breakfast schedule is many hours in the wrong direction so I need to work on it. This checkin was sent wayy too late at night :((\n- Get back to running! @**Elijah Reissman Kennedy (he) (S1'24)** and I are going to put running on the calendar next week at least one day, TBD\n- Try out LARPing at [Empire's Grove](https://www.facebook.com/groups/435821493129108/). It's been many years and I'm excited to get back into it.\n- Read over everyone's #welcomes. I also need to read through a lot of checkins and get back in sync with Zulip in general.\n- I still want to form a git group. I will eventually get around to this! Probably will post something Monday.\n\nIdeas!\n\n- I want to knock off [appetize.io](https://appetize.io/product) but open source! I want to make an android emulator that can be used as a web component and runs android and eventually IOS in a serverless context. Basically, the idea is to use nix to get an android emulator to run (which is so easy!), and stream the emulator (probably with [looking glass](https://looking-glass.io/)). I want to have a server that can spawn lambdas with android emulators, and then returns `iframe`s that are phone emulators! And I want to learn rust in the process to build the backend. I don't really know where to start, so I want to research this tomorrow. This may be my next half batch project, maybe.\n\n# 2024-06-11\n\nA checkin! It's been a while, and a lot of things have happened. I'm going to get better at being consistent with this. This is a conglomeration of about a week worth of stuff I've done, so it's on the longer end.\n\nThings I've been working on...\n\n- Paired with @**Joseph Martinez (he) (S1'24)** recently to work on [mktute](https://github.com/josephrmartinez/mktute/), a super cool tutorial generating tool that uses GPT to make tutorials based on git diffs. I started working to refactor with `typescript`, but quickly ran into import/require nonsense, and want to spend some time tomorrow figuring out how to properly deal with having libraries that use both. For what it's worth, `esbuild` seems to have been able to deal with both at once, and I've read that `deno` and `bun` can also deal with it, so it might be a `node` thing.\n- Wrote a [chrome extension](https://github.com/404Wolf/Browser-Zoom) to skip past the stupid Zoom popups asking to open in desktop, and take you directly to the browser zoom website, when you open a Zoom link. I submitted it to the chrome extensions store, but it's pending review for now. Hopefully I can present on it at some point, since it was fun to implement and is genuinely useful.\n- Wrote a nix `flake` for my system with `nixosConfigurations` and `homeConfigurations` that are separate, as opposed to using home manager as a nix module. Here is an example flake that uses it [as a module](https://github.com/nix-community/home-manager/blob/master/templates/nixos/flake.nix) and here is one that uses it [as a flake](https://github.com/nix-community/home-manager/blob/master/templates/standalone/flake.nix) to see the difference.\n- Learned about [cookiecutter](https://cookiecutter.readthedocs.io/en/stable/) and wrote [these project templates](https://github.com/404Wolf/Project-Templates) for `python3`, `typescript`, and `java`. Cookiecutter is a super cool tool that lets you define a project template by actually setting up a project with a file hierarchy, but using `{{ cookiecutter.field }}` anywhere in the template project (including file names and within files!), along with full `jinja` templating code, to do more advanced templating. It lets you specify fields that you can have interactively prompted for when creating a project, and can even register hooks to run for project set up. I also added `nix` to all these cookiecutter templates I wrote -- learning and then using `buildMavenPackage` for `java`, `buildNpmPackage` for node/npm, and `poetry2nix` for python. It was annoying to learn the APIs for these but seems super powerful now that I know how to use them. i'm probably going to sign up to present on this for tool talk on Friday.\n- Cleaned up and improved [this Echo360 downloader utility](https://github.com/soraxas/echo360/) for my needs. Echo360 is the lecture recording platform my University uses, which does not come with any way to download lectures. Under the hood it's just s3, though (so I'll be leaving them with a pretty big egress bill, probably, lol). Lectures have 3-4 streams, where there's the audio for each stream, along with a stream for the slideshow itself, which is a video, and the video of the lectuerer. [My version](https://github.com/404Wolf/Echo360-Downloader) is a bit cleaner and more safely typed than the original, is much more minimal, and uses `ffpmeg` to automatically merge together the streams into nice side-by-side `mp4` videos.\n\nEvents --\n\n- Joined today's movie night! [Hacker 1995](https://www.imdb.com/title/tt0113243/). Weirdly it got quite low reviews, but I really enjoyed it. If only systems hacking were as fun as the movie!\n- Did a running event with @**Elijah Reissman Kennedy (he) (S1'24)** and @**Seamus Edson (he) (S1'24)**. Also learned about an HTML energy event that I might attend.\n- Signed up for [AI Tinkerers](https://nyc.aitinkerers.org/p/ai-tinkerers-june-meetup-at-betaworks) prompt engineering competition! Planning as part of helping @**Joseph Martinez (he) (S1'24)** with mktute also practicing with improving prompting to get better tutorials.\n- Did a board game night take 1! Was a ton of fun, did 7 Wonders, Tsuro, So Clover, and Coup. Was great to see so many people join, and to try @**Isaac Rhett (he) (S1'24)**'s spicy popcorn. I will also bring popcorn next time (but it will be a bit more generic)!\n- Joined @**Finn Boire (he) (S1'19)** and a few RCers and a friend to attend the [Twenty Sided Tavern](https://thetwentysidedtavern.com/), an interactive DND event where the audience gets to play along. It was a ton of fun.\n- Paired with a few people on learning a bit about how `git` works and more advanced usages. Got to hear from @**Jaseem Abid (he) (S1'24)** on how `git` objects work and sharding, which was super cool. I'm going to hopefully try to assemble a `git` group soon.\n\nImpossible day!\n\n- I worked with @**Divya (she) (S1'24)** and @**Jacob Zimmerman (he) (S1'24)** on implementing Raft in python for use on raspberry PIs. We were able to draw out a state transition diagram and table, which we're using for the implementation. The idea behind Raft is that we can have a cluster of many distributed nodes, and the network holds a state, so if any node goes down, the state can still be accessed. What's cool about Raft is that there's a source of truth, the \"leader\" of the cluster, which all nodes get their information from. If the leader node goes down, then there's a complicated election process to decide on a new leader, along with reconciliation to decide which data to consider the most recent.\n\nStuff I want to do:\n\n- Deploy an API for a mobile app I've been working on and learn how to do ssl with nginx (https). I would like to learn more nginx in general, and how to use it with docker too.\n- Learn how to do nix docker base images.\n- Write my own nix home manager module to learn how writing modules and `option`s work.\n- Catch up on reading other peoples' checkins.\n- Maybe start a DND campaign if there's interest, but I'll have to see about that.\n- Continue working with @**Divya (she) (S1'24)** on implementing raft in python\n- Set up an email signature (like, the thing that is appended to emails), that looks nice and professional. Maybe also learn how to use [mutt](https://www.mutt.org/) email client.\n\n# 2024-06-02\n\nIt's been a bit since my last checkin, and I want to try to keep more consistent going forward. Here's some things I've done...\n\n- Configured neovim with an LSP, completion with CoC and github copilot, added a file tree and status bar, and set up a bunch of keybinds. I'm starting to use it as my main IDE and I'm beginning to like it. I really just wish that it was more reproducable and nixified -- this may be the next step I take.\n- Figured out how to package things with Python! Paired with @**Omar Jatoi (he) (SP2'24)** to work on devshells and building with Python. I was going to go down a rabbit hole of janking `requirements.txt` to work for my needs by creating an ad-hoc venv for the build, but realized that this would be impure and require disabling the sandbox. I figured out that this previously was the solution, using [pypi2nix](https://github.com/nix-community/pypi2nix), but that's now abandoned in favor of what seems to be [poetry2nix](https://github.com/nix-community/poetry2nix). I got a [DalleCLI](https://github.com/404Wolf/DALLE-CLI) and [ChatGpt CLI](https://github.com/404Wolf/nixified-gpt-cli) working with `nix` `flakes`, both for `devshells` and building! Poetry is an alternative python dependency and package manager that uses venv behind the scenes, but provides a really nice UX that includes a lockfile and proper version. Poetry2nix is a tool that \"automagically\" (their word!) scans the poetry lockfile and builds using those exact packages. To get the GPT CLI to work, I also had to deal with including a different external binary requirement, which I was able to get working by exporting `LD_LIBRARY_PATH = \"${pkgs.stdenv.cc.cc.lib}/lib\";` (I had to find the export from nixpkgs from a forum post, but this makes sense). Now I have a terminal GPT and Dalle client!\n- Started attending the Tools Talk meetings. Also had dinner with @**Paolo Holinski (he) (SP2'24)** and got to talk about ungoogled software and alternatives, scooter hacking, and a few other things, after attending his amazing Nix presentation (wherein I learned about [nixeverywhere](https://github.com/nix-community/nixos-anywhere) and `kexec`). Very excited to learn about overlays this week, try out nix docker containers, and maybe even nix VMs.\n\nThe next steps for me now are:\n\n- Arrange a meeting to practice some git this week. Also maybe finish up the flexbox froggy pairing group I started last week, and do grid garden.\n- Start a board game group! I'm going to kick off a topic in current batches to gauge interest later today.\n- Do some leetcode and research internships. I'm a bit overdue and I really need to get started.\n- Continue work on a react native project that I'm working on for someone. This is a closed source project that I'm doing for someone, so I don't really want to spend my RC time coding the project, but I do want to set up metro with react native on Nix. I've given up on android emulation on Nix for now (and got a physical android).\n- Learn about [`direnv`](https://github.com/nix-community/nix-direnv).\n- Further configure `hyprland`.\n  - I want to learn about `special` (yes, that's the technical name) `workspace`s, which are basically just workspaces that live outside the usual scroll through workspaces and are \"scratchpad\" workspaces.\n  - I need to set up mouse keybinds to drag around floating windows, and polish my existing keybinds a bit.\n  - Finish up configuring `waybar` to look nicer and include workspaces. I'm also considering setting up a workspace matrix for hyprland, and am considering forking [workspacer](https://github.com/CarloCattano/workspacer), which is a neat Python utility that adds workspace previews.\n- Make a utility to download my school's lecture recordings as mp4s using ffpmeg and some puppeteer (probably).\n- Figure out why copying and pasting to system clipboard aren't working with neovim.\n- Read everyone else's checkins!\n\n# 2024-05-22\n\nFirst day at the hub since last summer (okay, I did peep in during spring break to grab some board games I had left)! It's great to be back, to have espresso machine access again, and to be able to socialize with recursers in person. Tomorrow I will strategically **not** pack lunch so that I can hang out with other RC'rs to grab lunch! I will also try to locate an RC tshirt.\n\nI did a lot of meeting-and-greeting today, followed by pairing with @**Rylee Alanza Lyman (they) (S1'24)** to configure neovim (which we started, but ended up pausing because of how much trouble configuring it with raw lua with home manager was giving me with nix). I still have a long way to go, but it was still fun to see how configurable and powerful neovim-configuring is. I'll probably table this until my nix setup is ready.\n\nThen, I spent most of the rest of the day (and night) trying to get an Android emulator working on Nix for a React native app I've been working on. They say that `android-studio` should work and is already prepackaged, but I haven't been able to get it to work. It looks like android studio was having trouble locating \"libpng,\" and a friend told me about [NixLD](https://github.com/Mic92/nix-ld) to help binaries locate things when they look in places they aren't supposed to look (that's my understanding). I need to learn more about flakes and figure out how to hack my way into getting an android emulator to work. I think I'm going to need to read up on the [ELF](https://www.cs.cmu.edu/afs/cs/academic/class/15213-f00/docs/elf.pdf) file format.\n\n# 2024-05-21\n\nToday was a super long day, and I ended up doing a lot. Let's see...\n\n- Started this morning working with @**Charles Eckman (he) (SP2'24)** and a few other current-batch RC'rs who joined in on [Flexbox Froggy](https://flexboxfroggy.com/), a fun game-like website to help you learn the ins and outs of flex boxes. It was super interesting to discuss the implications of flexboxes in right-to-left languages. This included finally learning the differences between things like `space-between`, `space-around`, `space-evenly`, and more! Tomorrow I'm going to try to plan to finish the tutorials, and then move on to [Grid Garden](https://codepip.com/games/grid-garden/) (a similar game for grids).\n- Went to a formal methods/software foundations book club planning session. It seems really interesting, and I'm going to attempt a lesson/chapter this week and see if I'm interested.\n- From tinkering I learned that in Vim you need to use \\\\( and \\\\) for the parenthesis for capture groups in `sed`s and then \\\\\\\u003Cn> to access a specific captured element. Also, \\r for new lines to plop in instead of \\n, even though \\n is what you use to find newlines.\n- Hopped in a webdev group meeting. I had a ton of fun in a [NextJs](https://nextjs.org) group during my last batch, and would love to stay involved in webdev since it's still probably my primary interest. I love typescript!\n- Attended the pairing workshop. Last batch it was mastermind, but this time around it was the game of life. Ended up pairing with @**Jonah Vairon (he) (S1'24)** to work on a Python game of life implementation, which we then continued later on on. We learned about some [super super cool terminal escape character combinations](https://invisible-island.net/xterm/ctlseqs/ctlseqs.html#h2-Controls-beginning-with-ESC) to allow us to do things like moving around the cursor, delete lines, and overwrite lines in the terminal. [Here's the end result](https://github.com/404Wolf/game-of-life-animation) of what we worked on -- it is an animation **in the terminal itself** that updates in real time to display the game of life. We want to pair later this week to make a more general purpose library for terminal hackery and animations, and will probably give a Thursday presentation!\n- Helped a friend list a ton of Warhammer figurine kits on ebay. One sold right away within hours!\n- Had a coffee chat with @**Oliver Clive-Griffin (SP2'24)**. Learned about [UV](https://astral.sh/blog/uv) , which basically seems like a [pnpm](https://pnpm.io/) for Python. It seems super super powerful and useful, so I will absolutely be fiddling with it.\n\nAs for continued progress with configuring my Nix system...\n\n- I ported over my `VSCode` configurations to `home-manager`, but still need to set up my extensions. I want to move over to `vscodium` too (an open source de-microsoft-ed version of `VSCode`.\n- Setting up more keybinds for dealing with groups with hyprland. Groups are tabbed windows where you can have multiple windows nested within one window. I'm trying to replicate the shortcuts I'm used to with popos.\n- (related) Paired with @**John Isak Texas Falk (he) (W1'23)** to give a brief tour of `hyprland` and also to figure out how to yoink windows out of tabbed groups. Turns out the dispatcher for this was `moveoutofgroup`. Also turns out that there's no way to specify a direction to yoink it out by default. Will need to figure out a hacky solution. John also introduced me to `TTY`s (control + alt + f\\\u003Cn>) to get to specific shells on my computer. I need to play around with this more -- I wonder if I can run multiple instances of wayland at once.\n- Learned about \\[Sops]\\(- [https://github.com/Mic92/sops-nix](https://github.com/Mic92/sops-nix \"https://github.com/Mic92/sops-nix\")) and [Agenix](https://github.com/ryantm/agenix) for storing secrets in `Nix` configurations. Will set one of these up later this week or this weekend. If anyone wants to pair on this DM me!\n- Figured out that I can use `import` instead of `.imports` to import nix code directly instead of merging configs with the boilerplate of `home-manager.users.wolf.programs.x.y...`; I can just import specific pieces of `Nix` code. Will play with this more soon.\n\nNow, on my TODO-s:\n\n- Catch up on reading everyone's checkins\n- Finish up organizing a running group for pre-checking runs by the hub\n- Learn how `Nix Flakes` work so that I can get an unstable version of `hyprland` working for better configuration.\n- Fully configure `neovim` from scratch with `lua`. Would love to pair on this if anyone's interested!\n\n# 2024-05-20\n\nBad sleep deprivation caught up to me and I overslept a bit, but I got to join meet and greets and am really excited by the usual eclecticity (eclectic-ness?) of the batch! Judging from welcomes it seems like there's a lot of other people also interested in nix, and the other things I'm going to work on. I'm hoping to start a pre-checkin running group by the hub, and maybe even assemble a nix group shortly if there's people interested.\n\nOne of my goals this batch is to do daily checkins, every day, and then when the batch is done somehow put them on my website for reflection.\n\nToday I mostly continued to get my laptop to a slightly more usable state. I'm in the process of configuring my OS from scratch with hyprland and NixOS (so I don't even have a full DE!). It's been a ton of fun, but literally everything needs to be configured.\n\nToday, I made some next steps towards general usability...\n\n1. I got my audio keys working using `XF86Audio` keys from a [Reddit post](https://www.reddit.com/r/hyprland/comments/12p2yzv/comment/jglddmv/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) I found. I can even crank my volume above 100% this way!\n   Learning about [XF86](https://wiki.linuxquestions.org/wiki/XF86_keyboard_symbols) \"keyboard symbols\" was neat. Basically they are the non-fn-key-held actions for the top row keys, like the brightness-up key.\n\n```\nbinde =, XF86AudioRaiseVolume, exec, wpctl set-volume -l 1.4 @DEFAULT_AUDIO_SINK@ 5%+ # -l means limit, since we don't want to go above 140%\nbinde =, XF86AudioLowerVolume, exec, wpctl set-volume -l 1.4 @DEFAULT_AUDIO_SINK@ 5%-\nbind =, XF86AudioMute, exec, wpctl set-mute @DEFAULT_AUDIO_SINK@ toggle\n```\n\nIt took me 30 minutes to figure out that the command after `exec` CANNOT have quotes around it (it silently does not work)\n2\\) Learned about `wev`, a command line wayland keypress viewer that gives you information about the IDs of keys that get pressed.\n3\\) Figured out how to use hyprland `submaps`. Basically, I can have chords for keybinds, like SUPER + ENTER to enter a \"resize\" mode, where I can then use `hijk` to scale the active window, and then ESCAPE to leave the mode. It's super neat.\nI still have a lot of bugs to work out. Zulip desktop app doesn't launch, possibly because of an actual electron bug. Zulip terminal app does work, but I need to get used to it. Also, Zoom is super blurry, so I want to see if running a flatpak version will help. Once I finish getting my laptop to a more usable place I want to actually study the nix language more.\n\nOh, and one last thing: I have a Mac Mini that I'm going to set up a bluebubbles (imessage) server on this wee, at the hub. Basically, it will let me use imessage in the browser of a linux machine, and on android. If anyone's interested in pairing on that later this week at the hub (it involves hacky things to get around apple nonsense, like disabling disc protection), feel free to let me know!","src/posts/RecurseCheckins.mdx","f8fe4182ebb18f87","remarkablebackuputility",{"id":231,"data":233,"body":239,"filePath":240,"digest":241,"deferredRender":26},{"title":234,"type":15,"date":93,"covers":235,"tags":237,"description":238},"Remarkable Backup Utility",[236],"https://static.404wolf.com/remarkableExample_0001.png",[35],"A remarkable tablet is a digital paper replacement: an e-ink screen tablet with a stylus. To prevent dependency on the proprietary tools of Remarkable, I decided to develop a simple script to automatically recreate the directory structure of the tablet, including both the original .rm proprietary binary file format files, and rendered PDF files.\n","# The Remarkable\n\n![My remarkable](remarkableExample_0001.JPG)\n![Homescreen](https://static.404wolf.com/interface1_0001.png)\n![Notebook creation](https://static.404wolf.com/interface2_0001.png)\n![Notebook pages](https://static.404wolf.com/interface3_0001.png)\n\nRecently I got very into using a [remarkable](https://remarkable.com) tablet, which is an e-ink screen (no backlighting and monochromatic, like a kindle) tablet with a simple stylus. It's not the only tablet of its type, but it's unique in its simplicity: it runs Linux with a basic daemon that presents a QT program that is the entire user interface. Remarkables offer only the ability to take notes and annotate documents, and a basic folder organization feature. They have a cloud service that lets you sync your notes with your phone and computer, and back them up. I've been using it extensively over the course of my first semester at Case as an alternative for paper, and it's been great.\n\nOne problem I have with the tablet, however, is how proprietary their ecosystem is. On their website where they advertise their cloud service, they note that the cloud is a good way to back up the tablet. But, if you sign up, the terms and conditions state that\n\n```\nYou are responsible for backing up the content in Cloud Services, and reMarkable encourages you to do so in order to avoid loss of data. reMarkable shall under no circumstance be liable to you for loss of data.\n```\n\nThis seems a bit hypocritical, but for the convenience their cloud offers I still choose to use it. Usually their cloud costs $4/month or so (which is reasonable, since they use Google cloud as their backend and need to cover that cost), however, they offered free lifetime cloud subscriptions to all customers who bought the tablet up until 2021 or so. When I got my tablet, I made sure to find someone on eBay to buy an account from, so my account is a lifetime account and the subscription cost is not a factor.\n\nSo, since the cloud is not a good backup instrument, the issue is that they do not actually have any alternate good tool to back up the tablet. You can use the desktop app to download PDFs of your files, but this is a manual process. This project is making a tool to backup all files on the tablet, while preserving the original folder structure.\n\n# Notebooks\n\n![Notebook structure](https://static.404wolf.com/aNotebookStructure_0001.png)\n\nBefore I begin to discuss my tool, it's important to understand how notebooks work on the Remarkable. On the tablet, the file structure is actually just a blob. All the files are loosely stored in one directory and indexed. \"Folders\" are really just UUIDs in metadata json files. So, each notebook is in reality just a collection of a few specific files that loosely exist within the tablet's storage. However, Remarkable has a cloud service, and if you inspect the API of their cloud service they do containerize each notebook: they place them into tar files with the suffix \".rmn\" (\"dot remarkable notebook\"). You can extract the contents of a .rmn directly into the tablet, and it should register the notebook. These .rmn packages include a folder of files with .rm files, which are custom binary files containing actual page data, along with a bunch of metadata files like the last-page or notebook name and orientation.\n\nPreserving the actual notebook files as .rmn files is important because if the tablet were to ever get damaged and need replacing, and if anything happened to their cloud service, restoring from any other format, like PDFs, would mean loss of many notebook-specific features. You can annotate on top of PDFs, but they don't provide the same level of interactivity as an actual Remarkable .rmn notebook (for example, you can't move around marker marks, erase regions, etc).\n\nBut of course, exporting PDFs is important to me too, since one of the goals of this project is to be vendor-lockin-proof. I don't want a file in a format that requires proprietary closed source tools to make actually viewable or to convert, so rendering the notebooks to PDFs for purely archival purposes is also important. It would be unideal to no longer be able to edit my notebooks, but I still want to be able to review my class notes in the worst case. I wanted to create a simple recovery backup, and then also a second backup with PDFs.\n\n## Exporting\n\n![Web UI](https://static.404wolf.com/webUiAPI_0001.png)\n![Desktop App](https://static.404wolf.com/desktopApp_0001.png)\n\n![Mobile App](mobileApp_0001.PNG|float=left|width=20)\n\nSo, let's talk about how exporting works with the tablet natively. Exporting files is one of the weaker areas of the tablet. Right now, you can export notebooks through the desktop or mobile app as PDFs, email notebooks as PDFs, SVGs, or PNGs directly from the tablet, or, most interestingly, use the Web UI (a webserver that the tablet hosts over USB) to download files as PDFs using an internal PDF rendering script tablet-side. There is significant quality loss during this conversion process; only the original rmn files contain all the data.\n\nThough the desktop software provides a great user interface and the ability to convert to PDFs, it was a proprietary binary and I did not see a good way to automate it. So, instead, I'd take advantage of the tablet's internal renderer to process the rmns. The USB-Web interface is a basic webserver that you can access when the tablet is plugged in to your computer through a web browser. In addition, the tablet hosts a basic REST API that one can use to explore the contents and run rmn to PDF conversions.\n\nIt's unideal to have to render the notebooks on the tablet itself, since it (understandably) doesn't have a very powerful CPU, but since the tablet would be plugged in anyway to transfer the files, I was okay with the long processing time. My plan was to just run the backup overnight.\n\n### Access the Files\n\n![SSH Access](https://static.404wolf.com/sshAccess_0001.png)\n\nIt's a bit strange, but Remarkable (the company) does not want you to know that .rmn notebook files even exist. They don't have any documentation on them, don't discuss them anywhere on their website or apps, and try to abstract them away from you by forcing you into their proprietary cloud where the notebooks just appears as icons. In the web UI, these notebooks have a download button, but the download button just exports the notebook as a PDF. The rmn files are invisible.\n\nSo, then, how do we even know that rmn files exist? Remarkable uses some open source tools that use a specific open source license that requires them to provide you with access to the internal software as-is, they provide direct SSH access, where all the files within the tablet can easily be retrieved. Part of this project involved figuring out how to automate SSH with Python, which turned out to be fairly straightforward. I was able to use basic FTP to grab the rmns directly off the tablet, with access to root ssh.\n\n## The final product\n\nTo make my backup utility, I wrote a basic script to recursively scour the tablet using the API endpoint for viewing contents of a folder. I rebuilt the file structure of the tablet in a tar archive, storing both the rmn files and rendered PDFs. The final version is available on my [github](https://github.com/404Wolf/RemarkableBackup), and is functional.\n\n#### Future Plans\n\nNow that I have a working backup script, my future plans for this project are to make it so that I run the backup continiously from a dockerized server, which pulls my data from their cloud service's API. Running conversions to PDF this way will likely not be possible, but at the very least I'll be able to have copies of the rmns in case anything happens to their cloud or the tablet.\n\n# E-Ink\n\n![How e-ink works](einkDemo_0001.gif|width=40)\n\nSomething that I decided to research as I was tackling this project was how the e-ink technology actually works. It's super interesting, and was definitely worth looking into. Basically, e-ink screens consist of many tiny bubbles in a grid layout, with individually controllable electrodes behind each one. Each bubble is filled with a liquid and some very small white charged particles and very small black oppositely charged particles. Since opposites attract, they are tendent to cluster together. However, since there's an electrode, when it provides a charge only half the particles (those with the opposite charge) stick to the bottom of the bubble, and the other particles float up, resulting in a crisp black or white spot.\n\nWhat's unique about e-ink is that it doesn't require a backlight like RGB LCD or OLED screens. Instead, an external light source is needed so that light gets reflected off of the surface black or white particles. You can add a backlight behind the bubbles, but Remarkable chooses not to, since it reduces the thickness of the screen, which results in a more paper like feel. This makes e-ink much more paper like, much easier on the eyes, and have much better battery life. Plus, Remarkable further enhances this paper like experience, as does kindle and other brands of e-ink tablets, by using a matte treated glass screen and specially designed stylus with particular pen nibs.","src/posts/RemarkableBackupUtility.mdx","fdb3988b83edf19e","svgshenanigans",{"id":242,"data":244,"body":250,"filePath":251,"digest":252,"deferredRender":26},{"title":245,"type":9,"date":93,"covers":246,"tags":248,"description":249},"SVG Shenanigans",[247],"https://static.404wolf.com/hdiamond.png",[35],"In my quest to automate SVG file generation, I discovered Chrome's ability to convert complex SVGs with imports into self-contained PDFs through its printing protocol. My aim was to write a script to easily convert Chrome-preview-able files into PDFs. With Selenium and Chrome's Devtools Protocol, I was able to figure out how to perform the conversion, but wasn't satisfied. In this post, I discuss my script to convert complex files like SVGs to PDFs without any file handling, from memory to memory, headless-ly to allow for a smooth and efficient conversion process.\n","# The Task\n\nI've recently been working on a project to automatically generate English flashcards with a blend of AI and APIs to fetch data, and a template of some sort to slot it into. For the latter part, I've spent significant time researching. I've come across different Js frameworks like [Paper.js](http://paperjs.org/), but eventually settled on utilizing raw, generated `SVG` files. `SVG`s are a great type of image file to generate, since they follow a strict XML format, and thus can have text or base64 images injected into them with ease.\n\n## SVGs are Awesome\n\n`SVG`s really are great. They're a undervalued file format that can be used for so, so much more than just icons and simple graphics. They allow you to easily integrate countless different elements in `xml` form, like `\u003Canimate>` and `\u003Cpath>`. You can slot in `\u003CforeignObject>`s to add external elements like such...\n\n```xml\n\u003C!-- Inspirational quote -->\n\u003CforeignObject x=\"0\" y=\"41\" width=\"126\" height=\"24\">\n    \u003Cxhtml xmlns=\"http://www.w3.org/1999/xhtml\">\n        \u003Cp class=\"inspirational-quote\">\n            \"{{ INSPIRATIONAL_QUOTES_1 }}\"\n        \u003C/p>\n    \u003C/xhtml>\n\u003C/foreignObject>\n```\n\n`\u003CiFrame>`s, and all other `HTML` and even some `js` goodies become real possibilities. `css` styles can be added natively, including classes and all. However, when you begin to slot in external sources like this, problems arise when it comes to rendering the `svg`s into self-contained `PDF`s or rasterized `JPG`/`PNG` images.\n\nThe external imports and HTML elements that I'm loading into my SVGs prevents most libraries that already exist from importing them, likely as either a security precaution, or perhaps because externally defined data is hard to render. Something I noticed, however, is that Chrome has no issue with loading complex SVGs with imports. Chrome is a full fledged browser, so it makes sense that it has baked-in support for all the external elements I may include.\n\nBut how does this help me render `SVG`s? Well, as it turns out, Chrome provides a great renderer too. It's a bit clunky, and maybe not an ideal solution, but it works well and consistently.\n\n## Printing to PDFs\n\n![Chrome Devtools PDF Printing](renderPDF.png|width=36|float=right)\n\nTo render `SVG`s with chrome, I first turned to its printing functionality. Importantly, Chrome lets you print not just to printers, but also to PDF files directly. The settings are highly customizable, and let you export `SVG` super easily to a `PDF`.\n\nJust like with regular printing, Chrome provides options for setting the page layout, along with adding margins (which, since I'm not actually planning to print my `SVG`s, could be set to 0), setting a page range, and more. With the devtools protocol, which is essentially a way to computationally interact with the printing API, even more options become possible. With the API, Chrome allows for the file to be exported as a data stream or base64 data string, which would allow me to not have to do additional file handling.\n\n# Loading up a chrome driver\n\nThe first step of the process is to load up a chrome driver. I decided to externalize this step, loading up a chrome driver in a separate \"engine\" module, so that I wouldn't need to load in a new chrome driver for each PDF conversion. In the past I've used [Pyppeteer](https://github.com/pyppeteer/pyppeteer), a fork of [Puppeteer](https://pptr.dev/) to automate Chrome, for various unrelated projects. However, since Pyppeteer is now no longer maintained, I decided to explore [Selenium](https://www.selenium.dev/), a different popular browser automation library, instead. After some research, I came across many StackOverflow articles like [this one](https://stackoverflow.com/a/68353518/14266969), explaining how I could take advantage of the Chrome DevTools Protocol command [Page.printToPDF](https://chromedevtools.github.io/devtools-protocol/tot/Page/#method-printToPDF) to run the print command. Since my goal was to avoid needless file handling, I didn't plan on using the exact code from StackOverflow, but it would be a good starting point, and showed that my planned procedure was indeed a possibility.\n\n```py\nimport atexit\nimport os\n\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\n\n# Install chromium if it isn't already installed\nservice = Service(ChromeDriverManager().install())\n\nchrome_options = webdriver.ChromeOptions()\n# Kiosk printing makes it so that the print dialog GUI is hidden. Since I'm using headless\n# chrome, I believe this just reduces the compute to interact with the print-to-pdf API, since\n# it wouldn't be shown anyway, but may still be rendered. This seems like a common flag for\n# printing to PDF, so I included it since it didn't hurt.\nchrome_options.add_argument(\"--kiosk-printing\")\n# Disable's the UI. Not needed, but makes things faster and things work on CLI only computers.\nchrome_options.add_argument(\"--headless\")\n# Printing to PDF shouldn't require a GPU.\nchrome_options.add_argument(\"--disable-gpu\")\n# The sandbox seems to prevent tabs from messing with each other, as a security feature. Since\n# we're 'hacking' Chrome to render PDFs, making Chrome lighter any way we can is ideal.\n# https://www.google.com/googlebooks/chrome/med_26.html (comic I found that helps explain it)\nchrome_options.add_argument(\"--no-sandbox\")\n\n# Create the webdriver, and make sure that it closes properly when Python exits\nwebdriver_chrome = webdriver.Chrome(service=service, options=chrome_options)\natexit.register(webdriver_chrome.close)\n```\n\n# Webpage Injection 'Hack'\n\nAs aforementioned, something important for the rendering process is for it to be able to be done purely in memory. My project utilized templated `SVG`s, so writing rendered templates in their `SVG` form to disc for the sole purpose of loading them into Chrome only to dump them back to dic would be extremely redundant. So, I devised a solution.\n\nThe thing with `SVG`s is that they are, when it comes down to it, a special type of image file. You can put them into html with the special `\u003Csvg>` tag, or, just like any other image, with `\u003Cimg src=\"data:image/xml+svg;base64{base64-encoded-svg}>`. Then, you can set properties just like any other old `\u003Cimg>` element: `{width: 100%; height: 100%; ...}`. Super simple! So, instead of dumping the `SVG` to disc and using Chrome's file preview ability (in Chrome you can visit `file:///\u003Cpath>` to preview a file), I decided to inject the `SVG` I wanted to render.\n\n![Chrome's about:blank](https://static.404wolf.com/aboutBlank.png)\n![Injected image](https://static.404wolf.com/injectedImage.png)\n\nTo do this, first I opened an `about:blank` page. I knew I'd want to resize the image to fill the entire viewport, but I'd also want to resize the viewport to be the exact size that I wished for my final export to be. For this, I used Chrome devtools' `Emulation.setVisibleSize` command. Then, I sent the following javascript to the browser to inject the image.\n\n```js\ndocument.body.style.margin = \"0\"; // remove the default document margin\nconst content = document.createElement(\"img\"); // create the \u003Cimg> element\ncontent.src = \"data:{mimetype};base64,{data}\"; // inject the svg as a b64 image\ncontent.style.width = \"100%\"; // maximize the image\ncontent.style.height = \"100%\";\ndocument.body.appendChild(content); // inject the image\n```\n\n# 'Printing' the PDF\n\nNow comes the most important step: actually printing to a PDF. This step was super simple: just a Chrome devtools command. Check it out...\n\n```py\nwebdriver_chrome.execute_cdp_cmd(\n\"Page.printToPDF\",\n    {\n        \"printBackground\": False,\n        \"landscape\": False,\n        \"displayHeaderFooter\": False,\n        \"scale\": 1.5, # chrome seems to add some extra margin when printing, even\n        # when the margins are set to 0. I just scaled up a bit to account for this.\n        \"paperWidth\": 1.75, # the width of the document I'm dealing with, in inches\n        \"paperHeight\": 2.5, # the height in inches\n        \"marginTop\": 0,\n        \"marginBottom\": 0,\n        \"marginLeft\": 0,\n        \"marginRight\": 0,\n    }\n)[\"data\"]  # grab the b64 encoded PDF\n```\n\n# Potential\n\nThe cool thing with SVGs is that not only can you write them out in a text editor easily, but you can also template them. I'm not going to go too far into that procedure here, but [here's a simple example](https://github.com/404Wolf/SvgTemplating) of utilizing `SVG`s as a document template for an English vocab flashcard. The idea is that you can slot in `{{ FIELD_NAME }}` `jijna2` (templating engine) fields, slot in your own data (whether fetched from an API, user entered, AI generated, or what not), and then render it to a PDF.\n\nThis is just the start, and feel free to reach out if any other `SVG`-related ideas come to mind!","src/posts/SVGShenanigans.mdx","443156c1dadf3d01","todayilearned",{"id":253,"data":255,"body":261,"filePath":262,"digest":263,"deferredRender":26},{"title":256,"type":9,"date":16,"covers":257,"tags":259,"description":260},"Today I Learned",[258],"https://static.404wolf.com/Post-20240713182452886.webp",[35,20],"A collection of random disconnected things that I learn on given days.","---\n\n# Today I Learned\n\nA collection of random disconnected things that I learn on given days.\n\n# 2024-11-20\n\nLearned about the \"Dreadful Diamond on Derivation\" problem...\n\n[Full credit to this stack overflow](https://stackoverflow.com/questions/21558/in-c-what-is-a-virtual-base-class)\n\nBasically, you have an inheritance hierarchy that looks like\n\n```\n  A\n / \\\nB   C\n \\ /\n  D\n```\n\nThe issue is that if we do `A.D()`, we could be referring to `A::B.D()` or `A::C.D()`.\n\nSo you can do `class A : public virtual B, public C{…)` to only inherit the actual methods from `C` to solve this problem.\n\n# 2024-09-26\n\nI set up [neotest](https://github.com/nvim-neotest/neotest) and [nvim-dap](https://github.com/mfussenegger/nvim-dap) and then removed them from my config. Turns out I prefer `vscode` once I'm debugging/testing.\n\nSome `vscode` shortcuts:\n\n- `control+1` focus the text editor group\n- `control+shift+e` toggle focus of the file tree and text editor group\n- \"control+\\`\" focus the terminal, and then toggle it\n\n# 2024-09-25\n\n> In [information theory](https://en.wikipedia.org/wiki/Information_theory \"Information theory\"), [linguistics](https://en.wikipedia.org/wiki/Linguistics \"Linguistics\"), and [computer science](https://en.wikipedia.org/wiki/Computer_science \"Computer science\"), the **Levenshtein distance** is a [string metric](https://en.wikipedia.org/wiki/String_metric \"String metric\") for measuring the difference between two sequences. The Levenshtein distance between two words is the minimum number of single-character edits (insertions, deletions or substitutions) required to change one word into the other. It is named after Soviet mathematician [Vladimir Levenshtein](https://en.wikipedia.org/wiki/Vladimir_Levenshtein \"Vladimir Levenshtein\"), who defined the metric in 1965.[\\[1\\]](https://en.wikipedia.org/wiki/Levenshtein_distance#cite_note-1)\n\n# 2024-09-18\n\nLearned sql, used \\\u003Chttps://sqlbolt.com\\>. Very helpful tutorial.\n\n# 2024-09-08\n\nNeovim has built in spell checking! No plugins needed\n\nhttps://neovim.io/doc/user/spell.html\n`:setlocal spell spelllang=en_us` enable built in neovim spell checking\n`z=` - see spelling suggestions\n\n# 2024-09-05\n\nYou can use `git mv \u003Cfrom> \u003Cto>` and `git rm [-r] \u003Cthing>` to move and delete things with `git` without consequences if you have things like submodules.\n\n# 2024-08-15\n\nhttps://github.com/mikavilpas/yazi.nvim\n\nMake `dunst` go to the top right\n`origin = \"top-right\";`\n`offset = \"10x10\";`\n\n# 2024-08-15\n\nBash variable parameter extraction + glob stuff\n\n- `${VARIABLE}%ff` removes the first occurrence of `ff` from the back of `VARIABLE`\n- `${VARIABLE}#ff` removes the first occurrence of `ff` from the front of `VARIABLE`\n- `${variable//pattern/replacement}` is a form of parameter expansion that replaces all occurrences of pattern with replacement in the value of variable\n\n# 2024-08-14\n\nOpen source alternative to zoom https://p2p.mirotalk.com/\n\n# 2024-08-09\n\nIn `bash` you can use `**` to get a list of files in the current directory. You can even pattern match with like `**.nix`\n\nSo, like\n\n```bash\nfor file in **; do\n    echo $file\ndone\n```\n\nAnd `file` is the relative path of the file from where you run the command.\n\n# 2024-08-02\n\n`css` has a `not` function to target things that are not the thing. So like, `p:not(.foobar #barbar)` will target everything that is not of class `foobar` and with id `barbar`.\n\n# 2024-08-01\n\nCapital `W` and capital `B` take you forward and backward a word in vim without regard for periods\n\n![WindowsError](https://static.404wolf.com/Post-20240801230814573.webp)\n\nApparently `python` has a Windows specific error message\n\n# 2024-07-22\n\nYou can easily get example videos in various formats at \\\u003Chttps://sample-videos.com/\\>\n\n# 2024-07-20\n\n`gm` goes to the center of the current line in `vim`\n\n# 2024-07-16\n\n[Powershell](https://github.com/PowerShell/PowerShell) is open source. You can use Powershell as your default Linux shell. Who knew.\n\n![Powershell as Linux Shell](https://static.404wolf.com/Post-20240716222818686.webp)\n\nAlso, Windows has a cool app called \"Sandbox,\" which you can create `xml` config files to template, that are basically Windows virtual machines without bloat (not even the microsoft store). They work really well, I think they should be a distribution of Windows itself.\n\n![Windows sandbox](https://static.404wolf.com/Post-20240716223116191.webp)\n\nhttps://learn.microsoft.com/en-us/windows/security/application-security/application-isolation/windows-sandbox/windows-sandbox-overview\n\n# 2024-07-13\n\n- [You can terminate a unified AST traversal early, or skip the iteration early, by returning special things](https://unifiedjs.com/explore/package/unist-util-visit-parents/#what-is-this). If you return `false` the iteration ends. If you return 'skip' then it skips the iteration right away (kinda like `continue` if it were a loop or walker iterator).\n\nUsed this to create this script to yoink a specific section from a markdown string (for example, I want to get the # Description section's paragraphs only)\n\n```ts\nexport function getContentOfSection(\n  markdown: string,\n  header: string,\n  depth: number = 1,\n) {\n  const ast = unified().use(remarkParse).parse(markdown);\n\n  const output: string[] = [];\n  let inHeadersSection = false;\n  let nextIsWantedText = false;\n  visit(ast, (node) => {\n    if (\n      node.type === \"heading\" &&\n      node.depth === depth &&\n      node.children.length > 0 &&\n      node.children[0].type === \"text\" &&\n      node.children[0].value === header\n    )\n      inHeadersSection = true;\n    if (inHeadersSection) {\n      if (nextIsWantedText) {\n        if (node.type === \"text\") output.push(node.value);\n        else if (node.type !== \"paragraph\") return false;\n      }\n      if (node.type === \"paragraph\") nextIsWantedText = true;\n    }\n  });\n  return output.join(\"\\n\");\n}\n```\n\n# 2025-03-31\n\nGoing to try to be more consistent with this again!\n\n```ts\nconsole.trace(\"How did we get here?\");\n```\n\nWill do a `console.log` and also spit out a stack trace\n\n# 2025-04-03\n\n![](https://static.404wolf.com/73229a01-0bf5-430d-b119-7fab37d48aaf.webp)","src/posts/TodayIlearned.mdx","ca0931185041b465","valtowncli",{"id":264,"data":266,"body":274,"filePath":275,"digest":276,"deferredRender":26},{"title":267,"type":15,"date":268,"covers":269,"tags":271,"description":273},"Val Town CLI","2025-01-01",[270],"https://static.404wolf.com/37c9a2a8-3f0a-4b52-a9c7-cf7c0cc0799b.webp,430777215-b0211414-1fa5-4b7c-8612-b9459a2cb8f8.gif",[36,272],"work","A technical dive into the development of VT, Val Town's new command-line tool that enables local development for Val Town projects. Engineering considerations behind building VT, like its evolution from a FUSE-based approach to a more compatible Git-inspired CLI design. How VT handles synchronization between local and remote environments, file watching for live development, and the challenges of implementing features like rename detection.\n","# VT: The new Val Town CLI\n\nIntroducing VT: the official command line tool to edit, manage, and begin Val Town projects from the comfort of your terminal!\n\n![VT in action!](demo-video.mp4|width=100|float=none)\n\nVal Town gives you a super fast, intuitive, and powerful way to instantly create (and deploy) websites. But until now, this entire experience has been on the web. There's a lot of reasons to want to work on your Val Town projects locally. Maybe you want to work from the comfort of your favorite editor, whether that's vscode, with your favorite extensions, theme, and keybinds, or Neovim and tmux. Or you want to access powerful local devtools, like ripgrep or sed, or increasingly AI powered modern ones like Claude Code or AI powered IDEs like Cursor. Maybe you want to use `git`, or some other version control system outside of Val Town. Or maybe you want an easy way to port a non-Val-Town project to Val Town. Now you can!\n\n`vt` is designed to be a simple, robust, interactive CLI to interface with val town projects.\n\n![](404Wolf/Posts/Projects/makingVtCli/Resources/recording%201.gif)\n\nWith VT, you can:\n\n- `vt clone` a val town project to a folder, and then `vt watch` that folder, so that as you make changes locally they are automatically pushed to val town. This includes editing, creating, deleting, and renaming vals.\n- `vt checkout`, and manage multiple branches locally, working on multiple features at once.\n- `vt create` or `vt remix` to start new projects locally, and `vt list` and `vt delete` to manage your Val Town projects.\n- And more!\n\n![63 files cloned in 0.17 seconds](vtIsFast.gif)\n\n`vt` is also fast! Operations all happen concurrently whenever possible. Watch 62 files get cloned in 0.17 seconds!\n\n`vt` is still in beta, and we'd love your feedback! Join [the Val Town Discord](https://discord.gg/hd9U4GGB) to leave feedback. Vt is built entirely within Val Town \"userspace\" (with the public API), and the codebase can be found at [https://github.com/val-town/vt](https://github.com/val-town/vt) .\n\n## Try it out!\n\nTo get started using `vt`, make sure [you have Deno installed](https://docs.deno.com/runtime/getting_started/installation/), and then run\n\n```bash\ndeno install -grAf jsr:@valtown/vt\n```\n\nTo authenticate with `val.town`, just run `vt`, and you should get the dialog\n\n![](https://static.404wolf.com/b2f61bc1-8402-4192-9a28-6e6458755b80.webp)\n\nRespond yes to the prompt, and ensure you select to create an API key with user read & project read+write permissions.\n\nThen try cloning one of your projects with `vt clone`!\n\n![](https://static.404wolf.com/992c7283-3b28-4790-ab3a-50c4d496d181.webp)\n\nWhich will open up a menu with all of your projects that you can clone. You can actually clone anyone's project, but you won't be able to push if it isn't yours (you can always `vt remix` though!).\n\n![](https://static.404wolf.com/c323e98d-3e83-4d73-b344-121a308267df.webp)\n\nOnce cloned, you can run `vt watch` to enable automatic syncing with Val Town. When you edit the project locally, it will automatically upload the changes to Val Town. You may find it useful to use a terminal window in your editor of choice so you can easily see the changes being pushed and see errors.\n\nFinally, fire up your favorite editor and start creating!\n\nFor more information, head over to the [`vt` JSR page](https://jsr.io/@valtown/vt)!\n\nFor the curious, here's a technical overview of the making (and origin) of `vt`.\n\n# Finding the path\n\nThere's a lot of different ways we could engineer a local Val Town experience.\n\n![Pomdtr's Val Town VScode extension](https://static.404wolf.com/pomdtrextension.webp)\n\nOne of the very first sight of Val Town \"localdev\" came with Pomdtr's [Val Town vscode extension](https://marketplace.visualstudio.com/items?itemName=pomdtr.valtown). The extension was pretty straightforward, it hooked into the Val Town API to let you edit your vals locally and then push them to Val Town. It was made pre-project era, so it only supports traditional Vals. VSCode runs on electron, and gives extension developers a lot of power, the extension also offered web previews, and the ability to use Val Town SQL and blobstore.\n\nA bit later, I came along and implemented a fuse file system for Val Town vals, also pre-project era. Fuse is a Linux protocol that lets you implement arbitrary file systems in userspace. By implementing a fuse val town file system, all edits locally are instantly reflected on the Val Town website, and vice versa (if you update remotely, then if you try to save locally your editor will say something along the lines of \"more recent edits found, are you sure you want to write\"). Fuse is very powerful -- writes, reads, and all other file system syscalls can be handled with whatever response you want.\n\n![Diagram from https://www.cs.cmu.edu/~./fp/courses/15213-s07/lectures/15-filesys/index.html](https://static.404wolf.com/bcbdf72d-0875-4288-ab8c-3b06b1cace32.webp)\n\nThis project was `vtfs`. Originally it was a side project of mine, because \"can I write the code in neovim\" was the first question I asked myself when I first started using Val Town. I love the elegance of a file being a website, and thought it would be fun to be able to do a \"touch website.ts\" to create them, via the magic of fuse, and Val Town! There's a lot to love about the perfect 1:1 mapping of Val to File.\n\n[And so I built it](https://github.com/404wolf/valfs)! `valfs` was really cool: you'd run `vt mount [dir]` and you'd get a folder with all of your vals in it.\n\n`vtfs` was built written in go with [`go-fuse`](https://github.com/hanwen/go-fuse), because, well, I didn't want to deal with C++ package management, and I wanted to try go. `go` is super cool, it's like a \"cleaner\" `c` with actually pleasant devx, and the best type of imports (URL imports!).\n\nFuse is a two-part system that involves userspace/kernel-space communication via a special [\"wire protocol\"](https://john-millikin.com/the-fuse-protocol). The official userspace [\"reference library\"](https://github.com/libfuse/libfuse) for implementing fuse filesystems is written in `C`, but what's cool about `go-fuse` is that it's entirely rewritten in pure go (not just a wrapper with `cgo`).\n\n![](https://static.404wolf.com/37c9a2a8-3f0a-4b52-a9c7-cf7c0cc0799b.webp)\n\nWe decided to rewrite it mostly for compatibility reasons. Linux offers native fuse support, but MacOS and Windows definitely do not. For Mac, there's a project called [MacFuse](https://macfuse.github.io/) that acts as a kernel extension to provide fuse support to Mac. However, it's not totally stable, and [Apple is deprecating kernel extensions](https://developer.apple.com/support/kernel-extensions/) and it may not be the best long term solution. There's a really cool project called [fuse-t](https://www.fuse-t.org/) that takes a different approach, where it implements the fuse protocol by forwarding fuse to NFS (network file system), a protocol that Macs do naively support.\n\nOne idea we had to avoid dealing with fuse was to build a generic FTP server, largely inspired by Pomdtr's [Webdav](https://www.val.town/x/pomdtr/webdav/code/webdav.ts) server. His server works totally in userspace and maps the Val Town API to Webdav really nicely. [Webdav](https://en.wikipedia.org/wiki/WebDAV) is a generic \"file system\" ish protocol over HTTP, and making a FTP server would just be implementing on a fancier file transfer protocol that's more capable. What's nice about using protocols like these is that you can then just use `rclone` for mounting or syncing.\n\nIn addition to compatibility issues, implementing a fuse backend is just plain complicated. The way `valfs` worked, on [every write syscall](https://github.com/404Wolf/valfs/blob/418eff73b080fe8cdb7fe7f7afd3fe30dbae2720/valfs/vals/valfile.go#L116C1-L153C2), `valfs` would have to parse the file, extract metadata, and do multiple API calls. Even though `vt` is a total rewrite, many design choices for `vt` came from `vtfs`, like considerations on how we handle metadata, the notion that \"a val is a file,\" and more.\n\nAt its core, `vt` was built to be a decentralized synchronization tool. Unlike `vtfs`, where the sync is guaranteed and live, syncing happens asynchronously with `vt` (even when \"live syncing\" with `vt watch`, which is only \"psudo-live\" since you could create conflicts by updating state on the website while watching). We rebuilt `vt` in typescript with `Deno`, because, well, we (and our community) love typescript and Deno, there's an official [typescript sdk](https://docs.val.town/api/sdk/) for Val Town, and because we have hopes of turning `vt` into a esm library in the future (so you can use `vt` in your own, non-val-town workflows).\n\nWe originally wanted to host `vt` itself on Val Town, where we would begin development with git and github, and then eventually transition to using `vt` itself to continue development of `vt` (bootstrapping!).\n\nEarly on, however, we ran into a lot of trouble with path aliases. When you use `http` imports for libraries (as you would if we hosted `vt` on Val Town, since you'd do `deno install -grAf https://esm.town/std/vt` or similar), all the imports need to be relative since you lose all the configuration of your `deno.json`. This is an issue with `Deno` that is [\"expected behavior\"](https://github.com/denoland/deno/issues/25994). We did consider at one point just [caving and making all the imports relative](https://github.com/val-town/vt/pull/28), but it really sucks to have imports like `import foo from \"../../../../../foo.ts\";` all over the place. Unfortunately, this is a platform limitation that we still need to solve. One idea we had to get around this was to install the source code locally in a temp directory with the `deno.json` via a (http importable) install script. I even wrote a [Val that generates the install script to make this work for any project!](https://www.val.town/x/wolf/runWithDenoJson). You can see this in action (and it might still work!) by visiting [`https://run-with-deno-json.val.run/gh/val-town/vt/main/vt.ts`](https://run-with-deno-json.val.run/gh/val-town/vt/main/vt.ts) (notice how you put the entrypoint to the http library in the url path). We used this approach for a bit, but [eventually ran into weird issues where Deno would keep the old version cached](https://github.com/val-town/vt/issues/40) even if you did a new install with `-r`, which we never totally solved but I imagine is related to the fact that the entrypoint of `vt`, `vt.ts`, itself never changed.\n\n`vt` also has a [lot of automated tests](https://github.com/val-town/vt/actions), and currently Val Town doesn't offer automated CI.\n\n# Going Git\n\n`vt` is heavily inspired by both `git` and [gh](https://cli.github.com/), the github CLI. There's elements like `vt push` and pull that are very `git`ty, and things like `vt create` that act like `gh repo create`. Or, commands like `vt browse`, similar to `gh browse`, which opens up the current project in a web browser.\n\nLike `git`, `vt` \"Projects\" are denoted by the existence of a dot folder -- in `vt`'s case, `.vt`. This is also where state and configuration data lives for the project. Right now, the only thing that lives in `.vt` is `state.json`, which contains information about the current version of the project checked out, and the project and branch id.\n\nUnlike `git`, where you have a `stage` and `commits`, `vt` only has a notion of `pushing` and `pulling`. This means that the local state could conflict in ways with the remote state that could result in changes that we can't reconsile: like, if you pull and you have newer changes locally, or If you push and there are newer changes in the remote.\n\n[We spent a while considering what pushing and pulling meant](https://github.com/val-town/vt/issues/45). The conclusion we came to:\n\n- `pushing` is a forceful procedure. When you push we ensure that the remote state matches the local state, and by the end of the push the remote state should match the local state with no changes to the local state. This might sound scary, but we do versioning for projects, so in the worst case you could revert to an earlier version on the website and pull.\n- `pulling` is a \"graceful\" procedure. When you pull, you may receive modifications, deletions, creations, or renames to local files. For all of these changes except creations, pulling warns the user that local changes will be lost, and you need to confirm to complete the pull. This is implemented internally by doing a \"dry\" pull and checking what changes would be made locally.\n\nThis means that the contract for push is \"push the local state to make sure the remote matches it\" and pull is \"get the remote state and make sure the local state matches it.\"\n\nOne totally different idea that I had to solve this problem of \"the meaning of push and pull\" was to totally scrap both, and change the contract to \"sync to a consistent state.\" As it turns out, syncing really just redirects all the complexity, and is still quite complicated to implement.\n\n![](https://static.404wolf.com/23f9ca70-b232-4f70-a746-1a64c9590704.webp)\n\nI spent a while designing an algorithm for syncing, where the primary \"building block\" of the algorithm was to \"walk\" through revisions and make changes to the local state incrementally. Because of how Val Town does versioning, the changes could be applied one version at a time.\n\nOn the subject of versioning: the way Val Town does it made developing `vt` easier since versions are just increasing integers, but as a user numbers are sort of meaningless. In one project I'm working on, I've hit versions in the thousands! My solution to make versions more useful is to maintain a `versions.txt` file that adds messages to specific versions. Right now, reverting to an older version is the same as doing a force push to the current branch with that version, and this can be done via the web ui (and is not currently a `vt` feature).\n\nSyncing would start by pulling to incorporate all remote changes locally, and then push the remainder. It also would look at modification times to try to guess which update should be kept in the case of local/remote conflicts. [Here's the actual proposed algorithm for the curious](https://gist.github.com/404Wolf/3e79ce4b50c39cbc332fc07d7d2a0522).\n\nWith the way `vt` does git, we get a lot of internal logic \"for free.\" Many of the internal vt operations are able to easily piggyback off of one another in (sometimes) mind bending ways. Like `vt push --dry-run` being the same as `vt status`, `vt pull` just does a `vt clone`, and then removes stuff that does not exist on the remote that still exists locally, or `vt checkout` is somewhat like `vt pull`-ing the branch you are trying to check out. These abstractions make testing and maintenance much easier.\n\nThere's been some discussion of how far we should lean into the `git` analogy. For example, `vt` has command flags like `checkout -D/-b`, where, without the existence of `git` would probably be `branch create` `branch switch`. We don't think there's a \"correct\" answer here, and are open to thoughts on what would be most intuitive/ergonomic for folks. [Even git can't always seem to figure it out](https://stackoverflow.com/questions/57265785/whats-the-difference-between-git-switch-and-git-checkout-branch).\n\nWe also considered [and even implemented at one point](https://github.com/val-town/vt/pull/7) adding support for `vt stash`, so you could save local changes that you didn't want to push, but decided that we wanted to keep Val Town as the source of truth and try to avoid adding additional states. We may return to this later, since it would be nice to be able to \"scrap\" local changes without totally losing them, though. One thought is putting these changes into a \"scratchpad\" branch instead of storing them locally.\n\nFinally, something we knew early on is that people would need a way to opt out of syncing stuff. Originally, I thought this would be really straightforward, just add a `.vtignore`, and implement it like a `.gitignore`: a newline separated list of globs. But it turns out that `.gitignore`s are kinda complicated, and it isn't quite like that. I started down the path of trying to implement this myself, but eventually decided to use a [gitignore-parser](https://jsr.io/@cfa/gitignore-parser) library that I found. There's really interesting fancy `gitingore` behavior you've probably never thought about, like if you have conflicting patterns like `!foo.tsx` and `foo.tsx`, later ones take president, and `/` prefixed stuff is relative to the root of the git directory. [Git has a whole man page on it!](https://git-scm.com/docs/gitignore). We still don't have perfect parity, like `.vtignores` apply for the entire project and not just \"lower\" files like they do in `git`.\n\nOne other question with ignore files that is ongoing is whether we should name ours `.vtignore` (in the style of `.npmignore`, `.dockerignore`, etc), or, like some tools like `nix`, just re-use `.gitignore`. [We are still considering what to name ours](https://github.com/val-town/vt/issues/10), but right now use `.vtignore`.\n\n## The Live Dev Experience\n\nOne of the most important use cases of `vt` is \"watch\" functionality. There's a lot of reasons for this. One of the big ones is that, as you (and maybe your favorite LLM) edit your code locally, it is really handy to remove the friction of syncing with Val Town.\n\nFrom the beginning, my plan for this was to implement \"git\" behavior first (pushing and pulling), and then just doing file system watching to add live syncing using [Deno.watchFs](https://docs.deno.com/api/deno/~/Deno.watchFs) to handle file system events.\n\n![](https://static.404wolf.com/7f2ed32c-8fc4-4f5c-86ed-733402383d14.webp)\n\nOne particularly annoying challenge with `vt watch` was handling debouncing. Deno's standard library has an [async module](https://jsr.io/@std/async) that was super useful for implementing `vt watch`. `vt watch` works by doing a `push` initially, and then whenever local changes are made running another `vt push`. It sounds super simple, and it mostly is!\n\nThe issue is that there's a lot of different things that could trigger a \"files were changed\" notification, and doing the push itself is one of them (which took a painful amount of time to figure out: the `.vt` folder has files internally that get updated on a push, like book-keeping ticking the version). Instead of working out the corner cases, I added a grace for post-pushing before we are able to detect file changes again.\n\nI also debounce the push. Initially, I did this so that if you are doing large amounts of file modifications we wait until you're done before starting the push, but it turns out this is more important because of how editors will create ephemeral temporary files during writes. Now, when you edit a file, the editor might create transient files, but as long as it gets rid of them within the debounce the final state that gets pushed is the one that does not include those temporary files.\n\nAnother aspect of this live dev experience is the friction of having to reload the website as you make updates to the website. Unfortunately, even though we _can_ and do open browser tabs, browsers' CLIs do not expose a way to redirect or reload open tabs unless you launch the browser with remote debugging (think puppeteer).\n\nOne idea I have for solving this problem, which I think will be the best long term solution, is a minimal browser extension that [uses a websocket](https://developer.chrome.com/docs/extensions/how-to/web-platform/websockets) to talk to `vt`, and have `vt watch` use `Deno.serve` to host a minimal websocket server on localhost that pushes when the project gets updated. Extensions _can_ reload tabs, so this would give `vt` the power to tell your browser to reload tabs. This is still just an idea, and will be tested soon.\n\nSteve has been working on a [more general solution](https://www.val.town/x/stevekrouse/live-reload) to this problem by injecting code into the website that detects updates and reloads using a Val with long polling. There's a [demo of that here](https://www.val.town/x/stevekrouse/live-reload-demo), the general idea is that it polls the latest version of the project and reloads the page on updates. This works outside of `vt` too.\n\n## Some Nitty Gritty\n\nInternally, `vt` is broken up into two main parts: the `vt lib`, where the actual logic for `push`, `pull`, and other \"git\" operations is defined, and the `vt cmd` lib, where the CLI logic is laid out. Eventually, we want to make `vt` a esm library, where we expose the functionality of the `vt lib` component.\n\nFor both cases, we're using [Deno's native testing framework](https://docs.deno.com/runtime/fundamentals/testing/). For `vt lib`, it's pretty straightforward, where we run tests in temp directories doing things like pulls or pushes, and then use the `sdk` to verify changes.\n\nFor the command library, the CLI framework we're using for `vt` (cliffy) has a handy [Snapshot test module](https://cliffy.io/docs@v1.0.0-rc.7/testing/snapshot) that `vt` doesn't use. We decided against using snapshot tests mostly because we lose a lot of fine grain control. Instead, we took inspiration from cliffy in running the CLI tests as subprocesses, and make a lot of use of Deno's `assertStringIncludes` on `stdout`. One ongoing issue we've had with testing is that we've encountered a lot of \"resource leaks.\" It's really cool that `Deno` tests can detect unawaited promises or unawaited/cancelled request bodies, but it doesn't do a good job of helping us locate where the issues are.\n\n`vt` stores configuration in `\u003Cyour system configuration directory>/vt/config.yaml`, and loads it using `zod`. There's some interesting mechanics where we have multiple layers of configuration, like local and global, and prioritize configuration options in order. Once again, [Deno's standard library](https://jsr.io/@std/collections/doc/deep-merge) has been really handy in building out these components, like the `deepMerge` function.\n\nTo figure out where your system configuration directory is, usually I'd use [npm's xdg-portable](https://www.npmjs.com/package/xdg-portable), which gets us your os-aware configuration directory, but it turns out that using this via `npm:xdg-portable` [doesn't work with Deno](https://github.com/rivy/js.xdg-portable/issues/3), and we can't use the officially recommended http import version since `jsr`, the registry we publish `vt` to, doesn't support http imports. I looked into this, and it seemed like an issue with their build process not including their Deno code. The solution I decided on? Fork [xdg-portable](https://github.com/404Wolf/xdg-portable-deno) to be Deno native! In the process, I removed a ton of bloat.\n\nThere's also a lot of fun interactive niceities that the CLI provides. Right now, `vt` is primarily designed for the human user, but we plan on adding better scripting support down the line.\n\n![Fancy TTY stuff](430777215-b0211414-1fa5-4b7c-8612-b9459a2cb8f8.gif)\n\n`vt` takes some inspiration from Pomdtr's [previous vt CLI](https://github.com/pomdtr/vt), which served more as a management tool. Like his tool, `vt` uses the [Cliffy](https://cliffy.io/) CLI framework, which, although very new and not super well established, has served every use case we've come upon for `vt`. It's interactive capabilities and `tty` module have been super helpful to crafting some of the fancy interactive elements of `vt`.\n\n```typescript\ntty.cursorSave.cursorHide // Monad-ic tty manipulation is so cool!\n  .cursorTo(0, 0)\n  .eraseScreen();\n```\n\n![](https://static.404wolf.com/ad696f11-a00e-40fc-aa01-1e1e4d08dd6b.webp)\n\nI'm also using `highlight.js`, right now just for configuration commands, but in the future may also use it if we add `vt diff`.\n\n## Naming and (Re)naming\n\nOne of the initial concerns was how one could edit val metadata locally, if we are limited to the context of files.\n\n![](https://static.404wolf.com/Screenshot%202025-04-16%20at%206.32.46%20PM.webp)\n\n`vtfs`'s approach to this was to pack all of the metadata for a val into the file corresponding to it. For Val Town projects, it's a bit more complex, because there's metadata specific to vals in the project, and metadata for the entire project itself too. We decided that, in general, changing val metadata and other uniquely val town attributes is something that we would leave to the website.\n\n`vtfs` would indicate the type of a given val locally as `foobar.H.tsx` (or, if verbose, `foobar.http.tsx`), which was a really nice pattern. If you wanted to change the type of a val, you could just rename it to `foobar.script.tsx`. This pattern, however, turns out not to work as well for projects because vals in projects generally are suffixed with `.tsx`, so you would end up with `foobar.http.tsx.tsx`, and it would get messy quickly -- and there were some issues with Vscode not liking `.script.tsx`. In general, it's a bit scary to introduce magic like this.\n\nInstead of doing strict enforcement -- maintaining a 1:1 mapping of file extension to val type -- `vt` intuits the val type only on creation. If you create a `foobar.tsx`, `vt` sees `.tsx` and assumes it's a script. If you create `foobar_http.tsx` or `foobar.http.tsx`, `vt` sees `.tsx`, knows it's a val and not a file, and then guesses it's an `http` val. But it never will change it after the fact, so you can change `foobar.http.tsx` to be a script val on the website, and that's what it will continue to be going forward.\n\n### Renames\n\nIt might seem simple at first, but if you think about it, detecting whether a file was renamed is actually really tricky. If we move `foo.ts` to `bar.ts` how do we know that it wasn't a `CREATE bar.ts` and `DELETE foo.ts`? Originally we didn't plan on adding rename detection support to `vt` because of all the complexity that comes with rename detection.\n\n![](blob_file_1744341763182_recording.gif)\n\nBut then we realized that, without rename detection, if you move a val with configuration -- like cron config, or custom endpoint HTTP vals, then doing the deletion/creation would cause you to lose all your config! And so, we added rename detection to `vt`.\n\nThe rename detection algorithm is a bit complicated -- it works by looking at all files that got deleted and that got created, and then considering a file as renamed if a created file is sufficiently similar to a file that got deleted. When iterating over created files to see if a deleted file is similar enough to one of them, we use some heuristics to filter out files that could not possibly be similar enough, like the file length. Then we compute the Levenshtein distance between a given deleted file and created file, and consider a given created file \"renamed\" if it is above some theshold similar to a deleted file, and if it is similar enough to multiple, then the one it is most similar to [as it turns out, Deno's standard library has a super efficient edit distance function](https://jsr.io/@std/text). Git does fancy [directory rename detection](https://git-scm.com/docs/directory-rename-detection/2.22.0), which is something that, at least for now, `vt` does not do.\n\nBecause rename detection is relatively expensive, it is internally implemented as an optional operation that doesn't always get used for every `vt` operation. For example, there isn't a lot of reason to do rename detection for `vt pull` -- it would really just be for reporting.\n\n## More on VtFs\n\nThere's some fun features of `vtfs` that didn't end up making their way to `vt`, like blob support.\n\nFor `vtfs`, a core feature was going to be the ability to \"mount\" your val town blob store so that you could view, edit, and organize your blobs locally. With fuse, there's a ton of flexibility on how to \"implement\" inodes. `go-fuse` provides a lot of nice abstractions. For totally static files like `deno.json` I was using the [MemRegularFile](https://github.com/hanwen/go-fuse/blob/v2.7.2/fs/mem.go#L17) helper, which makes it trivial to create an Inode with static text contents. For Vals, I was doing it more manually, implementing the read and write methods for a custom `ValFile` Inode myself. But for blobs, I wanted to handle reads and writes by streaming the relevant portions of the file.\n\nWhen implementing my own write callback for fuse, I would be handling requests to write data to a region of a file (like, write 0001010101 starting at index 22 bytes). Our `/v1/blob` endpoint is somewhat restrictive here. You can only write an entire file, or get an entire file. `vtfs` would show you all your blobs by using the `blob list` endpoint when serving \"list directory\" syscalls, and when you tried to access a specific blob would download the blob to a temp file and internally manage the bookkeeping to map read calls to that temp file (read 1-11 from fooBlob == read 1-11 from `/tmp/f90jjf2j-fooblob`).\n\nHandling writes was particularly tricky -- I could start a new upload to upload the entire state of the file, with the new change made in the current write call, but if you're writing a lot of data to a file (like if you `cp bigFile.png` to the folder that I was using to represent your val town blobs), then there would typically be a burst of write requests to write to consecutive regions of the file.\n\nI spent a long time working on setting up a pipe where I would handle consecutive writes, writes that start at index i, end at index i+k, and then a new write that starts at index i+k+1, etc, as a special case. Eventually, I got something working!\n\nFor `vtfs` I was using [Openapi Generator](https://github.com/OpenAPITools/openapi-generator), and it turned out that Val Town's OpenAPI specification didn't accept file sizes on the order of my tests -- where the response would include the file size, it was an integer, not a `format: int64` (long).\n\n![Working piped blob uploads](https://static.404wolf.com/hashesMatch.webp)\n\nMaintaining this, and getting writes to work non consecutively continued to prove a huge challenge. `valfs` blob read/write support was a fun challenge to work on, but was never totally reliable.\n\n`vtfs` also had tighter Deno integration, which is something that we're still deciding if we want for `vt`. For example, with `vtfs`, when you mounted a folder, `vtfs` would automatically run `deno cache /path/to/thatDir` for you, to make sure that your language server would always have the types for all of the libraries that you were using. Additionally, we have a default `deno.json` file that is taken from `vtfs`, which includes [the Val Town type declarations](https://www.val.town/types/valtown.d.ts) like the `Email` interface, that only show up after you run a `deno cache` from that directory.","src/posts/ValTownCLI.mdx","deb33ba7d4dfc01b","vealesnyderreflection",{"id":277,"data":279,"body":285,"filePath":286,"digest":287,"deferredRender":26},{"title":280,"type":9,"date":16,"covers":281,"tags":283,"description":284},"Veale Snyder Fellowship Reflection",[282],"https://static.404wolf.com/coverFountainVeale, VealeSnyderReflection-20241025150445254.webp, Pasted image 20241025041749.png, Pasted image 20241025035853.png",[21],"As part of CWRU's Veale Snyder entrepreneurial fellowship, I had the incredible opportunity to travel to San Francisco and meet with executives and engineers from various companies, including Fountain, NVIDIA, Rivian, Google, Y Combinator, and Giant. Throughout the trip, I gained valuable insights into entrepreneurship, company culture, and personal growth, which I will carry with me on my entrepreneurial journey. This eye-opening experience has not only expanded my network but also provided me with invaluable lessons that I look forward to applying to my future endeavors.\n","# Veale Snyder Fellowship\n\n## What is it?\n\nThe [Veale Snyder Fellowship](https://case.edu/entrepreneurship/fellowships/veale-snyder-fellowship-program) is a 1 year entrepreneurship fellowship program at [Case Western](https://case.edu/). It's a two part program directed by [Michael Goldberg](https://www.linkedin.com/in/mgoldberg2) and [Stacey Lotz](https://www.linkedin.com/in/stacey-lotz-982484162/), where in the fall semester there's a 1 credit course taught by [Jose Dias Salazar](https://www.linkedin.com/in/josediazs) and a trip to San Francisco to meet various companies in SF and Silicone Valley, along with many Case alum, VCs, and entrepreneurs, and then in spring a 3 credit course and international trip to the Czech Republic.\n\n## Why me?\n\nIf you read my blog, you probably already know that I'm a very technical person. I'm interested in software, computers, webdev/fullstack, devtools, devops/linux/nix, and a plethora of other techy things. I love reading about shiny new typescript frameworks, and how fixed points work in nix. What am I doing in an entrepreneurship program?\n\nIn my application, I stated this well and succinctly,\n\n> Over the years, I've arrived at an ultimate interest in entrepreneurial webdev. I love the interconnectedness and accessibility: how it enables rapid contrivance of genuinely useful applications. I have always found realizing my own project ideas to not just be the best way for me to learn, but also to be most satisfying and fun. My favorite thing in this world is learning things that I want to learn, because I want to learn them. I see impatience as a virtue, a quest for speed and efficiency that naturally harmonizes with my field of interest. In the end, I feel pretty strongly that, eventually, entrepreneurship will be a big part of my future vocational journey.\n\nThis is pretty consistent with my current thoughts on why I'm here now. The only realization I've had since is how my area of focus has shifted more specifically for creating things to solve the problems that I myself face, which there's hints of in my previous thoughts -- I'm most interested in using fullstack technologies that I love using to alleviate developer experience (devx) friction. I want to make the world (for developers) a better place, so they can make the world (in general) one.\n\n# San Francisco Trek\n\nOne of the hallmarks of this program is a trip to the bay area between the 20th to the afternoon of the 22nd of October (2024). It's a very packed two days, where we get to experience entrepreneurship in SF/the valley. It was a really, really fantastic, eye opening experience -- I got to meet so many people and see so many different company cultures and philosophies in such a short time span.\n\nThe other fellows in the fellowship --\n[Salma](https://www.linkedin.com/in/salmabhar/?lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_all%3BCEhhZxHjTLuqlquuMozLsQ%3D%3D), [Alvisa](https://www.linkedin.com/in/alvisakrasniqi), [Ariella](https://www.linkedin.com/in/wayzaro-ariella-yve-taylor-450956217), [Apeksha](https://www.linkedin.com/in/apeksha-malik-125a9a2b), [Sreya](https://www.linkedin.com/in/sreya-srinidhi), [Vinlaw](https://www.linkedin.com/in/vinlaw-mudehwe), [Kaleb](https://www.linkedin.com/in/kaleb-k), [Adam](https://www.linkedin.com/in/adam-hamdan), [RV](https://www.linkedin.com/in/rvyadav), [Alessandro](https://www.linkedin.com/in/alessandro-mason-117417260), and [Vidyut](https://www.linkedin.com/in/vidyutveedgav)\nwere amazing to be around for the trip! One of the coolest parts of the fellowship is how we stick around with the same group of people and all get to know each other. It was a really cool coincidence that most of us are CS people with technical interests; I've managed to sneak in some talk of flutter and system design with Allesandro, or system design, graph generation, and AWS lambdas with Vidyut!\n\nMany other fellows [have](https://www.linkedin.com/posts/salmabhar_this-fall-break-i-had-the-incredible-opportunity-activity-7254647616276226048-Yvta) [already](https://www.linkedin.com/posts/apeksha-malik-125a9a2b_over-the-past-semester-the-team-at-cwru-veale-activity-7255431533707030529-0SS8) [posted](https://www.linkedin.com/posts/rvyadav_vealesnyderfellowship-cwru-techinnovation-activity-7254613603188645888-6Zjx) really great reflections with awesome comprehensive overviews of everything that we did during the trip, so I want to focus on my takeaways, but I'll keep it sequential. This is my first (but definitely not my last) non-technical blog!\n\n## The trip\n\nSunday was more about experiencing SF. We rode in [Waymo](https://waymo.com/) self-driving cars, which was an incredible experience. There was a lot of talk about self driving cars across almost all the companies we visited; it's a trend that seems very well accepted. It seems like, for companies with the resources, there's a pretty big pressure, perhaps out of expectation, that they invest in \"trends\" that _could_ be the future.\n\n## Companies\n\n### Fountain\n\n![Visiting Fountain](https://static.404wolf.com/20241025035853.png)\n\nOn Monday, we started out by heading over to [Fountain](https://www.linkedin.com/company/fountaininc), a software company for recruiting and optimizing hourly wage employee retention. We spoke with [Sean Behr](https://www.linkedin.com/in/seanbehr) about his entrepreneurial philosophies.\n\nWe'd already met Sean virtually during our first class. I'd say his unique takes were that:\n\n- Speed is key. The faster you get a product out the door, the faster you can know to kill it (or accelerate it).\n- Adapting is necessary. The product isn't going to be a masterpiece unless you meld it into one.\n\nEntering his office, it was amazing to see how many people had migrated to work remotely. Honestly, it was a bit sad to see -- I'm a big proponent of pair programming and collaborative workflows, but it seems like it's a dying desire. Sean seemed to agree in the importance of in person collaboration (and cost of lack thereof).\n\nThis time, there was a bit more focus on company culture, and company/system dynamics.\n\n- Culture\n  - Culture is largely immutable. It is also in part a function of company success. Extreme success fosters positive culture. So, CEOs steer for economic success to drive culture.\n- Adaptability\n  - There's _discrete_ categories of success, and it's really, really hard to traverse up the latter. You _need_ to be able to adapt to climb in the long term. But, sometimes it's just not possible to adapt fast enough, and you can't win.\n- Organization\n  - Clarity is very important. Every piece of data _could_ be important, any abstraction on the raw datapoints is lossy.\n  - Having some sort of project management is really important. Set goals are good.\n- Market Research\n  - Connecting with clients and asking about their needs is the best way to improve. Directly mentioning the product induces bias, so sometimes it's best to ask surrounding questions.\n\nI really like Sean's focus on efficiency. I think his thoughts on culture are very valid, but that \"good\" culture doesn't _require_ vast success, just that the success is a way to induce culture. This is also why it's so critical to choose an awesome co-founder and founding team to establish a good culture from the start.\n\nSean believes that some traits are critical for a successful culture. I think he's right, but I also feel these traits are in flux with the state of the company.\n\nHe honors speed and responsibility, and I think these are really really important early on, but less so as the company evolves. By reducing responsibility and honoring exploration, larger companies we visited like Google and NVIDIA have been able to accomplish insane things.\n\nFinally, there seemed to be an emphasis on _identification_ and explicitness, on the \"tangibility\" of goals, values, ideas, and pretty much everything he values and talked about. Writing things down is really, really important. It makes them real.\n\n### NVIDIA\n\n![Nvidia \"Fireside chat\"](https://static.404wolf.com/20241025041604.png)\n![HQ Tour](https://static.404wolf.com/20241025041624.png)\n\nNvidia was an entirely different experience than Fountain. Walking into their headquarters was like walking into an airport. You could tell that if you were to talk to anyone, they'd have a really interesting story to tell, but everyone seemed to be laser focused on their own chunks of work.\n\n[Sabrina Trans](https://www.linkedin.com/in/sabrinatrans/?lipi=urn%3Ali%3Apage%3Ad_flagship3_search_srp_all%3BrCNagRURT%2FiAl%2BHW861hEg%3D%3D) gave us a great tour of the facility -- it was massive; the outdoor area and open spaces were really, really nice.\n\nWe got a brief presentation about their products, which seemed a bit abstract to me. What it did show me though is that their demographic is a much wider net than I would have anticipated: they design tooling for a substantial audience -- yes, software engineers, but also datacenter designers, car companies, and many others.\n\nWhat was most important was the \"fireside\" chat afterwards; an open Q\\&A.\n\nWe met with [Kevin Kranzusch](https://www.linkedin.com/in/kevinkranzusch/), one of the first employees at NVIDIA, [Nick Triantos](https://www.linkedin.com/in/triantos/), VP of software, and [Sarah Yurick](https://www.linkedin.com/in/sarahyurick/), a recent case grad now working on [NeMo](https://www.nvidia.com/en-us/ai-data-science/products/nemo/), and a few others.\n\nSome key points from NVIDIA:\n\n- Their culture has **not** really changed over time. They really value intellectual honesty. I remember back to when I was starting my first batch at [Recurse Center](https://recurse.com), their introduction stresses the importance of being \"kind\" instead of \"nice,\" a similar idea: being honest and upfront over obscurative and always reinforcing.\n- Being well rounded is important. Kevin talked about how Nvidia hasn't really had major \"Pivot\"s, but that they do have to adapt. Something unique about a company their size is that they can invest in R\\&D in speculative fields to try to keep ahead of competition.\n- The best types of industries to go into are the ones with \"insatiable\" desire. Easier said than done.\n\nTheir actual work seemed to be very sharded. Different people we spoke to would work on totally different things, and not know much about what others were working on. I think that, while they value ideas, it seems like just by how their company flows, this \"segmentation\" may make it hard to contribute substantially as any given employee.\n\nOn the other hand, they seem to treat their employees really well. They talked about how there's a lot of respect for ideas and asking for help, which is always good to hear. Because of the specificity of what employees work on, it also seems to be the case that everyone is really interested in what they're working on. They are for sure solving some revolutionary technical problems.\n\n### Rivian\n\n![Rivian Presentation](https://static.404wolf.com/20241025041716.png)\n\nBetween Nvidia and Google, we visited [Rivian](https://www.linkedin.com/company/rivian), another totally different experience.\n\nAt Rivian we got a presentation on the EV industry, what the sorts of products they work on are, and an overview of the challenges they are facing and how they want to grow in the future.\n\nI found a few things neat about Rivian\n\n- The idea that you sell an \"experience\" with the car. This sort of \"buying into an experience\" idea is something I've come across a lot over recent years. I don't totally buy the value that turning conventional goods into \"experiences\" adds. But I understand the idea.\n- Their CI/CD process sounded very technically interesting. They're automatically pushing software updates to cars, so they have to have a pretty complex testing setup, and they talked about how they have stripped down hardware specifically for testing. I wish I could've asked more questions about their integration testing.\n- It's helpful to break down problems into specific concrete steps you can take to solve them.\n\nI wish we had more time to chat, but we were crunched on time since they had a relatively long technical presentation. I think that the most valuable insights have come from the loose conversations we've had during the trip.\n\nI'm still really curious how it's possible Rivian is able to maintain such low (negative) profit margins and operate at such a high loss, it seems like a dangerous recipe that surely must be intentional. It's an interesting stance on the side of the value of speed. The auto industry is definitely very capital intensive, and I feel like that fact can induce inefficiency.\n\n### Google\n\n![Google discussion](https://static.404wolf.com/20241025041749.png)\n\nAt first, I expected Google to share some resemblance with NVDIA. It's a massive company, with a ton of employees, and a ton of projects, too. They're both leaders in their industries.\n\nBut Google's really, really, different.\n\nJust as we walked in to Google, the aesthetic was extremely eccentric, with unique architecture and bright Google colors.\n\nWe met with [Gopi Kallayil](https://www.linkedin.com/in/gopikallayil/), chief business strategist and AI evangelist, and [TT Ramgopal](https://www.linkedin.com/in/ramgopal/), head of android relations.\n\nI was particularly excited to talk to TT about Android, but we were really crammed for time and I decided it best not to get bogged down in a super technical discussion. I'll have to reach out on linked in to begin the discussion on android devtools! My big takeaway from what TT had to say was how rampant competition is at all levels, even at the scales of Google; the importance of looking into the future to predict the battles of the future.\n\nGopi had a really great personality, and the passion you could feel he had was really incredible. He talked about Google AI, and how _vast_/general its potential may be. What's unique about Google is how broad their impact is, because of how massive their audience is. I think that's pretty cool.\n\nWhat Gopi said that I more personally resonate with, and I've now been much more conscious of is battling the tendency to complete other people's sentences. Not necessarily cutting people off, but overcoming the inclination to \"autocomplete\" people's train of thought, and then losing attention of the actual things they're communicating. To be honest, I definitely feel I sometimes tend to do this, and I think that being aware of it and more deeply listening is great general advice.\n\nI think one of the unique things about Google is how empowering the culture is. This is something that I've really never sensed to the degree I did at Google, and is probably why I know so many Recursers who were also ex-Googlers. It seems like Google encourages employees to ideate and explore beyond their specific area of work. There's some tangible ways that they mentioned they do this.\n\nI fear working at \"mega\" companies because I'm worried that I'll be trapped into doing work that I have little control over, and that my impact will be necessarily small in scope of the work that the company does, but Google seems to truly care about what areas you are interested in, so you can focus your energy on what matters.\n\n### Y-Combinator\n\n![Discussion](https://static.404wolf.com/20241025041821.png)\n![Space tour](https://static.404wolf.com/20241025041842.png)\n\nOn Tuesday, we visited Y Combinator and got to hear from [Pete Koomen](https://www.linkedin.com/in/petekoomen/) about his journey.\n\nPete was one of the original founders of [optimizely](https://www.optimizely.com), an A/B testing platform designed to be easy to use even for non developers to set up tests.\n\nThis is in a similar arena to the sorts of things I'm interested in, and I found it really interesting to hear about his journey. He was also inspired to start the company out of frustration with problems that he'd experienced as an engineer.\n\nWhat's cool about his role at YC is that he gets to experience working with a lot of different start ups all at once.\n\nSome themes were\n\n- What makes a good founder. Being very resourceful, learning things quickly, and never making the same mistake twice.\n- Running towards risk. Finding hard problems and solving them. This isn't necessarily required for success, but it seems to enable much vaster success.\n- Try to find customers as early as possible. Sean at Fountain also noted this, and I definitely see the value.\n\nI agreed with most of what he had to say. There's a pattern I've seen throughout the trip on how heavily to fund ventures. There seems to not be a clear cut answer -- some people, perhaps particularly YC, feel that it's important for there to be an aspect of scarcity; by not having huge amounts of funding you use what you have much more efficiently. On the other hand, companies like Rivian take a totally opposite approach, and raise substantial amounts of money to try to grow very quickly. My thought is that you _can_ put a price on speed, but sometimes it's not a price worth paying.\n\n### Giant\n\n![John @ Giant](https://static.404wolf.com/https://static.404wolf.com/VealeSnyderReflection-20241025172611110.webp)\n\nFinally, we met with [John Kobs](https://www.linkedin.com/in/johndkobs/). At most of the places that we visited, we would give brief 2 minute introductions about ourselves, but with John, he told us to \"talk about our most recent failure.\"\n\nI found this meaningful, because it got us to _think_ about why we failed and how we could prevent it from happening again. Being conscientious about it seemed key. I recalled how a few weeks ago I feel I did poorly in a Go debugging interview because I entered it with the wrong mindset and didn't fully _analyze the situation_: they wanted to see how I understood the adjacent concept to the thing I was debugging, but I was laser focused on getting the test to pass.\n\nHe went on to lead an extremely insightful Q\\&A.\n\nThe biggest takeaways:\n\n- Learning from mistakes. Never making the same mistake twice seems like a generally good piece of advice.\n- Recognizing bottlenecks, but transitioning carefull. He created what became Apartments List. He talked about how he saw how being an aggregator of aggregators was a bottleneck to scale, and how they needed to pivot to work with brokers themselves. This pivot initially was extremely painful, beyond expectation.\n- Being open. This is something that came up at Google too. Instead of being overly prescriptive, listening to others and thinking through things without the underlying assumption that there's nothing left to figure out or learn.\n\n## Chats\n\nThere were two networking events during the trip. There, there were a bunch of Case alums and people affiliated with Case.\n\nDuring the second event, I got to speak to [Donald Knuth](https://en.wikipedia.org/wiki/Donald_Knuth) himself; the creator of Tex and writer of 30+ books, including _The Art Of Computer Programming_. The chat reminded me a bit of some interviews with Linux Turvals that I watched a few years back. There's the debate between whether the right way to delve into CS is top down or bottom up; whether to start with high level languages and the ergonomics of abstraction, or to jump into registers, boolean algebra, and C. I personally don't think that it's a one size fits all topic, but Donald talked about how he think's its imperative that you learn how things work, and how abstractions can quickly become very dangerous. I think there's value to that train of thought. By the time I got to ask him about his thoughts on [typst](http://typst.app), a Tex competitor, it was clear what his opinion would be -- its ergonomics are a dangerous disguise. But I think it's fine for the application. Another really important topic was writing -- we both agree that it's really important to write about what you do and think. This includes non technical writing, like this post!\n\nIn the second networking session of the trip, I got to chat with [Stephen Hahn](https://www.linkedin.com/in/schahn/). We had some great technical conversation, and he talked about how he'd avoided tool related start ups (probably my most specific interest). When I asked why, it was pretty straightforward: it's hard to sell tools. Big companies will often release them for free and crush you, or it is just technically difficult to provide them in a way that requires payment. My interest is in bridging fullstack with developer tooling, and he seemed to agree that the idea of web based tooling is an interesting new category that may enable tooling related startups that may previously not have been possible.\n\nI had a ton of other really great chats, and I'll try to post some more reflections here over the next few days.\n\n# Reflections\n\n![](https://static.404wolf.com/https://static.404wolf.com/VealeSnyderReflection-20241025150445254.webp)\n\nThroughout the trip, I really felt the value of time. Being able to pack questions into such short sessions, and make meaningful connections with the execs and engineers that we met, seemed almost impossible. Time in general seems like one of the biggest limiting factors, and in general I tend to agree with Sean in how vital efficiency is.\n\nOne important insight was how it's important to be able to adapt to and embrace change rapidly. Speed is imperative, but sometimes overpriced. Efficiency is important too. There's a lingering question of how important it is to balance speed and quality, and being careful not to over complicate things (something I, and other engineers are particularly vulnerable to), is something I want to be more attentive to.\n\n\"Good\" culture seems like it can make or break a company, but it can often be largely immutable. Some companies value efficiency, some intellectual honesty, some curiosity, etc. I really liked the culture [Google](https://www.linkedin.com/feed/#) was targeting in particular; even in such a large company, they care that you contribute to specific things you care about. The power of \"passion\" for your work is massive.\n\nAlso, being open-minded and carefully considering others' ideas is always important. Specifically, deeply considering everyone's ideas, and, in the context of startups, close contact with clients. I found [Sean Behr](https://www.linkedin.com/feed/#)'s thoughts on the danger of data abstraction inspiring -- charts and summaries can mask critical insights; anecdotes are often most valuable.\n\nThe trip also placed a huge emphasis on the power of networking. I think sometimes networking takes on too formal a connotation -- but really, it's all about meeting and then staying in touch with an ever increasing amount of awesome, interesting people. I've always found that the most powerful \"network\" links are bidirectional, and in that way it's like making friends.\n\nMichael Goldberg is a big proponent of LinkedIn as a powerful networking tool, and it's absolutely true that I'll be able to stay in touch with a lot of the people that I met over the trip there. It's a really great tool. But I think there's a pretty significant personal aspect that's lost. It's an amazing tool to connect with and organize a network. But I think that LinkedIn is, perhaps reasonably so, somewhat superficial. It feels a bit out of place to post a real, thoughtful digest of things like this trip, in the form of a LinkedIn post, because of the context that it's placed in. Hopefully my insights here are useful and interesting. I'd love to chat further if you have any additional comments or thoughts! Email me at wolf@404wolf.com, or 212/767/9653.\n\nI cannot thank [CWRU Veale Institute for Entrepreneurship](https://www.linkedin.com/feed/#), [Michael Goldberg](https://www.linkedin.com/feed/#), [Stacey Lotz](https://www.linkedin.com/feed/#), and many others enough for making this opportunity possible! I've learned a ton, met so many interesting people, and have got to further connect with the other fellows!\n\n# Czech Republic Trip\n\n![Brno](https://static.404wolf.com/4be0999f-0483-4679-b0e1-dfb7c02451b6.webp)\n![Brno](https://static.404wolf.com/dc7621e3-95f4-4750-bfe0-4d785749bdc7.webp)\n![Kuku clock](https://static.404wolf.com/4a54acd9-f393-434b-aa38-75a90752fb59.webp)\n![Castle](https://static.404wolf.com/https://static.404wolf.com/c567ad77-0fbe-499a-b056-1d7c11159967.webp)\n\nThe second major part of the Veale Snyder fellowship is an international trip, with the same group as the first trip. For my year, we visited the Czech Republic (including a day in Austria)! We went on a lot of walking tours -- of Vienna, Brono, and Prague. It was in some ways a really unique and different experience, but in others bared many similarities to places in the US.\n\nWe went to Brno because our professor thought that Brno has various similarities to Cleveland. I think this is true in some ways, but I wouldn't really draw the comparison. I didn't find Brno very dense, it felt somewhat like busier towns in NJ -- not really a city, but also not really suburban. My favorite part of the trip was definitely visiting Prague, I think it bore many more similarities to NYC than Cleveland to Brno.\n\nThe second half of the program is lead by Michael Hill, former Medtronic CTO. What I like about Michael is that all of his advice is very practical, and his answers and thoughts are very to the point. Michael's shared a lot of insights, but there's some that particularly have stood out to me\n\n- During one of our lunches Michael talked about his decision to stay at Medtronic so long (almost 30 years!), and it boiled down to loving your boss, and aligning with your companies interests. These things sound obvious, and I agree with them -- but it is powerful to be able to pinpoint it directly.\n- It's really important to keep focused: on a specific audience, on your company's trajectory, mission, etc. Being clear and strategic is critical to success.\n\n## What makes an Innovator?\n\nThe Veale Snyder program for the second half of the semester is taught as a 3 credit course. The course Syllabus leaves a few ongoing questions for us to think about:\n\n1. What is innovation? What does it mean to be an innovator?\n2. What is entrepreneurship? What does it mean to be an entrepreneur?\n3. What is a \"value proposition\" and why does it matter?\n4. What mindset, skills, and tools are required for success in innovation (to be an entrepreneur)?\n\nAnd then, after our trip, asks us to reflect on the first question, \"What makes an innovator?\"\n\nIt's a subjective, multifaceted question. So here's the evolution of my thoughts on it--\n\nBefore the trip, we read _The Medici Effect_: \"what elephants and epidemics can teach us about innovation.\" I'd say it sums up pretty easily:\n\n- The _Intersection_ is a unique space that's created only when people of diverse backgrounds and interests, are brought together over a thread of commonality.\n- When you have an _Intersection_, you can achieve _The Medici Effect_. _The Medici Effect_ is named after the Medici family from Florence, a wealthy banking family who played a significant role in funding the Renaissance by funding a large variety of very different creative artisans. It describes the big results you can get by fostering *Intersection*s.\n\nWe also read _The Innovator Mindset_\nSome takeaways:\n\n- All products have target customers, and the target customer is never \"everyone.\" Identifying the people you're serving is critical to success.\n\n> Innovation is about people and their assumptions and subconscious thought patterns (a.k.a. their mindset) and their daily actions and habits that stem from that mindset (a.k.a. their behavior). Put all those together, add some procedures, rewards and penalties, social dynamics, unspoken rules—and a pinch of stress—and you get a wonderfully messy, organic, and complex environment. An environment in which behavior, not lip service (although words are also important), drives the results. If you fail to address that daily behavior, even the greatest strategy and plan to drive innovation are doomed to fail.\n\n[Recurse Center](https://recurse.com) for me has one of the most impactful experiences of my life because, I think, of how it neatly conforms to the _Medici Effect_'s _Intersection_. The entire RC space is a carefully curated environment of serendipity and diversity. Theres a large variety of people from all different backgrounds. I've done pair programming with ML engineers, Art Historians, quant developers, and more. And, there's a closed space where everyone is packed together. This exposes you to so many different projects and thought processes; when directly pair programming with people, during lunch discussions, or group meetings.\n\nCreating a space of innovation to drive entrepreneurship I think requires a lot of similar components, which Czechia is trying to cultivate. It's a difficult process, though, because, as we've talked about a lot in our class, mindset is one of the most important factors. You can have a very accessible entrepreneurial environment (creating serendipity, providing spaces and resources, general access to funding, etc), which is one side of the puzzle and something that they haven't nailed yet, but there's also a component of convincing people that it's worth it in the first place. If people are content with work, like what they do, and are happy with where the amount they earn gets them, it is difficult to convince them to channel their ideas into startups -- it's a risk that people aren't internally justifying taking.\n\n### BIT Entrepreneurial Panel\n\nA panel of speakers answering the question \"Does Brno region need an Entrepreneurial Ecosystem?\"\n\nAt first, I'd thought that this was a rhetorical question, but the more we focused on it the more it seems that it's really a matter goals. When asked why Brno might want Entrepreneurship, the answer seemed to mostly be about freedom and self dependence, largely aligned with American values. The appeal seems to be largely that entrepreneurship can provide the city with more security and independence. Brno's economy and workforce is largely dependent on electron microscopes. We toured ThermoFisher Scientific's manufacturing facility, and the level of sophistication and and intelligence there is really incredible. ThermoFisher makes up a disproportionate share of Brno's GDP, and so it makes sense that they would want to foster entrepreneurship to diversify.\n\nDuring the trip we got to interact with some local students at BUT's entrepreeneurship school, and got to speak with them about what their educational experience has been. We also visited BUT's maker lab, and Strojlab, their maker space. Czech academics seems much more rigid -- there's much less time spent outside of classes, and there's not real choice over the classes you take. There's a lot of similar factors--Brno is somewhat of a \"college town,\" with about 20% of the population being students, and apparently it was common that students would go home for the weekend. I think this more traditional style of instruction provides more consistency, but that that's not necessarily a good thing.\n\nWe also visited Charles University, to learn about how they support entrepreneurship, and it seemed their focus was also largely environment, and their approaches were also more traditional; a lot of importance was placed on creating serendipitous spaces, networking opportunities, and preserving a specific reputation/brand. The difficulty seemed similar to that of many of the other places we visited: trying to motivate students to actually care about entrepreneurship. It seemed like a lot of people were more focused on academics for the sake of academics and thought of vocation interests as just that -- the students we spoke to had interesting ideas and were very interesting to learn from, but I felt they had a less clear sense of their \"passion\"s, and were more focused on *path*s.\n\n### Czech Invest\n\nDuring our trip, we went to a \"Czech Invest\" presentation at [The American Center](https://www.americkecentrum.cz/en/) at the US embassy. My takeaways:\n\n- There's a lot of legal challenges that Czech startups face. You can't really pay people in equity, and there's weird unfavorable tax intensives\n- Entrepreneurship isn't something baked into the culture, and it's not really taught very often (although that seems like it's slowly changing) (and, adding on, change in general seems relatively slow)\n- The intensives are placed in ways that are more favorable to larger businesses and less so to start ups\n- One big inhibitor seems like the \"failure is bad\" mindset. People don't want to make mistakes, so they don't take as many risks. Growing up, I've always been told to make mistakes to learn from them, but I don't think that's something that's stressed in Czechia.\n\n### JIC Entrepreneurship Center\n\n![](https://static.404wolf.com/VealeSnyderReflection20250328021818169.webp)\n\nAt JIC we met Czech entrepreneur Libor Horeni who shared his experiences with us. He talked about starting with his first company [Top Recepty.cz](http://toprecepty.cz/), sharing how he was inspired to create the website while in high school, from looking through most visited websites in Czechia and trying to find areas where he could make improvements. He found a recipe sharing website that got a huge amount of traffic, and thought that he could recreate it better. After Top Recepty, he talked about a company like (America's) Too Good to Go -- a company that reduces food waste by connecting restaurants with customers to pick up their leftover food at a greatly reduced cost at the end of the day.\n\nWhat I think made Libor such an effective entrepreneur was not just his true passion for what he does -- he admitted that he doesn't really cook himself -- but the process. It seems like there's a lot of different factors that draw people to entrepreneurship, and it can vary a lot person to person. In SF, it seemed like the primary motivators were value creation, and money. But in Czechia it was quite different -- in general the people innovating were more concerned on the common good and improving their community, going down paths that they wanted to go down. I get the sense that many less \"I have no idea where to start\" product ideas come to fruition because people want to reapply what they do to new contexts for different reasons.\n\nThis is certainty not a _bad_ thing per se, but it fosters a different type of entrepreneurship. Libor talked about how in growing Top Recepty, he reached out to a lot of Czech grandmothers, trying to curate blog posts; he talked about how he got companies to sponsor him with pots to give away for competitions to grow his platform. Here, I don't think people would feel the need to ask for permission to repost recipes, and people would be more inclined to pursue more direct forms of marketing.\n\nHis general model seemed to be to find existing products, and refine them to compete, leveraging their niche market in Czechia. That strategy seemed very effective in Czechia, but I feel that in the US that there's not many _tech_ ideas left to pull in from abroad and refine, and that most of the products we already have already are well refined; more importance is placed on original ideas.\n\n![Entrepreneurship Roundtable](https://static.404wolf.com/https://static.404wolf.com/e23c532d-7d7a-4203-aeb6-dd08b8733fb5.webp)\n\nWe had a roundtable event at Brno University of Tech (BUT) with Michael Goldberg and a a variety of experts on whether and why the South Moravian region needs more entrepreneurship. I love playing devils advocate, and I was curious at trying to grasp exactly why all of these experts seemed to agree that the answer was yes\n\n- America is often idolized for entrepreneurial success, and it seems like this strongly affects entrepreneurial sentiment abroad. they seemed to have a strong association between entrepreneurship and _freedom_. There's a fear that in Czechia (and even more so Europe as a whole), people are significantly more dependent on the government than in the US. One of the perks that Czechia officials consistently mentioned is the general political and economic stability of the country. By fostering entrepreneurship, Czechia fosters more self sufficiency.\n\nI think it's important to note though, that, while it does seem like Czechia struggles to foster an environment that can cultivate entrepreneurial mindsets and actually produce global startups, I don't that needs to be a \"bad\" thing; it just isn't a primary focus. Prague was still a beautiful and very energetic (and historical) city with what felt like more of an industrial focus than, say, NYC. In lue of the massive entrepreneurial focus of big US cities, there was more of a focus on everyday quality of life.","src/posts/VealeSnyderReflection.mdx","9924d78a2a2185b8","whirlwindtourofnix",{"id":288,"data":290,"body":296,"filePath":297,"digest":298,"deferredRender":26},{"title":291,"type":9,"date":16,"covers":292,"tags":294,"description":295},"Tour of Nix",[293],"https://static.404wolf.com/52042908-6c60-4f88-9880-22b486c7242c_0001.png",[35],"An introduction to Nix and its ecosystem. The basics of Nix as a language, its use as a package manager, build tool, and much more. Some brief discussion of core concepts like derivations and flakes, and a walkthrough of simple examples packaging programs. Learn how Nix can help create reproducible builds and consistent development environments, and do fun things like allow bash scripting with any binary, or making pure latex documents. Post is still in progress.\n","Okay, before we get started:\n\nNO, NIX IS NOT JUST AN OPERATING SYSTEM. I'm going to talk about what it is and what you can use it for, but `nixos` is merely a project that uses the `nix` language/tooling. You do not need to even use `linux` to use `nix`. Okay, now that we have that out of the way let's get started.\n\n# Why Nix?\n\nBefore even grappling with what it is, I think it's good to understand what it can do. Some awesome things that nix does:\n\n- Consistent developer environments that are decoratively specified. This means everyone working on a project can have the same LSP, binaries in their $PATH, etc.\n- Pure, reproducible project builds. Nix \"wraps\" onto tooling you already use for builds, and does the build in a sandbox. This means that there's no internet access, the time is set to `0` (UTC) (which means things like Latex \"builds\", which inject timestamps, will be reproducible too!), and more.\n- Let you configure your home directory using a project called \"home manager.\" You can specify how to set up various programs and their configurations fully declarativly with `nix` code.\n- Create very minimal docker images, that don't have a `FROM` (that are `FROM SCRATCH`), and only have exactly the things you need to dockerize your project.\n- Get an android emulator going in 4 lines of code.\n  And a million other things.\n\nWhere nix really shines is reproduability. If it works once, it will probably work again.\n\n# Some Terms\n\nWhat is **purity?**\nPurity just means when you put X, Y, and Z in, you'll get W out. If you put X, Y, and Z in two weeks later, on a Mac, in a different time zone, you'll get W out. If you install a different C compiler, you'll still get W out. Nix can guarantee that your builds are pure.\n\nWhat is **lazy**?\nLazy just means that the language won't try to evaluate anything it does not absolutely need to evaluate. If you import every package in existence, `nixpkgs`, `nix` will not literally build everything. But if you reference `foobar` from `nixpkgs` then it will build it.\n\n# What is [Nix](https://nixos.org/)?\n\nThe question with so many answers. Nix is at least 4 totally different things.\n\n![So many nix packages!](map_repo_size_fresh_0001.svg)\n\n1. It's a programming language. It's functional, lazy, and can be pure. You can do basic things like `{ a, b }: a + b`! You can also use it to do more advanced tasks like mapping over arrays or attrsets (dictionaries), and everything you'd want from a programming language.\n2. It's a [package manager](https://search.nixos.org/)! The nix repository has more packages than any other package manager (`apt`, `pacman`, etc), and more fresh (new) packages too! All the packages are not actual binary blobs, but `nix` code (remember, it's a language!) that defines build instructions for producing `derivations` (more on this later) containing over 100k different projects. This even includes pure build instructions for things like building `chrome` from source and packaged patched binaries like jetbrains IDEs (ikk). Your packages are all nicely managed in a `nix store`, again, more on this later.\n3. It's a utility library. `nixpkgs` is a library that contains a bunch of utilities that let you do super cool things, like defining pure builds for minimal `FROM SCRATCH` docker images. It fixes all the bloat of `docker`!\n4. It's an operating system. Because it gives you so much power in specifying an exact state of a build output (a \"derivation\"), people have used it to create [nixos](https://nixos.org/). NixOS is a completely decoratively specified Linux distribution where your entire computer configuration lies in `.nix` text files. I have configured my computer this way, and, though it was a long process, the declarativity/reproducitivity is really nice.\n\n# Derivations\n\n### The \"nix store\"\n\nThere is this thing called the \"nix store\". It's just a directory that's read only, usually at `/nix/store`. You can write nix code, using the `derivation` keyword, to create them, but that's very low level. I'll let you read more about them [here](https://nixos.org/guides/nix-pills/06-our-first-derivation), but in this post we'll just use `pkgs.stdenv.mkDerivation`, along with trivial builders like `pkgs.writeShellScriptBin`. They are handy helper functions from the `nixpkgs` utilities (remember when I said nix was a utility library!). Everything in the `nixpkgs` registry outputs derivations. These \"derivations\" are resulting directories in this \"nix store\", that look like `«derivation /nix/store/z3hhlxbckx4g3n9sw91nnvlkjvyw754p-myname.drv»` -- they are just subdirectories of the store. The outputs are read only because they are in the store, and we know that everything that made its way to the store did so in a way that was pure.\n\nIf you're interested in how derivations actually work, there's some intermediate steps, including producing a `drv` file with instructions to nix on how to create it. But I'm going to skip over that.\n\n## Flakes\n\nFlakes are really just entrypoints. The older way to do things with `nix` was to use channels. I don't want to go too far into those, since they are lame (sorry, it's true), but basically, they are global references to sources. They'd let you specify internet inputs to projects with `\u003C>` syntax:\n\n```nix\n{ pkgs ? import \u003Cnixpkgs> { }, }:\n...\n```\n\nWhere we by default get `nixpkgs` from the global \"channel\" (iickk)! That's im**pure**. What if nix decides to update their `unstable` branch (nixpkgs is just a git repo!) and your package references break?\n\nSo from this point on I'm going to pretend channels don't exist, and completely stop using them (mostly). Flakes are nix's solution to the problem. They guarantee real purity.\n\nA flake has this basic structure:\n\n```nix\n# flake.nix\n{\n  inputs = {}; # Specify inputs with URIs\n  outputs = {self, ...}: {}; # A function!\n}\n```\n\nIt lives in a `flake.nix`\n\nWhere we usually make inputs at least have `nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";`, the nix package registry, with all the packages we may ever want. `self` is a reference to the project at its previous commit, and flakes require you to use version control to ensure purity of file inputs.\n\nYou might be thinking, \"hey, `github:nixos/nixpkgs/nixos-unstable` doesn't sound very pure!\" True. `flakes` generate lockfiles with reversions and `sha256` hashes. When we run `nix flake lock` we get something like this.\n\n```json\n// flake.lock\n{\n  \"nodes\": {\n    \"nixpkgs\": {\n      \"locked\": {\n        \"lastModified\": 1719690277,\n        \"narHash\": \"sha256-0xSej1g7eP2kaUF+JQp8jdyNmpmCJKRpO12mKl/36Kc=\",\n        \"owner\": \"NixOS\",\n        \"repo\": \"nixpkgs\",\n        \"rev\": \"2741b4b489b55df32afac57bc4bfd220e8bf617e\",\n        \"type\": \"github\"\n      },\n      \"original\": {\n        \"owner\": \"NixOS\",\n        \"ref\": \"nixos-unstable\",\n        \"repo\": \"nixpkgs\",\n        \"type\": \"github\"\n      }\n    },\n  \"root\": \"root\",\n  \"version\": 7\n}\n```\n\nFlakes let us define ways to get to derivation (the things that \"build their way into\" the nix store).\n\n### A C hello world\n\nA grain of salt: I don't do much C. But I'm going to kick off this section with a C hello world, specifically because C is pretty easy to compile, and has a _build time_ requirement: a compiler like `gcc`.\n\nThis is a bit boring, but the way we package this will be helpful for some more fun stuff later.\n\nFirst, we make a `hello.c` with a hello world...\n\n```c\n#include \u003Cstdio.h>\n\nint main() {\n  printf(\"Hello, World!\\n\");\n  return 0;\n}\n```\n\nOkay, we've created the hello world. Now time to define the build with `nix`.\n\nTo start, a tiny bit more on flakes.\n\nWith flakes, there's some special `outputs` that `nix` will look for.\n\n- `packages.${system}.default`\n  - If we're running linux (this works on mac too though), this might be `packages.x86_64-linux.default`. This is basically the \"default\" thing that gets build when we do `nix build`, but if we specify something else, like `packages.${system}.foobar`, then we can build the derivation with the `nix` cli using `nix build .#foobar` instead.\n\nThis means that a flake often will look something like\n\n```nix\n{\n  inputs = { ... };\n  outputs = { self, ... }:\n    {\n      packages.x86_64-linux = {\n        default = pkgs.writeShellScriptBin \"hello\" \"echo 'hello!'\"\n      };\n    };\n}\n```\n\nHaving to define an export for every system when our project isn't really system specific is annoying, so nixers often use something called `flake-utils`, which provides a helpful `eachDefaultSystem` utility to generate the different outputs for different systems for us. Nix is `lazy`, so it'll only build for the system we need to build for when we run `nix build`.\n\n```nix\n...\n  outputs =\n    {\n      self,\n      nixpkgs,\n      flake-utils,\n    }:\n    flake-utils.lib.eachDefaultSystem (\n      system:\n      let\n        pkgs = import nixpkgs { inherit system; };\n      in\n      {\n        packages = {\n          default = # (The derivation / builder)\n        };\n...\n```\n\n`eachDefaultSystem` is a function that intakes a function that takes an argument `system`, that outputs the regular outputs based on it, and then provides outputs for all systems supported by nix (but only evaluates when you need to).\n\nReturning to our `C` hello world, we will use a helper function called `pkgs.stdenv.mkDerivation`. `nix` ships with a `derivation` keyword, but that takes a binary that expects to make the derivation, and is super raw. This helper will do a lot of the heavy lifting by breaking things up into stages -- the `unpack phase`, `build phase`, and `install phase` (and a ton others -- see [here](https://nixos.org/manual/nixpkgs/stable/#sec-stdenv-phases)).\n\n`buildInputs` specifies what should be available in the path of our builder's environment. We can use `nativeBuildInputs` since our `buildInputs` are only needed during building -- native implies that the program itself doesn't need them.\n\n#### The Sandbox\n\nAll `nix` builds happen in a special sandbox. The `src` argument specifies what should exist in the sandbox. We need to move the source code over!\n\nThe `sandbox` does a lot to ensure that we are declarative and the output is **pure**.\n\n> When sandbox builds are enabled, Nix will set up an isolated environment for each build process by constraining build inputs to improve reproducibility.\n\n> It is achieved by isolating build jobs from input sources whose contents are prone to change dynamically and without notice. For example, the main file system hierarchy is completely bypassed to prevent depending on files in global directories, such as `/usr/bin`, where a reference to an executable may point to different version as time goes by.\n\nAlso, it does things like disallow networking and sets the timestamp to UNIX 0 (even time is dynamic and could lead to impurity!).\n\nOkay. So let's look at the `flake`...\n\n```nix\n{\n  description = \"C Hello world\";\n\n  inputs = {\n    flake-utils.url = \"github:numtide/flake-utils\";\n    nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";\n  };\n\n  outputs =\n    {\n      self,\n      nixpkgs,\n      flake-utils,\n    }:\n    flake-utils.lib.eachDefaultSystem ( system:\n      let\n        pkgs = import nixpkgs { inherit system; };\n      in\n      {\n        packages.default = pkgs.stdenv.mkDerivation {\n          pname = \"hello\";\n          version = \"1.0\";\n          src = self; # code at the last commit\n          nativeBuildInputs = [ pkgs.gcc ];\n          buildPhase = ''\n            gcc -o hello ./hello.c\n          '';\n          installPhase = ''\n            mkdir -p $out/bin\n            cp hello $out/bin\n          '';\n        };\n      }\n    );\n}\n```\n\nWe're not quite ready. Remember when I said that we need to use version control to help our flakes guarantee purity?\n\n```bash\ngit init\ngit add *.c *.nix\ngit commit -m \"Initial commit\"\n```\n\nOkay, finally we can build and run it with nix.\n\n```\nnix run\n# OR\nnix build && ./result/bin/hello\n```\n\nAnd we get a \"hello world\"!\n\n`pkgs.stdenv.mkDerivation` resolves to a string (that's right, a piece of text). It's a path to a result in the nix store. `nix build` helps us out by making a symlinked folder `./result` that directs to that directory in the nix store (that is read only, because it's in the nix store).\n\nOkay, enough boring hello worlds in C nonsense. Here's something fun -- binary runtime dependencies, and Python!\n\n### A simple Python Script\n\nLet's consider a simple Python script that uses selenium to navigate to `https://example.com`. Usually this would be a little annoying since there's a dependency on `chrome` and `chromedriver`, but we can bundle those things with `nix` pretty easily.\n\nHere's our basic script that goes to `example.com` and yoinks the tab's title, printing it to `stdout`.\n\n```py\n#./main.py\n\nfrom selenium import webdriver\n\nif __name__ == \"__main__\":\n  driver = webdriver.Chrome()\n  driver.get('https://example.com')\n  print(driver.title)\n  driver.quit()\n```\n\nHere we have one dependency, `selenium`, and two secret ones, `chromedriver`, and `chromium`. Usually, we'd do something like\n\n```cmd\nsudo apt-get install chromium-browser\nsudo apt-get install chromium-chromedriver\n```\n\nGod forbid we're on Windows, and it's so much worse. We might have to add\n\n```py\noptions = webdriver.ChromeOptions()\noptions.binary_location = '/usr/bin/chromium-browser'\n```\n\nSo let's package it with `nix`, which will work on ALL systems (including native macos, and windows with wsl)...\n\nI have a collection of [Project Templates](https://github.com/404Wolf/Project-templates) for various different languages that use popular nix tools to create derivations for projects. I'm using [Cookiecutter](https://cookiecutter.readthedocs.io/), which is a bit of an aside, but lets you template entire projects using [Jinja](https://jinja.palletsprojects.com/en/3.1.x/), so you can specify what a \"directory\" of a, say, Python project would look like. We're going to use my python script template here, which you can get at that repo if you want, but we'll build up to it slowly.\n\n#### pkgs.writeShellScriptBin\n\n`writeShellScriptBin` is a nice little helper function\n\nIt is so simple, [here's the source code](https://github.com/NixOS/nixpkgs/blob/36e813a7630ff1bde9f6baa82757fabfbeb6e95c/pkgs/build-support/trivial-builders/default.nix#L169)...\n\n```nix\nwriteShellScriptBin = name: text:\n  writeTextFile {\n    inherit name;\n    executable = true;\n    destination = \"/bin/${name}\";\n    text = ''\n      #!${runtimeShell}\n      ${text}\n    '';\n    checkPhase = ''\n      ${stdenv.shellDryRun} \"$target\"\n    '';\n    meta.mainProgram = name;\n  };\n```\n\nruntimeShell is just `/nix/store/blahblahShaHashblahblah/bin/bash`. It literally just makes an executable bash script.\n\nOkay, so let's use it to package our `python` program...\n\nWe'll first write a `bash` script, that's roughly similar to what we want at the end of the day, but without binary dependencies\n\n```bash\nexport PATH=$PATH:${pkgs.chromedriver}/bin:${pkgs.ungoogled-chromium}/bin;\nexport PYTHONPATH= ???\n${python}/bin/python3 main.py\n```\n\nSomething like that. `nix` can handle the `python` packages for us. I'm not going to go too far into that for now. Notice the `python3.withPackages`. Most popular packages are already packaged with `nix`, and it's not hard to package ones that aren't (usually, some require messy runtime deps).\n\n```nix\n{\n  description = \"Some python script\";\n\n  inputs = {\n    flake-utils.url = \"github:numtide/flake-utils\";\n    nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";\n  };\n\n  outputs =\n    {\n      self,\n      nixpkgs,\n      flake-utils,\n    }:\n    flake-utils.lib.eachDefaultSystem (\n      system:\n      let\n        pkgs = import nixpkgs { inherit system; };\n        python = pkgs.python3.withPackages (python-pkgs: [ python-pkgs.selenium ]);\n      in\n      {\n        packages = {\n          default =\n            pkgs.writeShellScriptBin \"main\" /* bash */ # (treesitter directive)\n              ''\n                export PATH=$PATH:${pkgs.chromedriver}/bin:${pkgs.ungoogled-chromium}/bin;\n                ${python}/bin/python3 main.py\n              '';\n        };\n      }\n    );\n}\n```\n\nRemember to `git init`, `git add` and `git commit` (I didn't say this before, but commiting isn't actually necessary, if you don't `nix` will still build but complain that your codebase is dirty. Okay, now we're ready.\n\n```\nnix run\n```\n\nIt works! Chromedriver should open up, the tab should load `example.com`, and then it should grab the tab name and close.\n\n![It works!](https://static.404wolf.com/https://static.404wolf.com/Post-20240713170649585.webp)\n\nThis still is slightly impure (although, I should note that `nix` guarantees pure builds, not pure executions, so we may never be able to be 100% sure that the program will _run_ the same way) though because we're appending to our $PATH, which means that we're expecting things to exist in our PATH that may not. I'd like to avoid \"generating\" bash scripts, so instead I'm going to use a utility called `wrapProgram` to set the PATH to whatever we have at build time as our path, which has the necessary deps and is pure (because of nix), and only run the python script with a bash script (to make it executable -- we could use a python shebang too).\n\nHere's what that would look like...\n\n```nix\n{\n  description = \"Python with Selenium example\";\n\n  inputs = {\n    flake-utils.url = \"github:numtide/flake-utils\";\n    nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";\n  };\n\n  outputs =\n    {\n      self,\n      nixpkgs,\n      flake-utils,\n    }:\n    flake-utils.lib.eachDefaultSystem (\n      system:\n      let\n        pkgs = import nixpkgs { inherit system; };\n        python = pkgs.python3.withPackages (python-pkgs: [ python-pkgs.selenium ]);\n      in\n      {\n        packages = rec {\n          default = pkgs.stdenv.mkDerivation {\n            name = \"main\";\n            src = self;\n            dontUnpack = true;\n            buildInputs = [ pkgs.makeWrapper ];\n            installPhase = ''\n              mkdir -p $out/bin\n              cp ${script}/bin/* $out/bin\n            '';\n            postFixup = ''\n              wrapProgram $out/bin/main \\\n                --set PATH $PATH:${\n                  pkgs.lib.makeBinPath [\n                    pkgs.chromedriver\n                    pkgs.ungoogled-chromium\n                  ]\n                }\n            '';\n          };\n          script = pkgs.writeShellScriptBin \"main\" \"${python}/bin/python3 main.py\";\n        };\n      }\n    );\n}\n```\n\n### Bash scripts with ANY binary!\n\nIf we're okay with only kinda-pure stuff though, generating bash scripts is really fun with nix. We can write a script using literally any dependency we want.\n\nI'll provide a neat script I made to take screenshots of regions of my screen.\n\nUsually it'd look like this...\n\n```bash\nFILEPATH=/tmp/$(uuidgen)\ngrim -g \"$($slurp)\" \"https://static.404wolf.com/$FILEPATH.png\"\nwl-copy --type \"text/uri-list\" \"https://static.404wolf.com/file://$FILEPATH.png\"\nnotify-send \"Successfully saved screen capture!\" \"The png has been saved to $FILEPATH\"\n```\n\nBut that means I'd need to add `grim` (a utility to select a region of your screen on Wayland), `wl-copy` (a Wayland clipboard cli utility), and `notify-send` (a notification daemon connector cli) to my global $PATH. That's gross, and not nixy at all. What if I want 50 more random binary dependencies? If you say that's a bad idea, it's probably because you don't want to have to have people install so many things to their global `/usr/bin` to install it.\n\nI really like this paradigm my friend Trevor showed me...\n\n```nix\npartial-screenshot = pkgs.writeShellScriptBin \"partial-screenshot.sh\" ''\n  slurp=${pkgs.slurp}/bin/slurp;\n  grim=${pkgs.grim}/bin/grim;\n  wl_copy=${pkgs.wl-clipboard}/bin/wl-copy;\n  notify=${pkgs.libnotify}/bin/notify-send;\n  ${builtins.readFile ./scripts/partial-screenshot.sh}\n'';\n```\n\nThe various binary dependencies will resolve to their `nix store` paths, and since nix is lazily evaluated we can use ANY binary, and it will poof into existence at the right store path at build time. `builtins.readFile` will then inject our regular bash script that uses the stuff...\n\n```bash\nFILEPATH=/tmp/$(uuidgen)\n$grim -g \"$($slurp)\" \"https://static.404wolf.com/$FILEPATH.png\"\n$wl_copy --type \"text/uri-list\" \"https://static.404wolf.com/file://$FILEPATH.png\"\n$notify \"Successfully saved screen capture!\" \"The png has been saved to $FILEPATH\"\n```\n\nAnd if we do a `nix build`, we'll get\n\n```bash\n#!/nix/store/agkxax48k35wdmkhmmija2i2sxg8i7ny-bash-5.2p26/bin/bash\nslurp=/nix/store/hfii9xxi8vwmlq86vh2j9dl73zzy7s1w-slurp-1.5.0/bin/slurp;\ngrim=/nix/store/jkv33a361c8nlgp2kcx1azncipxdn4nh-grim-1.4.1/bin/grim;\nwl_copy=/nix/store/18rwzxp6m29m8c5bxgpxci1ad1q4kl94-wl-clipboard-2.2.1/bin/wl-copy;\nnotify=/nix/store/w141cbf1p9mcyp7vqv6a4fw4hm093qb5-libnotify-0.8.3/bin/notify-send;\nFILEPATH=/tmp/$(uuidgen)\n$grim -g \"$($slurp)\" \"https://static.404wolf.com/$FILEPATH.png\"\n$wl_copy --type \"text/uri-list\" \"https://static.404wolf.com/file://$FILEPATH.png\"\n$notify \"Successfully saved screen capture!\" \"The png has been saved to $FILEPATH\"\n```\n\nA nice, executable script, with absolute references to packages that are NOT in our path. This is one of my favorite nix things to do.\n\n## Reproducible Developer Environments\n\nAnother nice thing `nix` can do is let you create developer environments very easily. You use `pkgs.mkShell`, which creates a derivation (remember those still?), and then enters the environment of the derivation.\n\nYou can specify `buildInputs` (although you should use `packages`) to add all the things you'd want for developing the project.\n\n```nix\ndevShells = {\n    default = pkgs.mkShell {\n      packages = [\n        python\n        pkgs.pyright\n        pkgs.black\n      ];\n    };\n  };\n```\n\nAnd then you can plop it in your `flake.nix` (here's the one we worked on earlier)\n\n```nix\n{\n  description = \"{{ cookiecutter.description }}\";\n\n  inputs = {\n    flake-utils.url = \"github:numtide/flake-utils\";\n    nixpkgs.url = \"github:nixos/nixpkgs/nixos-unstable\";\n  };\n\n  outputs =\n    {\n      self,\n      nixpkgs,\n      flake-utils,\n    }:\n    flake-utils.lib.eachDefaultSystem (\n      system:\n      let\n        pkgs = import nixpkgs { inherit system; };\n        python = pkgs.python3.withPackages (python-pkgs: [ python-pkgs.selenium ]);\n      in\n      {\n        packages = {}#snip ...\n        devShells = {\n          default = pkgs.mkShell {\n            shellHook = ''\n             # run when they enter\n              echo \"Welcome to the dev environment!\"\n            '';\n            packages = [\n              python\n              pkgs.pyright\n              pkgs.black\n            ];\n          };\n        };\n      }\n    );\n}\n```\n\nThis will give you access to what our output had access to -- it updates our $PYTHONPATH so that our LSP can see the dependencies, so we can get nice red squiggles and all the good language server support. We can add any dependencies we want, and even add shell hooks to set up the developer environment further.\n\nTo enter the `devshell`, you just do `nix develop`. You can also use `direnv`, by [installing it](https://direnv.net/), and then creating a `.envrc` with the contents\n\n```env\nuse flake\n```\n\nAnd then typing `direnv allow`. It's a neat utility made so that when you cd into directories it automatically enters their respective devshell. This is great because you don't need your python and rust and android and javascript and typescript bun node encryption cli tools and so much other crap in the global path. It reduces conflicts, and all developers working on your project can have the same environment.\n\nWhen you're ready for a real, pure build, you can then just slap in a `packages.default`, and then you're set.\n\n## Some really cool builders\n\nThere's a lot of nice nix abstractions out there. This includes 3rd party builders and builtin ones. Some cool ones are\n\n- [Poetry2nix](https://github.com/nix-community/poetry2nix) to build poetry python projects easily\n- [buildMavenPackage](https://github.com/NixOS/nixpkgs/blob/master/doc/languages-frameworks/maven.section.md) to build java projects\n- [buildNpmPackage](https://github.com/NixOS/nixpkgs/blob/master/doc/languages-frameworks/javascript.section.md) for building maven packages\n- [buildGoModule](https://nixos.wiki/wiki/Go) for building go modules\n- And builders for most other languages too!\n\nOne of the issues with packaging with nix is that the `sandbox` that the building happens in must use `nix`'s primitive `fetchers` like `fetchURL` and `fetchTAR` before unpacking, and there's no internet during the build step. This poses a challenge since you can't do things like `pip install` during the build. These fancy builders basically let you do the downloads and specify hashes before the build, using the `hashes` to guarantee purity (a common `nix` technique)\n\n# Living the Nix Life (NixOS)\n\nHere is a pure, complete, declarative, plug and play NixOS configuration to describe an entire linux system.\n\n```nix\n{\n  description = \"An entire system configuration\";\n\n  inputs = {\n    nixpkgs.url = \"github:NixOS/nixpkgs/nixos-unstable\";\n  };\n\n  outputs = { self, nixpkgs, ... }@inputs: {\n    nixosConfigurations.my-nixos = nixpkgs.lib.nixosSystem {\n      system = \"x86_64-linux\";\n      modules = [];\n    };\n  };\n}\n```\n\nJust a plain old super super minimal linux setup. But this isn't really useful. There's no shell, no packages, no users, nothing useful.\n\nSo let's add some user and set up ssh...\n\n```nix\n# Credit (inspiration): https://nixos-and-flakes.thiscute.world/nixos-with-flakes/get-started-with-nixos\n{\n  description = \"An entire system configuration\";\n\n  inputs = {\n    nixpkgs.url = \"github:NixOS/nixpkgs/nixos-unstable\";\n  };\n\n  outputs = {\n    self,\n    nixpkgs,\n    ...\n  } @ inputs: {\n    nixosConfigurations.my-nixos = nixpkgs.lib.nixosSystem {\n      system = \"x86_64-linux\";\n      modules = [\n        {\n          users.users.wolf = {\n            description = \"wolf\";\n            openssh.authorizedKeys.keys = [\n              \"ssh-ed25519 %3Csome-public-key%3E wolf@wolf-pc\"\n            ];\n            packages = with pkgs; [firefox];\n          };\n          services.openssh = {\n            enable = true;\n            settings = {\n              PermitRootLogin = \"no\";\n              PasswordAuthentication = false;\n            };\n            openFirewall = true;\n          };\n        }\n      ];\n    };\n  };\n}\n```\n\n# Other Cool Things I've Come Accross\n\nThere's a million neat nix things that I come across each week. Here's a list of some cool ones that might be worth checking out...\n\n## Nix Dev Containers on Windows w/Nix WSL\n\nThanks to this [Nix on WSL](https://github.com/nix-community/NixOS-WSL) you can set up developer containers with nix devshells, defined with flakes, on Windows. You can also configure an entire NixOS configuration on Windows. This is much better than using docker dev containers!\n\n# Credits\n\nThanks to Paolo Holinski for inspiration from a Recurse Center nix presentation and Trevor Nichols for getting me into nix in the first place.","src/posts/WhirlwindTourOfNix.mdx","2a728b9b7fd5751a"]